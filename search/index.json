[{"content":"什么是 UPnP？ UPnP（Universal Plug and Play，通用即插即用）是一种网络协议标准，旨在让网络设备（如计算机、打印机、摄像头、智能电视、路由器、IoT设备等）在接入网络时能够自动发现彼此并建立功能性的网络服务，无需用户手动配置。其设计目标是实现“零配置”网络体验。 UPnP 基于开放的互联网标准和技术，如 TCP/IP、HTTP、XML、SOAP 和 SSDP，使其能在多种操作系统和硬件平台上运行。\nUPnP 基本原理 UPnP 网络通常包含三种角色：\n设备 (Device)：提供一项或多项服务的网络实体（如智能灯泡、网络摄像头）。\n服务 (Service)：设备提供的最小功能控制单元（如开关服务、亮度调节服务）。\n控制点 (Control Point)：发现并控制设备的控制器（如手机App、电脑上的软件）。\nUPnP 的工作流程可分为以下几个核心阶段：\n寻址（Addressing） 设备接入网络后，首先通过 DHCP 获取 IP 地址；若 DHCP 不可用，则使用 Auto-IP（如 169.254.x.x）自行分配一个局域网内可用的 IP。\n发现（Discovery） 设备使用 SSDP（Simple Service Discovery Protocol，简单服务发现协议）向局域网广播自己的存在：\n广播消息：设备发送 M-SEARCH 请求或 NOTIFY 通知。\n响应机制：控制点（如手机App或PC）监听这些广播，并向感兴趣的设备发送请求获取详细信息。\n使用组播地址 239.255.255.250:1900 进行通信。\n描述（Description） 控制点通过 HTTP GET 请求从设备提供的 URL 获取 XML 描述文件，该文件包含：\n设备类型、厂商信息、型号、序列号\n支持的服务列表（如端口映射、音量控制等）\n每个服务的控制URL、事件URL、描述URL\n控制（Control） 控制点通过 SOAP（Simple Object Access Protocol）协议向设备发送控制指令，调用其服务方法。例如：\n调用“AddPortMapping”在路由器上添加端口转发规则\n调用“SetVolume”调节音响音量 请求和响应均使用 XML 格式封装，通过 HTTP POST 发送。\n事件通知（Eventing） 设备状态变化时（如播放状态改变、端口映射成功），可通过 GENA（General Event Notification Architecture）协议向订阅的控制点推送事件通知（也是 XML 格式），实现状态同步。\n展示（Presentation，可选） 设备可提供一个内置的 Web 界面（URL 包含在描述文件中），用户可通过浏览器访问进行图形化控制或查看状态。\nUPnP 主要功能 自动设备发现与互操作 局域网内设备自动广播身份，无需手动输入 IP 或配置。\n不同厂商设备只要遵循 UPnP 标准即可互通（如智能灯泡 + 手机App）。\n自动端口映射（NAT 穿透） 最重要功能之一：允许内网设备（如游戏主机、P2P软件、监控摄像头）自动在路由器上创建端口转发规则，实现从外网访问。\n应用场景：在线游戏联机、远程访问家庭摄像头、BT下载加速等。\n无需用户登录路由器后台手动设置端口转发。\n设备控制与状态同步 可远程控制设备功能（播放/暂停、开关机、调节参数等）。\n实时接收设备状态变更通知（如“播放结束”、“电量低”）。\n零配置网络体验 用户无需了解网络知识，插上网线或连上WiFi即可使用设备功能。\n特别适合家庭用户和 IoT 设备。\n支持多种设备类型 路由器、打印机、NAS、媒体服务器（DLNA）、智能家电、安防设备等均可支持 UPnP。 UPnP 的优缺点 ✅ 优点： 简单易用：真正实现“即插即用”。\n跨平台兼容：基于标准互联网协议，支持 Windows、Linux、macOS、Android、iOS 等。\n自动化程度高：减少人工配置错误。\n❌ 缺点与风险： 安全风险：恶意软件可能利用 UPnP 自动在路由器上开洞，暴露内网服务（如勒索软件、僵尸网络）。\n缺乏认证机制：默认无用户权限控制，局域网内任何设备都可操作。\n稳定性问题：部分设备实现不规范，可能导致冲突或失效。\n🛡️ 安全建议：\n家庭用户如无远程访问需求，建议在路由器中关闭 UPnP 功能。 企业网络应严格禁用 UPnP。 使用支持 UPnP-IGD v2 的设备，其安全性有所增强（支持 PIN 验证等）。 典型应用场景 场景 说明 在线游戏主机联网 Xbox/PS 自动请求端口映射，实现 NAT 开放或中等。 P2P 下载（如 BitTorrent） 客户端自动映射端口，提高连接数和下载速度。 远程访问家庭摄像头/NAS 自动在路由器上映射端口，便于外网访问。 DLNA 媒体共享 电视自动发现局域网内的媒体服务器并播放影片。 智能家居控制 手机 App 自动发现并控制智能插座、灯泡等。 相关协议与标准组织 标准组织：UPnP Forum（现由 Open Connectivity Foundation 接管） 核心协议： SSDP（发现） HTTP + XML（描述） SOAP（控制） GENA（事件） 扩展标准： UPnP-IGD（Internet Gateway Device）：专用于路由器端口映射。 DLNA（Digital Living Network Alliance）：基于 UPnP 的媒体共享标准。 总结 UPnP 是一项旨在简化家庭和小型办公网络设备互联的技术，通过标准化的发现、描述、控制和事件机制，实现了真正的“零配置”体验。尤其在自动端口映射方面极大地方便了普通用户。然而，其安全机制的缺失也带来潜在风险，用户应根据实际需求权衡是否启用。 随着 IoT 和智能家居的普及，UPnP 仍在广泛使用，但正逐步被更安全的替代方案（如 NAT-PMP、PCP、mDNS + DNS-SD）所补充或取代。\n📚 参考资料：UPnP Device Architecture 2.0, IETF RFC 6970, OCF Specifications\n","date":"2025-09-15T14:53:06+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/upnp%E9%80%9A%E7%94%A8%E5%8D%B3%E6%8F%92%E5%8D%B3%E7%94%A8%E5%8D%8F%E8%AE%AE%E4%BB%8B%E7%BB%8D/","title":"upnp(通用即插即用)协议介绍"},{"content":"docker 搭建 hwdsl2/docker-ipsec-vpn-server: Docker image to run an IPsec VPN server, with IPsec/L2TP, Cisco IPsec and IKEv2\n1 2 3 4 5 6 7 8 9 10 docker run \\ --name ipsec-vpn-server \\ --restart=always \\ --env-file ./vpn.env \\ -v ikev2-vpn-data:/etc/ipsec.d \\ -v /lib/modules:/lib/modules:ro \\ -p 500:500/udp \\ -p 4500:4500/udp \\ -d --privileged \\ hwdsl2/ipsec-vpn-server vpn.env\n1 2 3 4 5 6 VPN_IPSEC_PSK=ipsec VPN_USER=vpnuser VPN_PASSWORD=123456 VPN_PUBLIC_IP=x.x.x.x VPN_ADDL_USERS=vpnuser1 vpnuser2 VPN_ADDL_PASSWORDS=123456 123456 查看docker启动log\ndocker logs ipsec-vpn-server\n一些client 连接可能遇到的问题\nsetup-ipsec-vpn/docs/clients.md at master · hwdsl2/setup-ipsec-vpn\n连接ipsec/l2tp 可能遇到的问题 Windows error 809\nError 809: The network connection between your computer and the VPN server could not be established because the remote server is not responding. This could be because one of the network devices (e.g, firewalls, NAT, routers, etc) between your computer and the remote server is not configured to allow VPN connections. Please contact your Administrator or your service provider to determine which device may be causing the problem.\n1 REG ADD HKLM\\SYSTEM\\CurrentControlSet\\Services\\PolicyAgent /v AssumeUDPEncapsulationContextOnSendRule /t REG_DWORD /d 0x2 /f 配置Ikev2 可参考docker-ipsec-vpn-server/README-zh.md at master · hwdsl2/docker-ipsec-vpn-server\ndocker logs ipsec-vpn-server查看IKEv2 相关配置信息\n1 2 3 4 5 6 7 IKEv2 is already set up. Details for IKEv2 mode: VPN server address: 208.216.217.35 VPN client name: vpnclient Client configuration is available inside the Docker container at: 首次启动时，可能使用的是默认配置，需要手动更改\n进入dockerdocker exec -it ipsec-vpn-server /bin/sh\n1 2 wget https://get.vpnsetup.net/ikev2addr -O ikev2addr.sh bash ikev2addr.sh 执行ikev2addr.sh去手动更改vpnserver address\n配置IKEv2 client（windows) 1 2 3 4 # 查看容器内的 /etc/ipsec.d 目录的文件 docker exec -it ipsec-vpn-server ls -l /etc/ipsec.d # 示例：将一个客户端配置文件从容器复制到 Docker 主机当前目录 docker cp ipsec-vpn-server:/etc/ipsec.d/vpnclient.p12 ./ 在创建IKEv2连接之前，需要在windows 客户端 导入证书\n1 2 # Import .p12 file (replace with your own value) certutil -f -importpfx \u0026#34;\\path\\to\\your\\file.p12\u0026#34; NoExport 可能遇到的问题 IKE authentication credentials are unacceptable\n可能是IKEv2 vpn server中 server address配置不对，可以尝试更改VPN server address\nPolicy match error\n1 REG ADD HKLM\\SYSTEM\\CurrentControlSet\\Services\\RasMan\\Parameters /v NegotiateDH2048_AES256 /t REG_DWORD /d 0x1 /f 在windows server 上搭建vpn server 可参考Windows Server 2012 R2 安装SSTP/L2TP/PPTP – Noname\n在windows 上安装并使用openvpn 参考链接\nopenvpn安装配置说明(windows系统) OpenVPN Windows 平台安装部署教程 安装openvpn https://github.com/OpenVPN/openvpn\nhttps://openvpn.net/community-downloads/\nopenvpn软件服务端和客户端都是同一个安装包 安装服务端的时候要选择Customize，勾选openvpn service和EasyRSA3 安装，用于服务端配置和证书生成使用。 安装客户端时可直接点击Install Now进行安装 证书生成 安装服务端的时候已经安装了证书生成工具**EasyRSA3，**使用此工具即可生成所需证书\n进入EasyRSA shell 环境dos窗口\n进入C:\\Program Files\\OpenVPN\\easy-rsa目录，双击EasyRSA-Start.bat 进入EasyRSA shell 环境dos窗口中\n初始化证书生成程序\n弹出的dos窗口中输入./easyrsa init-pki 初始化证书生成程序，初始化成功后会在C:\\Program Files\\OpenVPN\\easy-rsa目录下新建文件夹kpi\n生成ca证书\n在dos窗口中输入./easyrsa build-ca nopass生成无密码CA证书，生成过程中会要求输入证书名称，随意输入即可，生成结束后会打印出证书所在目录easy-rsa\\pki\\ca.crt\n生成服务端证书\n输入./easyrsa build-server-full server nopass 生成无密码服务端证书,生成后证书文件在C:\\Program Files\\OpenVPN\\easy-rsa\\pki\\issued文件夹\n生成客户端证书\n输入./easyrsa build-client-full client nopass生成无密码客户端证书,生成后证书在C:\\Program Files\\OpenVPN\\easy-rsa\\pki\\issued文件夹\n生成DH密钥交换协议\n输入./easyrsa gen-dh生成DH密钥交换协议文件,生成文件在C:\\Program Files\\OpenVPN\\easy-rsa\\pki目录下\n目录C:\\Program Files\\OpenVPN\\easy-rsa\\pki\\private下为证书key\nopenvpn --genkey tls-auth ta.keyto help block DoS attacks and UDP port flooding.\n配置文件 服务端配置文件模板为server.ovpn，客户端配置文件client.ovpn，在 C:\\Program Files\\OpenVPN\\sample-config目录下有。在服务端或客户端的windows主机上复制对应配置文件模板到C:\\Program Files\\OpenVPN\\config目录下\n配置文件中 ； # 都可以用作注释，但是不支持在配置指令的同一行后面添加注释\n例如 cipher AES-256-CBC #选择加密算法 这样写是错误的，解析时会将cipher 后的AES-256-CBC #选择加密算法整个字符串当成参数值，从而导致错误\n服务端server.ovpn 修改\n端口：（公网需要对应开通此端口）port udp 1194 协议文件名：dh dh2048.pem修改为dh dh.pem 运行多用户使用同一客户端证书：;duplicate-cn取消注释（前面;号删除）修改为duplicate-cn 客户端client.ovpn修改\n修改连接服务器地址: remote my-server-1 1194修改为remote 服务器公网ip 1194 取消注释掉此行: ;tls-auth ta.key 1修改为 tls-auth ta.key 1（前面;号删除） 证书复制 配置文件server.ovpn client.ovpn 中的证书 和 key 都是只有文件名 ，没有规定具体路径\n需要将其copy 到C:\\Program Files\\OpenVPN\\config 下\n将服务端证书，服务端key，ca证书，dh文件, ta.key复制到文件夹C:\\Program Files\\OpenVPN\\config下\n将客户端证书，客户端key，ca证书 , ta.key复制到目录C:\\Program Files\\OpenVPN\\config下\n连接 右键点击任务栏带锁小电脑图标，点击连接,连接成功后系统分配ip，小电脑变绿\n其它 tls-auth ta.key 配置为防御 DoS,UDP 淹没等恶意攻击行为的选项，如配置需要生成ta.key证书，生成方式：跳转到openvpn软件的bin目录下，在dos窗口中输入：openvpn.exe --genkey --secret ta.key ，便在bin目录下生成ta.key证书了，复制到配置文件目录即可。 证书时间等参数可以在vars文件中设置，设置后重新启动EasyRSA-Start即可加载新配置。 ;client-to-client为客户端之间是否能直接访问的配置，去掉注释后生效。 ;push \u0026ldquo;redirect-gateway def1 bypass-dhcp\u0026rdquo; 配置开启后客户端所有流量将路由至服务器，需要在访问端服务器上配置路由转发后才可以访问公网。 开启第4步后，可在客户端配置文件中增加route 192.168.1.0 255.255.255.0 net_gateway配置，使该网段不通过openvpn路由 ","date":"2025-09-01T19:31:02+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/%E6%90%AD%E5%BB%BAvpn-server/","title":"搭建vpn server"},{"content":"官方文档\nCORE (Common Open Research Emulator) 是一个强大的、开源的网络模拟和仿真工具，广泛应用于网络研究、教学、协议开发和网络应用测试\n主题 描述 Architecture 体系结构概述，介绍如何使用Python、gRPC直接控制Core Installation CORE的安装方法及要求 GUI 如何使用GUI Node Types CORE支持的节点类型概述 (BETA) Python GUI 如何使用基于Python的BETA GUI Python API 介绍如何使用Python直接控制Core (自己实现core-daemon) gRPC API 介绍如何使用gRPC控制Core (连接core-daemon 调用其api) Distributed 在多个服务器上运行CORE的分布式细节 CTRLNET 如何控制网络从主机与节点通信 Services 概述所提供的服务并创建自定义服务 Performance 使用CORE时的性能说明 Developers Guide 概述如何对CORE开发 Core Emane CORE中运行和使用EMANE的高级主题和示例 Emane开发手册 Emane的架构介绍 开发相关 ","date":"2025-08-18T20:01:30+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/corecommon-open-research-emulator%E7%BD%91%E7%BB%9C%E4%BB%BF%E7%9C%9F%E5%B7%A5%E5%85%B7/","title":"CORE(Common Open Research Emulator)网络仿真工具"},{"content":"IPv6 地址结构 一个 IPv6 地址由 128 个比特（bits）组成，通常分为 8 个 16 比特的块，每个块用冒号（:）分隔，并以十六进制表示。\n例如：2001:0db8:85a3:0000:0000:8a2e:0370:7334\n地址压缩规则 为了简化书写，IPv6 地址可以被压缩：\n省略前导零 每个块中开头的\n1 0 可以省略。\n0db8 -\u0026gt; db8 0000 -\u0026gt; 0 0370 -\u0026gt; 370 压缩连续的零: 可以使用双冒号 :: 来替代地址中任意一段连续的、全为 0 的块。注意：在一个地址中 :: 只能使用一次。\n应用上述规则后，上面的地址可以被简化为：\n1 2001:db8:85a3::8a2e:370:7334 IPv6 地址类型 IPv6 地址主要分为三种类型：单播（Unicast）、多播（Multicast）和任播（Anycast）。\n单播地址 (Unicast) 单播地址标识一个唯一的网络接口，发往单播地址的数据包将被送到该地址所标识的唯一接口。\n全球单播地址 (Global Unicast Address - GUA)\n范围: 全球唯一，可在公网路由。\n前缀: 通常以 2000::/3 开头。\n结构:\n全局路由前缀 (Global Routing Prefix): 通常为 48 位，由 ISP 分配给组织。 子网 ID (Subnet ID): 通常为 16 位，由组织内部规划子网。 接口 ID (Interface ID): 64 位，用于标识子网中的具体设备接口。 链路本地地址 (Link-Local Address)\n范围: 仅在同一物理或逻辑链路上有效，不能跨路由器路由。\n前缀: fe80::/10。\n用途: 用于邻居发现、自动地址配置等链路内部通信。设备启动后会自动生成。\n唯一本地地址 (Unique Local Address - ULA)\n范围: 仅在有限范围内（如一个组织或站点内部）使用，功能类似 IPv4 的私有地址。它不会在公网路由。\n前缀: fc00::/7。\n特殊地址\n环回地址: ::1/128，相当于 IPv4 的 127.0.0.1。\n多播地址 (Multicast) 多播地址标识一组网络接口，发往多播地址的数据包将被送到该组中的所有接口。\n前缀: ff00::/8。\n常见示例:\nff02::1: 链路本地范围内的所有节点。 ff02::2: 链路本地范围内的所有路由器。 任播地址 (Anycast) 任播地址也标识一组网络接口，但发往任播地址的数据包只会被送到这组接口中距离最近（根据路由协议的度量）的一个。任播地址的格式与单播地址相同，但通过路由配置实现。\nIPv6 地址分配方法 设备获取 IPv6 地址主要有以下几种方式：\n无状态地址自动配置 (SLAAC) SLAAC 是 IPv6 的核心特性之一，允许设备在没有 DHCP 服务器的情况下自动配置地址。\n过程:\n设备启动后，首先为自己生成一个链路本地地址。 设备向本地链路发送一个路由器请求 (Router Solicitation - RS) 多播消息。 链路上的路由器收到 RS 后，会回复一个路由器通告 (Router Advertisement - RA) 消息。RA 消息中包含了网络前缀（如 GUA 前缀）和其他网络信息。 设备使用 RA 中通告的前缀，并结合自己的接口 ID（通常通过 EUI-64 算法或随机生成）来构成一个完整的全球单播地址。 有状态 DHCPv6 (Stateful) 工作方式类似于 IPv4 的 DHCP，由 DHCPv6 服务器集中管理和分配 IPv6 地址。\n优点: 便于集中管理和审计，可以精确控制地址分配。 适用场景: 需要严格管理地址分配的企业网络。 无状态 DHCPv6 (Stateless) 这是一种混合模式。\n设备通过 SLAAC 获取 IPv6 地址。 同时，设备通过 DHCPv6 获取其他网络配置信息，例如 DNS 服务器地址、域名等。 这种方式既利用了 SLAAC 的便捷性，又弥补了其无法提供 DNS 等附加信息的不足。 静态配置 (Manual) 管理员手动为设备配置静态的 IPv6 地址、网关和 DNS 等信息。适用于服务器、路由器等需要固定地址的设备。\nDHCPv6 交互过程 DHCPv6 客户端和服务器之间的通信过程，用于获取 IPv6 地址和/或其他网络配置参数。标准的交互过程涉及四次消息交换，这确保了客户端可以选择最合适的服务器。\n四步交换 (Four-Way Exchange):\nSolicit (请求): 客户端在本地链路上发送一个 Solicit 多播消息，以发现可用的 DHCPv6 服务器。 消息发送到所有 DHCP 中继代理和服务器的多播地址 ff02::1:2。 Advertise (通告): 收到 Solicit 消息的 DHCPv6 服务器会回复一个 Advertise 单播消息。 此消息中包含了服务器可以为客户端提供的地址和/或配置信息。一个客户端可能会收到多个 Advertise 消息。 Request (请求): 客户端从收到的一个或多个 Advertise 消息中选择一个服务器，并向其发送一个 Request 单播消息，正式请求分配地址和/或配置参数。 消息中会包含它所选择的服务器的标识符。 Reply (回复): 被选中的服务器收到 Request 消息后，会发送一个 Reply 单播消息，确认地址分配和配置信息。 此时，客户端完成配置，可以开始使用获取到的地址。 两步交换 (Two-Way Exchange) - 快速提交 (Rapid Commit): 为了加速地址分配过程，DHCPv6 引入了快速提交选项。 Solicit (请求): 客户端在 Solicit 消息中加入 \u0026ldquo;Rapid Commit\u0026rdquo; 选项，表示希望立即完成地址分配。 Reply (回复): 支持快速提交的服务器如果愿意立即分配地址，会直接回复一个 Reply 消息，跳过 Advertise 和 Request 步骤。 这种两步交换减少了延迟，在许多场景下（如网络中只有一个 DHCPv6 服务器）非常高效 关键协议与技术 在一个部署 IPv6 的广播域中，相比 IPv4 一个最明显的区别就是 IPv6 路由通告；在 IPv4 时代，一个广播域中的 ipv4 网段并没有显式说明，或者说并没有一个 ipv4 网段宣称占据了这个广播域，仅使用这个广播域的广播/组播能力，多个ipv4网段共用一个广播域的情况也不鲜见；而在ipv6中，运行ipv6协议的路由器会主动发送名为路由通告 Router Advertisement的 ICMPv6 报文，在广播域中宣告/广播*此 ipv6 网段占据了该广播域；\n*（准确的讲应该是组播，IPv6 已经没有广播概念了，这里使用广播这个说法为了说明是公开发送的，在一个广播域中，广播和组播达成的功能类似，且在低端交换机中，广播和组播的转发方式是一致的）\nRA（路由通告 Router Advertisement）使用 ICMPv6 报文（type 134），属于 NDP 协议的一部分\nIPv6 的功能实现严重依赖于一些关键的底层协议，特别是 ICMPv6 和在其基础上构建的邻居发现协议 (NDP)，以及用于动态分配网络前缀的 DHCPv6-PD。\nICMPv6 IPv6 时代的ip层控制协议（类比ipv4中的arp、icmp等）均使用icmpv6报文，取消了IP层的广播，转而广泛使用组播。ICMPv6 中的 type 133 ~ 137 报文由NDP协议使用，用于发现网关、邻居、地址配置等等。\nICMPv6 ICMPv6 是 IPv6 的一个核心组成部分，其功能远超 IPv4 中的 ICMP。它不仅用于传输网络错误和诊断信息，还承载了许多关键的网络控制功能。如果防火墙错误地完全阻止 ICMPv6，将导致 IPv6 网络中断。\n主要功能:\n错误报告: 如 \u0026ldquo;目标不可达\u0026rdquo;、\u0026ldquo;数据包过大\u0026rdquo;、\u0026ldquo;超时\u0026rdquo; 等。 诊断查询: 如 ping 命令所使用的 \u0026ldquo;Echo Request\u0026rdquo; 和 \u0026ldquo;Echo Reply\u0026rdquo;。 网络控制: 为 NDP、MLD (多播侦听发现) 等协议提供消息支持。 NDP (邻居发现协议) NDP 是 IPv6 中一个至关重要的协议，它取代了 IPv4 中的 ARP、ICMP 路由器发现和 ICMP 重定向等多个协议的功能。NDP 基于 ICMPv6 实现，是实现即插即用和 SLAAC 的基础。\nNDP 的核心功能:\n地址解析: 将 IPv6 地址解析为链路层地址（如 MAC 地址），取代了 ARP。 路由器发现: 主机可以发现本地链路上的路由器。 前缀发现: 主机可以发现用于自动配置的地址前缀。 重复地址检测 (DAD): 节点可以确认其想要使用的地址在链路上是唯一的。 可达性跟踪: 判断邻居节点是否仍然可达。 NDP 使用的五种 ICMPv6 消息类型:\n路由器请求 (Router Solicitation - RS): 通常由终端主动发送，用于在未收到周期性 RA 的情况下，请求 RA 路由器通告 (Router Advertisement - RA):由路由器周期性发送，也可以响应 RS 发送，用于宣告本广播域中 IPv6 相关信息。比如前缀、网关、DNS等 邻居请求 (Neighbor Solicitation - NS): 用于解析邻居的链路层地址或执行 DAD,和 IPv4 的 ARP request 功能一致。 邻居通告 (Neighbor Advertisement - NA): 对 NS 消息的响应，或在链路层地址变化时主动发送和 ,IPv4 的 ARP reply功能一致。 重定向 (Redirect): 路由器告知主机有更优的下一跳路径,类似于 IPv4 的icmp redirect功能。 RS/RA RS/RA 是IPv6 环境下独有的控制信令，此信令明确了一个广播域中各节点所代表的角色。\n广播域中发送RA的为路由器\n广播域中可以存在多个路由器\nRA 组播周期性发送\nRS 用于在未收到 RA 情况下请求 RA\nRA 中的Flags表明当前广播域中 IPv6 地址的配置方式\n这些 Flags 分布在两个位置\u0026mdash;-ICMPv6 报头和 prefix option，后者称为 PIO(Prefix Information Option) flag。\nM(Managed address configuration):位于报头，M=1 表明终端应该使用 DHCPv6 协议配置地址和其他网络参数；如果M=1，则忽略 O Flag；此flag用于DHCPv6 有状态模式。 O(Other configuration):位于报头，O=1且M=0 表明终端应该使用 DHCPv6 设置除了 IPv6 地址之外的其他（dns/ntp等），此 flag 用于 DHCPv6 无状态模式。 A(Autononous address-configuration flag):位于PIO中，A=1 表明终端应该使用 SLAAC 配置 IPv6 地址；PIO可以包含多个 Prefix，这也就意味着一个广播域中可以存在多个 IPv6 网段。 这几种flag是可以复合使用的，以满足不同场景需求,除了手动静态配置ipv6地址，动态/自动配置或者半自动配置ipv6地址的方式都需要从ndp协议的 RA 开始，就好像 RA 引导了IPv6自动配置的开始；RA中的不同flag叠加影响地址自动配置；\nDHCPv6-PD DHCPv6前缀代理DHCPv6-PD(PrefixDelegation)是一种前缀分配机制，通过DHCPv6前缀代理机制，下游 网络设备不需要再手工指定用户侧链路的IPv6地址前缀，它只需要向上游网络设备提出前缀分配申请，上游网 络设备便可以分配合适的地址前缀给下游设备，下游设备把获得的前缀再通过路由通告(RA)至与IPv6主机直连 的用户链路上，实现IPv6主机的地址自动配置，完成整个系统层次的地址布局。\nDHCP-PD 技术最早在RFC3633中提出，经过几次更新目前最新的是RFC8415，其主要思想是把DHCPv6的地址分配方式划分为多层，dhcp client不再是仅仅获取地址用于终端通信，而是可以作为次级路由器身份把地址层层分配下去；这样的好处是便于快速和统一部署大量地址，尤其是在大规模动态地址的情况下，此种地址分配方式在家庭宽带中已经大量部署；光猫从其上级获取一段地址用于本地网络终端的地址分配，甚至从光猫拿到的地址还能再往下一层分配.\n工作原理:\n请求: 家庭路由器（客户端）向其上游 ISP 的路由器（服务器）发送 DHCPv6 请求，希望获得一个 IPv6 地址前缀（例如一个 /56 或 /48 的地址块），而不仅仅是一个地址。 代理: ISP 路由器从其地址池中分配一个前缀块，并通过 DHCPv6 回复将其“代理”或“授权”给家庭路由器。 分配: 家庭路由器获得该前缀后，就拥有了管理这个地址块的权限。它可以将这个前缀进一步划分为更小的子网（例如多个 /64 子网），并为连接到其 LAN 口的各个内部网络（如家庭网络、访客网络）分配这些子网前缀。 通告: 家庭路由器在其内部网络上发送 RA 消息，通告这些 /64 的子网前缀，使得内部网络中的设备可以通过 SLAAC 自动配置 IPv6 地址。 优势:\n自动化: 无需手动配置下游路由器的子网，实现了网络部署的自动化。 结构化: 使得家庭或小型办公室可以轻松地拥有多个独立的 IPv6 子网，便于网络隔离和管理。 高效性: 相比于 NAT，每个设备都能获得全球唯一的公网地址，实现了真正的端到端连接。 link-local 对比IPv4环境，IPv6 地址有所谓的 link-local 地址而且充当比较重要作用；由于一个接口可以配置很多IPv6地址，当这些地址作为下一跳使用的时候会出现混乱，这样不利于管理也不利于设备性能开销,使用Link Local地址唯一标识链路上的一个节点就避免了这个问题。而且在网络重新编址过程中，Link Local并不会发生变化，更利于快速更改编址\nDAD DAD 基于 ICMPv6 Neighbor Solicitation（NS，邻居请求） 和 Neighbor Advertisement（NA，邻居通告） 消息实现，步骤如下：\n节点分配一个 IPv6 地址（如通过 SLAAC 或手动配置），但该地址尚未正式启用（处于 \u0026ldquo;tentative\u0026rdquo; 状态）。 发送 Neighbor Solicitation（NS）： 目标地址（Target Address）设为待检测的 IPv6 地址。 源地址设为 未指定地址（::）（因为该地址尚未正式使用）。 发送到 \u0026ldquo;请求节点组播地址\u0026rdquo;（Solicited-Node Multicast Address，FF02::1:FFXX:XXXX）。 等待响应： 如果没有收到 Neighbor Advertisement（NA），说明地址未被占用，可以正常使用。 如果收到 NA，说明地址已被占用，节点必须放弃该地址并重新配置（如 SLAAC 会生成新地址）。 DAD 完成： 成功通过检测后，地址变为 \u0026ldquo;Preferred\u0026rdquo; 或 \u0026ldquo;Valid\u0026rdquo; 状态，可以正常通信 邻居表 邻居表，在IPv4环境下就是ARP表，系统维护Arp表内容由系统自己决定，比如端口、更新时间等；\n到了IPv6环境，ND表代替了arp表，而且协议规定了5种邻居状态，IPv6 邻居状态，分别是： Incomplete、Reachable、Stale、Delay、Probe，其中只有 Stale 状态是稳定状态。\nIncomplete （未完成状态）：表⽰正在解 析地址，但邻居链路层地址尚未确定。 Reachable （可达状态）：表⽰地址解析 成功，该邻居可达。 Stale（失效状态）：表⽰可达时间耗尽，未确定邻居是否可达。 Delay（延迟状态）：表⽰未确定邻居是否可达。Delay 状态不是⼀个稳定的状态，⽽是⼀个延时等待状态。 Probe （探测状态）：节点会向处于 Probe 状态的邻居持续发送 NS 报⽂。 不同状态之间迁移如下图 1 2 ip neigh ip -6 neigh ","date":"2025-08-15T19:58:16+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/ipv6-%E5%9C%B0%E5%9D%80%E5%88%86%E9%85%8D%E8%AF%A6%E8%A7%A3/","title":"IPv6 地址分配详解"},{"content":"一般情况下如果我们想使用其他文件的函数时，常规操作是将该函数在头文件中声明，然后在需要使用的文件里引用这个头文件 但若是没声明呢？\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 11.c #include \u0026lt;stdio.h\u0026gt; extern char* b; int main() { printf(\u0026#34;aaa--d:%x----%s--p\\n\u0026#34;, aaa(),b,b); char*p = aaa(); printf(\u0026#34;p = %p\\n\u0026#34;, p); if(p) printf(\u0026#34;---\\n\u0026#34;); printf(\u0026#34;value = %s\\n\u0026#34;，p);// 崩溃! return 0; } 2.c char *b=\u0026#34;aaa\u0026#34;; char* aaa(){ return b;} 1 2 3 4 5 6 7 8 9 10 11 12 13 gcc 11.c 2.c -o test 11.c: In function ‘main\u0026#39; 11.c:4:37: warning:: implicit declaration of function ‘aaa\u0026#39;[-Wimplicit-function-declaration] 4| printf(\u0026#34;aaa--d:%x----%s--%p\\n\u0026#34;,aaa(),b,b); | ^~~ 11.c:5:15: warning:： initialization of ‘char *’ fromn‘int\u0026#39; makes pointer from integer without a cast [-Wint-conversion] 5| char *p = aaa(); | ^~~ ./test aaa--d:4b1c032----aaaa--0x560604b1c032 p=0x4b1c032 --- Segmentation fault (core dumped) 这里并没有引用这个头文件，为什么依然可以使用呢？\n这就引出了一个概念：隐式声明。\n简单来讲就是当前文件使用没有声明的函数时，编译器会自动声明一个，但返回值是int类型\n那为什么会出现段错误呢? 上面编译运行的环境是64bit的:\nchar* aaa() 返回的是一个指针8B(64bit) 但是在编译时 已经确定了是返回值类型(由于是隐式声名,编译器默认是int) 是int 4B(32bit) ,所以就会把指针的低32bit 取出来 赋给char* *p 指针p 的值就是一个截断的值, 这个指针就变成了一个非法的了,如果取访问其指向的内存,就会出现 段错误.\n如果是32bit 环境呢\nint 是4B 指针也是4B ,指针不会被截断,还是原来的值,不会出现非法访问.\n如何避免呢: 在Makefile 里加上 -Wall -Werror ,编译时会检测出这种错误\n","date":"2025-08-15T16:22:16+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/implicit-function-declaration/","title":"implicit-function-declaration"},{"content":"什么是虚拟网卡？ 虚拟网卡是软件实现的网络接口，与物理网卡不同，它没有物理硬件，只存在于操作系统的内存中。虚拟网卡可以用来模拟网络环境，进行数据包的捕获、分析和处理。 TUN 和 TAP 的基本概念 Tun （Network TUNnel） TUN 是三层（网络层）的虚拟网络设备，主要用于 IP 数据包的处理。TUN 设备会模拟一个网络层接口，接收到的数据包会被传递给用户空间的程序进行处理，处理完的数据包会被发送回内核网络栈。\nTAP（Network TAP） TAP 是二层（数据链路层）的虚拟网络设备，主要用于以太网帧的处理。TAP 设备可以模拟一个以太网接口，能够接收和发送原始的以太网帧。这使得 TAP 设备非常适合用于桥接不同的网络环境，或者在虚拟机中模拟物理网卡。TAP是数据链路层的虚拟网络设备。\nTun和Tap的异同 Tun是三层的设备，该设备没有MAC地址，从字符设备上读取IP数据包，写入的也是IP数据包，因此不能进行二层的操作，例如发ARP包和以太网广播 Tab是二层的设备，该设备有MAC地址，处理的是数据链路层的数据帧，从字符设备上读取的是数据链路层的数据帧，写入的也是数据。\n在使用上面，两者都是通过字符设备的方式进行读取和写入，Tun是三层网络设备，而Tab是二层网络设备，Tun常用于VPN等技术，由于工作在IP层，无法与物理网卡做bridge，但可以通过三层交换（如 ip_forward）与物理网卡连通，Tab设备工作在第二层，收发的是MAC层数据包，拥有MAC层的功能，可以与物理网卡做bridge，支持MAC层广播 Tun和Tap应用场景 Tun是一个网络层设备，支持点到点的网络通信，常用于tunnel隧道和VPN的构建，tunnel技术是网络设备把网络层数据包封装到另一个协议中以跨过网络传送到另一个网络设备的处理过程，主要用于公网主机和私有网络互联互通。在Linux系统中支持多种隧道技术，其底层实现原理都是基于Tun设备。 TAP接口的典型应用场景是在虚拟化网络中。例如，我们通过KVM创建的多个VM（虚拟机），以LinuxBridge（桥接网络）互通；实际上即是通过像vnet0这样的TAP接口来接入LinuxBridge的。在这种场景下，KVM程序就是向TAP接口读写数据的用户空间程序。当VM0向本机的eth0接口发送数据，KVM会将数据发送到TAP接口vnet0，再通过LinuxBridge将数据转发到vnet1上。然后，KVM将数据发送到VM1的eth0口。 Tun 配置 1 2 3 4 5 6 7 8 \\# 创建网卡并配置IP ip tuntap add dev tun0 mode tun ip link set dev tun0 up ip addr add 10.0.0.1/24 dev tun0 ip route add 10.0.0.0/24 via 10.0.0.1 \\# 清除网卡 ip link set dev tun0 down ip tuntap del dev tun0 mode tun 转载自\nLinux虚拟网卡TUN和TAP - 心若向阳花自开 - 博客园\n参考资料 Universal TUN/TAP device driver Universal TUN/TAP device driver Frequently Asked Question Tun/Tap interface tutorial A simplistic, simple-minded, naive tunnelling program using tun/tap interfaces and TCP ","date":"2025-08-07T15:17:36+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/linux%E8%99%9A%E6%8B%9F%E7%BD%91%E5%8D%A1tun%E5%92%8Ctap/","title":"Linux虚拟网卡TUN和TAP"},{"content":"作业控制 (Job Control) 作业控制是大多数 shell 提供的一个功能，允许用户在单个终端上同时运行和管理多个命令（作业）。\n前台作业 (Foreground Job): 在终端中启动，它会独占终端的输入和输出。在它运行期间，shell 会被挂起，等待该作业完成。\n后台作业 (Background Job): 通过在命令后添加 \u0026amp; 符号启动。它不会占用终端，你可以在它运行时继续在 shell 中输入其他命令。\nCtrl+Z(SIGTSTP）暂停前台进程Ctrl+C(SIGINT）终止当前前台进程Ctrl+D（EOF）\n常用命令: jobs, fg, bg, kill %\u0026lt;job_id\u0026gt;。\n进程组 (Process Group) 进程组是一个或多个进程的集合。系统中的每个进程都属于一个进程组。\n目的: 主要用于作业控制，方便将信号（如 SIGINT, SIGTSTP）发送到一组相关的进程。例如，当你在终端按下 Ctrl+C 时，SIGINT 信号会被发送到当前前台作业的整个进程组。\n进程组ID (PGID): 每个进程组都有一个唯一的 ID。\n进程组领导 (Process Group Leader): 进程组中第一个创建的进程，其 PID 通常就是该进程组的 PGID。\n一个管道（pipeline）中的所有进程（例如 cat file | grep \u0026quot;text\u0026quot; | wc -l）通常属于同一个进程组。\n会话 (Session) 会话是一个或多个进程组的集合。它提供了一个更高层次的进程组织方式。\n目的: 将一个用户登录到退出期间创建的所有进程组织在一起。\n会话ID (SID): 每个会话都有一个唯一的 ID。\n会话领导 (Session Leader): 创建该会话的进程。通常，这是用户登录时启动的 shell 进程。\n控制终端 (Controlling Terminal): 一个会话通常与一个控制终端相关联。当控制终端断开连接时（例如关闭终端窗口或网络断开），内核会向会话领导发送 SIGHUP 信号，后者通常会将其传播给会话中的所有进程，导致它们终止。\nsetsid() 系统调用 setsid() 是一个关键的系统调用，用于创建一个新的会话。\n功能: 1. 调用 setsid() 的进程会成为一个新会话的会话领导。\n2. 该进程会成为一个新进程组的进程组领导。\n3. 该进程会脱离它之前的控制终端。\n前提: 调用 setsid() 的进程不能是某个现有进程组的领导者。为了确保这一点，通常的做法是 fork() 一个子进程，然后让父进程退出，子进程再调用 setsid()。\n用途: 这是创建守护进程（Daemon）的标准方法。通过创建一个没有控制终端的新会hs话，守护进程可以确保自己不会因为终端的关闭而意外终止。\nlxc-attach 后台进程导致退出卡住的原因分析 问题场景 用户在终端中执行 lxc-attach \u0026lt;container_name\u0026gt;。\n在 lxc-attach 创建的 shell 中，启动一个后台作业。\n输入 exit 尝试退出 lxc-attach 的 shell。\n此时，终端卡住，用telnet 连接然后kill 掉才可以回到host 主机的shell\n原因剖析 这个问题的核心在于进程关系和信号处理。\n进程结构: - 当你运行 lxc-attach 时，它会在容器内启动一个新的 shell 进程（如 bash）。\n- 这个新的 shell 是 lxc-attach 进程的子进程。\n- 重要的是，这个新 shell 没有成为新的会话领导。它与 lxc-attach 进程、以及你最初的登录 shell 位于同一个会话中，并共享同一个控制终端。\n启动后台进程: - 当你在 lxc-attach 的 shell 中运行一个后台进程。\n- 这个 后台进程与 lxc-attach 的 shell 属于同一个进程组。\n执行 exit: - 你输入 exit，lxc-attach 的 shell 进程开始退出流程。\n- shell 进程本身会终止。\n- lxc-attach 进程在等待其子进程（即那个 shell）完全终止。\n卡住的根源: - shell 进程虽然终止了，但它启动的后台进程仍然在运行。\n- 这个后台进程仍然是前台进程组的一部分（相对于控制终端而言），或者说它仍然与控制终端关联。\n- 控制终端的驱动程序会发现，虽然前台的 shell 退出了，但该进程组里还有其他进程 在运行。此时，终端会处于一种“挂起”或“等待”状态，因为它需要处理这个仍在运行的后台进程的标准输入/输出（即使它不读写）。\n- lxc-attach 进程本身也在等待，因为它可能需要清理与子进程相关的所有资源。只要 这个后台进程还在运行，整个进程链就无法干净地结束。\n- 只有当 这个后台进程结束后，整个进程组才算完全终结，控制终端的锁定状态被解除，lxc-attach 进程也随之退出，你才能回到原来的 shell 提示符。\n解决办法: nohup setsid disown\n参考链接 Linux session和进程组概述 - Linux程序员 - SegmentFault 思否\nLinux TTY/PTS概述 - Linux程序员 - SegmentFault 思否\n","date":"2025-08-06T15:36:36+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/linux-%E4%BD%9C%E4%B8%9A%E6%8E%A7%E5%88%B6%E8%BF%9B%E7%A8%8B%E7%BB%84%E5%92%8C%E4%BC%9A%E8%AF%9D/","title":"Linux 作业控制、进程组和会话"},{"content":"frok 一个运行的进程,它调用了fork()函数，然后就产生了子进程，原来的进程叫父进程。这个子进程也是进程，但凡是进程，都有自己的虚拟地址空间（让每个进程自己看起来是独占内存，通过段页内存管理映射到不同的物理地址空间）。虚拟地址空间是从0到4G的大小，其中3-4G是属于内核的（32位系统）。创建完子进程后，父进程继续运行程序（即原来的进程）的代码，刚创建出来的子进程拥有和父进程完全一样的代码段，数据段，也就是说完完全全拷贝了一份父进程，和父进程完全一样。即clone父进程0-3G的内容，而3-4G的kernel只需要重新映射一下到物理地址的kernel即可。但是操作系统要如何区分这两个进程呢？答案就是进程ID即pid。pid是存储在PCB当中的类似身份证的东西. kernel会创建子进程自己的PCB,然后clone父进程的PCB(task_struct)的绝大部分信息，如内存映射(mm_struct，采用 COW 机制copy on write),文件描述符表,调度信息（优先级、CPU 时间等）,但某些关键字段会被修改,如pid,ppid等.\nkernel会设置 fork() 的返回值.在子进程的 task_struct 中，kernel会预先设置 eax/rax 寄存器（存储返回值）为 0，因此子进程看到的 fork() 返回 0。父进程的 fork() 返回子进程的 pid。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; int q_val = 100; int main() { printf(\u0026#34;father is running, pid: %d, ppid: %d\\n\u0026#34;, getpid(), getppid()); sleep(2); pid_t id = fork(); int cnt = 3; while(1) { if(id == 0) { // Child process printf(\u0026#34;I am child process, pid: %d, ppid: %d, q_val: %d, \u0026amp;q_val: %p\\n\u0026#34;, getpid(), getppid(), q_val, \u0026amp;q_val); sleep(1); cnt--; if(cnt == 0) { q_val = 300; printf(\u0026#34;I am child, q_val is changed, 100 -\u0026gt; 300\\n\u0026#34;); } } else { // Parent process printf(\u0026#34;I am father process, pid: %d, ppid: %d, q_val: %d, \u0026amp;q_val: %p\\n\u0026#34;, getpid(), getppid(), q_val, \u0026amp;q_val); sleep(1); } } return 0; } fork底层是调用了内核的函数来实现fork的功能的，即先create()先创建进程，此时进程内容为空，然后clone()复制父进程的内容到子进程中，此时子进程就诞生了，接着父进程就return返回了。而子进程诞生后，是直接运行return返回的，然后接着执行后面的程序，这里注意：子进程是不会执行前面父进程已经执行过的程序了得，因为PCB中记录了当前进程运行到哪里，而子进程又是完全拷贝过来的，所以PCB的程序计数器也是和父进程相同的，所以是从fork()后面的程序继续执行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 father is running, pid: 2193928, ppid: 784260 I am father process, pid: 2193928, ppid: 784260, q_val: 100, \u0026amp;q_val: 0x55e878c7f010 I am child process, pid: 2193930, ppid: 2193928, q_val: 100, \u0026amp;q_val: 0x55e878c7f010 I am father process, pid: 2193928, ppid: 784260, q_val: 100, \u0026amp;q_val: 0x55e878c7f010 I am child process, pid: 2193930, ppid: 2193928, q_val: 100, \u0026amp;q_val: 0x55e878c7f010 I am father process, pid: 2193928, ppid: 784260, q_val: 100, \u0026amp;q_val: 0x55e878c7f010 I am child process, pid: 2193930, ppid: 2193928, q_val: 100, \u0026amp;q_val: 0x55e878c7f010 I am father process, pid: 2193928, ppid: 784260, q_val: 100, \u0026amp;q_val: 0x55e878c7f010 I am child process, pid: 2193930, ppid: 2193928, q_val: 100, \u0026amp;q_val: 0x55e878c7f010 I am father process, pid: 2193928, ppid: 784260, q_val: 100, \u0026amp;q_val: 0x55e878c7f010 I am child, q_val is changed, 100 -\u0026gt; 300 I am child process, pid: 2193930, ppid: 2193928, q_val: 300, \u0026amp;q_val: 0x55e878c7f010 I am father process, pid: 2193928, ppid: 784260, q_val: 100, \u0026amp;q_val: 0x55e878c7f010 I am child process, pid: 2193930, ppid: 2193928, q_val: 300, \u0026amp;q_val: 0x55e878c7f010 I am father process, pid: 2193928, ppid: 784260, q_val: 100, \u0026amp;q_val: 0x55e878c7f010 I am child process, pid: 2193930, ppid: 2193928, q_val: 300, \u0026amp;q_val: 0x55e878c7f010 I am father process, pid: 2193928, ppid: 784260, q_val: 100, \u0026amp;q_val: 0x55e878c7f010 I am child process, pid exec族 用fork创建子进程后执行的是和父进程相同的程序（但有可能执行不同的代码分支）， 子进程往往要调用一种exec函数以执行另一个程序。当进程调用一种exec函数时，该进程的 用户空间代码和数据完全被新程序替换，从新程序的启动例程开始执行。调用exec并不创建 新进程，所以调用exec前后该进程的id并未改变\n1 2 3 4 5 6 7 #include int execl(const char *path, const char *arg, ...); int execlp(const char *file, const char *arg, ...); int execle(const char *path, const char *arg, ..., char *const envp[]); int execv(const char *path, char *const argv[]); int execvp(const char *file, char *const argv[]); int execve(const char *path, char *const argv[], char *const envp[]); 这些函数如果调用成功则加载新的程序从启动代码开始执行，不再返回，如果调用出错 则返回-1，所以exec函数只有出错的返回值而没有成功的返回值\nwait/waitpid 僵尸进程: 子进程退出，父进程没有回收子进程资源（PCB），则子进程变成僵尸进程 孤儿进程: 父进程先于子进程结束，则子进程成为孤儿进程,子进程的父进程成为1号 进程init进程，称为init进程领养孤儿进程\n一个进程在终止时会关闭所有文件描述符，释放在用户空间分配的内存，但它的PCB还 保留着，内核在其中保存了一些信息：如果是正常终止则保存着退出状态，如果是异常终止 则保存着导致该进程终止的信号是哪个。这个进程的父进程可以调用wait或waitpid获取这 些信息，然后彻底清除掉这个进程。我们知道一个进程的退出状态可以在Shell中用特殊变 量$?查看，因为Shell是它的父进程，当它终止时Shell调用wait或waitpid得到它的退出状 态同时彻底清除掉这个进程。但是，如果父进程先于子进程结束，则子进程成为孤儿进程。孤儿进程将被 init 进程（进程号为1）领养，并由 init 进程对孤儿进程完成状态收集工作。而如果子进程先于父进程退出，同时父进程太忙了，无瑕回收子进程的资源，子进程残留资源（PCB）存放于内核中，变成僵尸。任何进程在刚终止时都是僵尸进程，正常情况下，僵 尸进程都立刻被父进程清理了.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; int main(void) { pid_t pid; pid = fork(); if (pid == 0) { printf(\u0026#34;I am child, my parent= %d, going to sleep 3s\\n\u0026#34;, getppid()); sleep(3); printf(\u0026#34;-------------child die--------------\\n\u0026#34;); } else if (pid \u0026gt; 0) { printf(\u0026#34;I am parent, pid = %d, myson = %d, going to sleep 5s\\n\u0026#34;, getpid(), pid); sleep(5); system(\u0026#34;ps -o pid,ppid,state,tty,command\u0026#34;); } else { perror(\u0026#34;fork\u0026#34;); return 1; } return 0; } 在这个程序里，父进程创建子进程之后，就休眠 5 秒钟。而子进程只休眠 3 秒钟就退出，在它退出之后，父进程还未苏醒，因此没人给子进程「收尸」，所以它就变成了僵尸进程。\n僵尸进程其实已经就是退出的进程，因此无法再利用kill命令杀死僵尸进程。僵尸进程的罪魁祸首是父进程没有回收它的资源，那我们可以想办法它其它进程去回收僵尸进程的资源，这个进程就是 init 进程。因此，我们可以直接杀死父进程，init 进程就会很善良地把那些僵尸进程领养过来，并合理的回收它们的资源，那些僵尸进程就得到了妥善的处理了\n","date":"2025-07-31T17:22:16+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/%E8%BF%9B%E7%A8%8B%E5%8E%9F%E8%AF%ADfork-exceve-waitpid/","title":"进程原语fork exceve waitpid"},{"content":"openwrt procd启动流程分析 kernel_init Linux内核执行start_kernel函数时会调用kernel_init来启动init进程，流程如下图\nstart_kernel\u0026ndash;\u0026gt;rest_init\u0026ndash;\u0026gt;kernel_init\u0026ndash;\u0026gt;try_to_run_init_process\nkernel_init()(位于 linux-4.1.52/init/main.c)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 /* * We try each of these until one succeeds. * * The Bourne shell can be used instead of init if we are * trying to recover a really broken machine. */ if (execute_command) { ret = run_init_process(execute_command); if (!ret) return 0; panic(\u0026#34;Requested init %s failed (error %d).\u0026#34;, execute_command, ret); } if (!try_to_run_init_process(\u0026#34;/sbin/init\u0026#34;) || !try_to_run_init_process(\u0026#34;/etc/init\u0026#34;) || !try_to_run_init_process(\u0026#34;/bin/init\u0026#34;) || !try_to_run_init_process(\u0026#34;/bin/sh\u0026#34;)) return 0; panic(\u0026#34;No working init found. Try passing init= option to kernel. \u0026#34; \u0026#34;See Linux Documentation/init.txt for guidance.\u0026#34;); } /sbin/init openwrt 源码 openwrt/package/system/procd/Makefile\n1 2 3 4 5 6 7 8 9 10 define Package/procd/install $(INSTALL_DIR) $(1)/sbin $(1)/etc $(1)/lib/functions $(INSTALL_BIN) $(PKG_INSTALL_DIR)/usr/sbin/{init,procd,askfirst,udevtrigger,upgraded} $(1)/sbin/ $(INSTALL_DATA) $(PKG_INSTALL_DIR)/usr/lib/libsetlbf.so $(1)/lib $(INSTALL_BIN) ./files/reload_config $(1)/sbin/ $(INSTALL_CONF) ./files/hotplug*.json $(1)/etc/ $(INSTALL_DATA) ./files/procd.sh $(1)/lib/functions/ $(INSTALL_BIN) ./files/service $(1)/sbin/service endef procd源码procd/CMakeList.txt\n1 2 3 4 5 6 7 8 9 10 IF(DISABLE_INIT) ADD_DEFINITIONS(-DDISABLE_INIT) ELSE() ADD_EXECUTABLE(init initd/init.c initd/early.c initd/preinit.c initd/mkdev.c sysupgrade.c watchdog.c utils/utils.c) TARGET_INCLUDE_DIRECTORIES(init PUBLIC ${SELINUX_INCLUDE_DIRS}) TARGET_LINK_LIBRARIES(init ${LIBS} ${SELINUX_LIBRARIES}) INSTALL(TARGETS init RUNTIME DESTINATION ${CMAKE_INSTALL_SBINDIR} ) procd 启动流程 /sbin/init main 函数入口位于 procd/initd/init.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 int main(int argc, char **argv) { pid_t pid; ulog_open(ULOG_KMSG, LOG_DAEMON, \u0026#34;init\u0026#34;); sigaction(SIGTERM, \u0026amp;sa_shutdown, NULL); sigaction(SIGUSR1, \u0026amp;sa_shutdown, NULL); sigaction(SIGUSR2, \u0026amp;sa_shutdown, NULL); sigaction(SIGPWR, \u0026amp;sa_shutdown, NULL); if (selinux(argv)) exit(-1); early(); cmdline(); watchdog_init(1); pid = fork(); if (!pid) { char *kmod[] = { \u0026#34;/sbin/kmodloader\u0026#34;, \u0026#34;/etc/modules-boot.d/\u0026#34;, NULL }; if (debug \u0026lt; 3) patch_stdio(\u0026#34;/dev/null\u0026#34;); execvp(kmod[0], kmod); ERROR(\u0026#34;Failed to start kmodloader: %m\\n\u0026#34;); exit(EXIT_FAILURE); } if (pid \u0026lt;= 0) { ERROR(\u0026#34;Failed to start kmodloader instance: %m\\n\u0026#34;); } else { const struct timespec req = {0, 10 * 1000 * 1000}; int i; for (i = 0; i \u0026lt; 1200; i++) { if (waitpid(pid, NULL, WNOHANG) \u0026gt; 0) break; nanosleep(\u0026amp;req, NULL); watchdog_ping(); } } uloop_init(); preinit(); uloop_run(); return 0; } kmodloader 先启动的是kmodloader(实现于openwrt/ubox/kmodloader.c),会insmod位于/etc/modules.d/下的kernel module list\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 static int main_loader(int argc, char **argv) { int gl_flags = GLOB_NOESCAPE | GLOB_MARK; char *dir = \u0026#34;/etc/modules.d/\u0026#34;; struct module_node *mn; struct module *m; glob_t gl; char *path; int ret = 0, fail, j; if (argc \u0026gt; 1) dir = argv[1]; path = malloc(strlen(dir) + 2); if (!path) { ULOG_ERR(\u0026#34;out of memory\\n\u0026#34;); return -1; } strcpy(path, dir); strcat(path, \u0026#34;*\u0026#34;); if (scan_module_folders()) { ret = -1; goto free_path; } if (scan_loaded_modules()) { ret = -1; goto free_path; } ULOG_INFO(\u0026#34;loading kernel modules from %s\\n\u0026#34;, path); ...... } int main(int argc, char **argv) { char *exec = basename(*argv); avl_init(\u0026amp;modules, avl_modcmp, true, NULL); if (!strcmp(exec, \u0026#34;insmod\u0026#34;)) return main_insmod(argc, argv); if (!strcmp(exec, \u0026#34;rmmod\u0026#34;)) return main_rmmod(argc, argv); if (!strcmp(exec, \u0026#34;lsmod\u0026#34;)) return main_lsmod(argc, argv); if (!strcmp(exec, \u0026#34;modinfo\u0026#34;)) return main_modinfo(argc, argv); load_options(); if (!strcmp(exec, \u0026#34;modprobe\u0026#34;)) return main_modprobe(argc, argv); ulog_open(ULOG_KMSG, LOG_USER, \u0026#34;kmodloader\u0026#34;); return main_loader(argc, argv); } uloop_init实现位于libubox源码uloop.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 int uloop_init(void) { if (uloop_init_pollfd() \u0026lt; 0) return -1; if (waker_init() \u0026lt; 0) { uloop_done(); return -1; } return 0; } static int uloop_init_pollfd(void) { if (poll_fd \u0026gt;= 0) return 0; poll_fd = epoll_create(32); if (poll_fd \u0026lt; 0) return -1; fcntl(poll_fd, F_SETFD, fcntl(poll_fd, F_GETFD) | FD_CLOEXEC); return 0; } preinit实现位于procd源码文件initd/preinit.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 static struct uloop_process preinit_proc; static struct uloop_process plugd_proc; void preinit(void) { char *init[] = { \u0026#34;/bin/sh\u0026#34;, \u0026#34;/etc/preinit\u0026#34;, NULL }; char *plug[] = { \u0026#34;/sbin/procd\u0026#34;, \u0026#34;-h\u0026#34;, \u0026#34;/etc/hotplug-preinit.json\u0026#34;, NULL }; int fd; LOG(\u0026#34;- preinit -\\n\u0026#34;); plugd_proc.cb = plugd_proc_cb; plugd_proc.pid = fork(); if (!plugd_proc.pid) { execvp(plug[0], plug); ERROR(\u0026#34;Failed to start plugd: %m\\n\u0026#34;); exit(EXIT_FAILURE); } if (plugd_proc.pid \u0026lt;= 0) { ERROR(\u0026#34;Failed to start new plugd instance: %m\\n\u0026#34;); return; } uloop_process_add(\u0026amp;plugd_proc); setenv(\u0026#34;PREINIT\u0026#34;, \u0026#34;1\u0026#34;, 1); fd = creat(\u0026#34;/tmp/.preinit\u0026#34;, 0600); if (fd \u0026lt; 0) ERROR(\u0026#34;Failed to create sentinel file: %m\\n\u0026#34;); else close(fd); preinit_proc.cb = spawn_procd; preinit_proc.pid = fork(); if (!preinit_proc.pid) { execvp(init[0], init); ERROR(\u0026#34;Failed to start preinit: %m\\n\u0026#34;); exit(EXIT_FAILURE); } if (preinit_proc.pid \u0026lt;= 0) { ERROR(\u0026#34;Failed to start new preinit instance: %m\\n\u0026#34;); return; } uloop_process_add(\u0026amp;preinit_proc); DEBUG(4, \u0026#34;Launched preinit instance, pid=%d\\n\u0026#34;, (int) preinit_proc.pid); } 创建子进程执行 /sbin/procd -h /etc/hotplug-preinit.json ，主进程同时使用 uloop_process_add()把 /sbin/procd 子进程加入 uloop 进行监控，当 /sbin/procd 进程结束时回调 plugd_proc_cb 函数。 创建子进程执行 /etc/preinit 脚本，此时 PREINIT环境变量被设置为1，主进程同时使用 uloop_process_add() 把/etc/preinit 子进程加入 uloop 进行监控，当 /etc/preinit 执行结束时回调 spawn_procd函数 spawn_procd()函数繁行后继真正使用的 /sbin/procd 进程，从 /tmp/debuglevel 读出 debug 级别并设置到环境变量 DBGLVL 中，把 watchdog fd 设置到环境变量 WDTFD 中，最后调用 execvp()繁行 /sbin/procd 进程 首先看procd，因为带有参数“-h /etc/hotplug-preinit.json”，所以会执行hotplug_run函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 int main(int argc, char **argv) { int ch; char *dbglvl = getenv(\u0026#34;DBGLVL\u0026#34;); int ulog_channels = ULOG_KMSG; if (dbglvl) { debug = atoi(dbglvl); unsetenv(\u0026#34;DBGLVL\u0026#34;); } while ((ch = getopt(argc, argv, \u0026#34;d:s:h:S\u0026#34;)) != -1) { switch (ch) { case \u0026#39;h\u0026#39;: return hotplug_run(optarg); // hotplug case \u0026#39;s\u0026#39;: ubus_socket = optarg; break; case \u0026#39;d\u0026#39;: debug = atoi(optarg); break; case \u0026#39;S\u0026#39;: ulog_channels = ULOG_STDIO; break; default: return usage(argv[0]); } } ulog_open(ulog_channels, LOG_DAEMON, \u0026#34;procd\u0026#34;); ulog_threshold(LOG_DEBUG + 1); setsid(); uloop_init(); procd_signal(); procd_udebug_set_enabled(true); if (getpid() != 1) procd_connect_ubus(); else procd_state_next(); uloop_run(); uloop_done(); return 0; } hotplug实现如下，这里是建立netlink通信机制，完成用户层和内核的交互，监听内核的uevent事件。\nprocd/plug/hotplug.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 void hotplug(char *rules) { struct sockaddr_nl nls; int nlbufsize = 512 * 1024; rule_file = strdup(rules); memset(\u0026amp;nls,0,sizeof(struct sockaddr_nl)); nls.nl_family = AF_NETLINK; nls.nl_pid = getpid(); nls.nl_groups = -1; if ((hotplug_fd.fd = socket(PF_NETLINK, SOCK_DGRAM | SOCK_CLOEXEC, NETLINK_KOBJECT_UEVENT)) == -1) { ERROR(\u0026#34;Failed to open hotplug socket: %s\\n\u0026#34;, strerror(errno)); exit(1); } if (bind(hotplug_fd.fd, (void *)\u0026amp;nls, sizeof(struct sockaddr_nl))) { ERROR(\u0026#34;Failed to bind hotplug socket: %s\\n\u0026#34;, strerror(errno)); exit(1); } if (setsockopt(hotplug_fd.fd, SOL_SOCKET, SO_RCVBUFFORCE, \u0026amp;nlbufsize, sizeof(nlbufsize))) ERROR(\u0026#34;Failed to resize receive buffer: %s\\n\u0026#34;, strerror(errno)); json_script_init(\u0026amp;jctx); queue_proc.cb = queue_proc_cb; uloop_fd_add(\u0026amp;hotplug_fd, ULOOP_READ); } int hotplug_run(char *rules) { uloop_init(); hotplug(rules); uloop_run(); return 0; } 内核发出uevent事件 内核使用 uevent 事件通知用户空间， uevent 首先在内核中调用 netink_kemel_create() 函数创建一个 socket 套接字，该函数原型在 netink.h 中定义。这是一种特殊类型的 socket ，专门用于内核空间与用户空间的异步通信。kobject_uevent()产生uevent 事件 (/lib/kobject_uevent.c)，事件的部分信息通过环境变量传递，如$ACTION,$DEVPATH,$SUBSYSTEM 等，产生的 uevent 先由 netlink_broadcast_filtered()发出，最后调用uevent helper 所指定的程序来处理。在linux 中，uevent_helper 里默认指定\u0026quot;/sbin/hotplug”，但可以通过 /sys/kemel/uevent helper (kernel/ksysfs.c) /proc/kernel/uevent_elper(kernel/sysctl.c)来修改成指定的程序。在新 OpenWRT 中，并不使用 user helper 指定程序来处理 uevent(/sbin/hotplug 不存在，在以前版本中存在)，而是通过PF_NETLINK套接字来获取来自内核空间的 uevent 。 用户空间监听uevent 在 procd/plug/hotplug.c 中，创建一个 PF_NETLINK 套接字来监听内核 netlink_broadcast_fitered() 发出的 uevent 。收到uevent 之后，在根据 /etc/hotplug.json 里的描述，定位到对应的执行函数来处理.通常情况下， /etc/hotplug.json 会调用 /sbin/hotplug-call 来处理 uevent ，它根据 uevent 的 $SUBSYSTEM 变量来分别调用 /etc/hotplug.d 下不同目录中的脚本。 /etc/preinit脚本大致内容如下，先调用另外的shell脚本，获取函数定义\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 . /lib/functions.sh . /lib/functions/preinit.sh . /lib/functions/system.sh # 初始化hook链 boot_hook_init preinit_essential boot_hook_init preinit_main boot_hook_init failsafe boot_hook_init initramfs # 依次执行/lib/preinit目录中的脚本，将函数调用添加到hook链中 for pi_source_file in /lib/preinit/*; do . $pi_source_file done # 执行preinit_essential注册的hook链的所有函数 boot_run_hook preinit_essential # 执行preinit_main注册的hook链的所有函数 boot_run_hook preinit_main /etc/preinit脚本执行完成后，调用spawn_procd,spawn_procd会调用 execvp()执行 /sbin/procd进程\nprocd/initd/preinit.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 spawn_procd(struct uloop_process *proc, int ret) { char *wdt_fd = watchdog_fd(); char *argv[] = { \u0026#34;/sbin/procd\u0026#34;, NULL}; char dbg[2]; if (plugd_proc.pid \u0026gt; 0) kill(plugd_proc.pid, SIGKILL); unsetenv(\u0026#34;PREINIT\u0026#34;); unlink(\u0026#34;/tmp/.preinit\u0026#34;); check_sysupgrade(); DEBUG(2, \u0026#34;Exec to real procd now\\n\u0026#34;); if (wdt_fd) setenv(\u0026#34;WDTFD\u0026#34;, wdt_fd, 1); check_dbglvl(); if (debug \u0026gt; 0) { snprintf(dbg, 2, \u0026#34;%d\u0026#34;, debug); setenv(\u0026#34;DBGLVL\u0026#34;, dbg, 1); } execvp(argv[0], argv); } procd/procd.c中\n1 2 3 4 5 6 7 8 9 10 setsid(); uloop_init(); procd_signal(); procd_udebug_set_enabled(true); if (getpid() != 1) procd_connect_ubus(); else procd_state_next(); uloop_run(); uloop_done(); 此时getpid()等于1，所以调用procd_state_next，进入到状态机处理中。\nprocd_state不断迁移，包括STATE_EARLY，STATE_UBUS，STATE_INIT等。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 [ 3.161338@3] init: Console is alive [ 3.173921@3] init: Ping [ 3.184207@3] init: Ping [ 3.192558@1] kmodloader: loading kernel modules from /etc/modules-boot.d/* [ 3.194447@3] init: Ping [ 3.196209@1] kmodloader: done loading kernel modules from /etc/modules-boot.d/* [ 3.204716@3] init: Ping [ 3.206180@3] init: - preinit - [ 3.208671@3] init: Launched preinit instance, pid=1308 [ 3.302967@3] init: Exec to real procd now [ 3.308865@3] procd: - early - [ 3.524654@2] procd: Finished udevtrigger [ 4.024929@2] procd: Coldplug complete [ 4.028061@2] procd: - ubus - [ 4.029198@2] procd: Create service ubus [ 4.030829@2] procd: Create instance ubus::instance1 [ 4.032109@2] procd: Started instance ubus::instance1[1554] [ 4.098895@2] procd: Connected to ubus, id=459ede6c [ 4.099092@2] procd: - init - [ 4.102474@2] procd: Launched new askconsole action, pid=1555 [ 4.104142@2] procd: Launched new askfirst action, pid=1556 以STATE_INIT为例，执行procd_inittab_run(\u0026ldquo;xxx\u0026rdquo;)会调用对应handlers的callback，对应所有的init_action是在procd_inittab()中添加的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 case STATE_INIT: LOG(\u0026#34;- init -\\n\u0026#34;); procd_inittab(); procd_inittab_run(\u0026#34;respawn\u0026#34;); procd_inittab_run(\u0026#34;askconsole\u0026#34;); procd_inittab_run(\u0026#34;askfirst\u0026#34;); procd_inittab_run(\u0026#34;sysinit\u0026#34;); static struct init_handler handlers[] = { { .name = \u0026#34;sysinit\u0026#34;, .cb = runrc, }, { .name = \u0026#34;shutdown\u0026#34;, .cb = runrc, }, { .name = \u0026#34;askfirst\u0026#34;, .cb = askfirst, .multi = 1, }, { .name = \u0026#34;askconsole\u0026#34;, .cb = askconsole, .multi = 1, }, { .name = \u0026#34;respawn\u0026#34;, .cb = rcrespawn, .multi = 1, } }; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 static const char *tab = \u0026#34;/etc/inittab\u0026#34;; static char *ask = \u0026#34;/sbin/askfirst\u0026#34;; static int add_action(struct init_action *a, const char *name) { int i; for (i = 0; i \u0026lt; ARRAY_SIZE(handlers); i++) if (!strcmp(handlers[i].name, name)) { a-\u0026gt;handler = \u0026amp;handlers[i]; list_add_tail(\u0026amp;a-\u0026gt;list, \u0026amp;actions); return 0; } ERROR(\u0026#34;Unknown init handler %s\\n\u0026#34;, name); return -1; } void procd_inittab(void) { #define LINE_LEN 128 FILE *fp = fopen(tab, \u0026#34;r\u0026#34;); struct init_action *a; regex_t pat_inittab; regmatch_t matches[5]; char *line; if (!fp) { ERROR(\u0026#34;Failed to open %s: %m\\n\u0026#34;, tab); return; } regcomp(\u0026amp;pat_inittab, \u0026#34;([a-zA-Z0-9]*):([a-zA-Z0-9]*):([a-zA-Z0-9]*):(.*)\u0026#34;, REG_EXTENDED); line = malloc(LINE_LEN); a = calloc(1, sizeof(struct init_action)); while (fgets(line, LINE_LEN, fp)) { char *tags[TAG_PROCESS + 1]; char *tok; int i; int len = strlen(line); while (isspace(line[len - 1])) len--; line[len] = 0; if (*line == \u0026#39;#\u0026#39;) continue; if (regexec(\u0026amp;pat_inittab, line, 5, matches, 0)) continue; DEBUG(4, \u0026#34;Parsing inittab - %s\\n\u0026#34;, line); for (i = TAG_ID; i \u0026lt;= TAG_PROCESS; i++) { line[matches[i].rm_eo] = \u0026#39;\\0\u0026#39;; tags[i] = \u0026amp;line[matches[i + 1].rm_so]; }; tok = strtok(tags[TAG_PROCESS], \u0026#34; \u0026#34;); for (i = 0; i \u0026lt; (MAX_ARGS - 1) \u0026amp;\u0026amp; tok; i++) { a-\u0026gt;argv[i] = tok; tok = strtok(NULL, \u0026#34; \u0026#34;); } a-\u0026gt;argv[i] = NULL; a-\u0026gt;id = tags[TAG_ID]; a-\u0026gt;line = line; if (add_action(a, tags[TAG_ACTION])) continue; line = malloc(LINE_LEN); a = calloc(1, sizeof(struct init_action)); } fclose(fp); free(line); free(a); regfree(\u0026amp;pat_inittab); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 void procd_inittab_run(const char *handler) { struct init_action *a; list_for_each_entry(a, \u0026amp;actions, list) { if (!strcmp(a-\u0026gt;handler-\u0026gt;name, handler)) { if (a-\u0026gt;handler-\u0026gt;multi) { a-\u0026gt;handler-\u0026gt;cb(a); continue; } a-\u0026gt;handler-\u0026gt;cb(a); break; } } } /etc/inittab\n1 2 3 ::sysinit:/etc/init.d/rcS S boot ::shutdown:/etc/init.d/rcS K shutdown ::askconsole:/usr/libexec/login.sh 这里来看runrc的实现，代码位于inittab.c\n1 2 3 4 5 6 7 8 9 10 11 static void runrc(struct init_action *a) { if (!a-\u0026gt;argv[1] || !a-\u0026gt;argv[2]) { ERROR(\u0026#34;valid format is rcS \u0026lt;S|K\u0026gt; \u0026lt;param\u0026gt;\\n\u0026#34;); return; } /* proceed even if no init or shutdown scripts run */ if (rcS(a-\u0026gt;argv[1], a-\u0026gt;argv[2], rcdone)) rcdone(NULL); } rcS.c\n1 2 3 4 5 6 7 8 int rcS(char *pattern, char *param, void (*q_empty)(struct runqueue *)) { runqueue_init(\u0026amp;q); q.empty_cb = q_empty; q.max_running_tasks = 1; return _rc(\u0026amp;q, \u0026#34;/etc/rc.d\u0026#34;, pattern, \u0026#34;*\u0026#34;, param); } 执行/etc/rc.d目录下S开头的脚本\n","date":"2025-07-30T18:28:23+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/openwrt-procd%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90/","title":"openwrt procd启动流程分析"},{"content":"OverlayFS 原理及应用场景 1. OverlayFS 概述 OverlayFS 是 Linux 内核中的一种联合挂载文件系统，它允许将多个目录层叠在一起，形成一个单一的、统一的文件系统视图。其主要特点是轻量级、高性能，并且不需要额外的存储空间来创建合并后的视图。OverlayFS 从 Linux 3.18 版本开始被正式合并到主线内核中。\n2. OverlayFS 工作原理 2.1 基本结构 OverlayFS 使用了三个主要的概念：\nLower 层：只读层，可以有多个（在较新的内核版本支持） Upper 层：可读写层，只能有一个 Merged 层：合并视图，用户看到并操作的统一视图 当挂载 OverlayFS 时，lower 和 upper 层被合并成一个统一的文件系统视图。\n2.2 文件操作原理 读取操作 当读取文件时，如果文件在 upper 层存在，则直接读取 upper 层的文件；如果不存在，则从 lower 层读取。\n写入操作 当修改一个文件时，OverlayFS 采用写时复制（Copy-On-Write，COW）策略：\n如果文件已在 upper 层存在，则直接修改 如果文件仅在 lower 层存在，则先将其复制到 upper 层，再进行修改 对文件的删除操作也是在 upper 层创建一个特殊的删除标记（whiteout） 2.3 目录合并 目录的处理略有不同：\n列出目录内容时，会合并显示 lower 和 upper 层中的所有文件和子目录 如果同名文件/目录同时存在于两层，则 upper 层的版本会覆盖 lower 层的版本 3. OverlayFS 的关键特性 轻量级：不需要额外的磁盘空间来存储合并视图 高性能：相比其他联合挂载文件系统，有更好的性能表现 透明性：对应用程序完全透明，应用无需感知底层文件系统的复杂性 灵活性：可以根据需要组合不同的文件系统 4. 应用场景 4.1 容器技术 OverlayFS 是 Docker、Podman 等容器技术的主要存储驱动之一：\n基础镜像作为只读的 lower 层 容器运行时的可写层作为 upper 层 多个容器可以共享相同的基础层，节省存储空间和提高启动速度 4.2 实时系统 可以将只读的系统文件作为 lower 层，临时的运行时数据作为 upper 层 系统重启后，上层的更改会丢失，系统恢复到初始状态 4.3 嵌入式系统 在资源受限的嵌入式系统中，可以将只读的固件作为 lower 层 用户数据和配置作为 upper 层存储在可写介质上 4.4 系统升级 将当前系统作为 lower 层，升级内容作为 upper 层 如果升级出现问题，可以轻松回滚到原始状态 ","date":"2025-07-29T09:52:54+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/overlayfs/","title":"OverlayFS"},{"content":"LXC (Linux 容器) 工作原理详解 LXC (Linux Containers) 是一种操作系统级别的虚拟化技术，它允许在单个 Linux 内核上运行多个隔离的 Linux 系统（容器）。与虚拟机（VM）不同，LXC 不需要模拟硬件，因此它非常轻量级且启动速度快。\nLXC 的核心是利用 Linux 内核的两个关键特性：命名空间 (Namespaces) 和 控制组 (Cgroups)。\nNamespaces：负责隔离，确保一个容器中的进程看不到或影响到另一个容器或宿主机的进程、网络、文件系统等。 Cgroups：负责资源限制和审计，确保每个容器只能使用分配给它的 CPU、内存、I/O 等资源。 本文将重点详细介绍几个关键的命名空间。\n1. PID 命名空间 (PID Namespace) PID (Process ID) 命名空间用于隔离进程 ID。\n原理 隔离进程树：每个 PID 命名空间都有一套独立的进程 ID，从 1 开始。 容器的 init 进程：在一个新的 PID 命名空间中创建的第一个进程会成为该空间的 \u0026ldquo;init\u0026rdquo; 进程，其 PID 为 1。这个进程负责管理容器内的所有其他进程（例如，处理孤儿进程）。如果这个 PID 为 1 的进程终止，内核将终止该命名空间中的所有其他进程。 内外 PID 映射：容器内的进程在容器内部有自己的 PID（例如，PID 1, 2, 3\u0026hellip;），同时在宿主机上也有一个全局唯一的 PID。这意味着从宿主机看，所有容器的进程都是普通的进程，只是被 PID 命名空间隔离开来。 示例 假设我们在宿主机上启动一个 LXC 容器，并在容器内运行 bash。\n容器内视角:\n1 2 3 4 5 6 # 在容器内执行 ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.1 0.0 2384 1596 ? Ss 10:00 0:00 /sbin/init root 15 0.0 0.0 4372 3480 pts/0 Ss 10:01 0:00 bash root 25 0.0 0.0 5924 1788 pts/0 R+ 10:02 0:00 ps aux 在这里，init 进程的 PID 是 1，bash 的 PID 是 15。\n宿主机视角:\n1 2 3 4 # 在宿主机执行 ps aux | grep bash # 输出可能像这样 root 12345 0.0 0.0 4372 3480 pts/0 Ss 10:01 0:00 bash 在宿主机上，同一个 bash 进程的 PID 可能是 12345。这种隔离使得容器内的进程管理与宿主机完全分离。\n2. 网络命名空间 (Network Namespace) 网络命名空间为每个容器提供了一个完全独立的网络协议栈。\n原理 独立网络栈：每个网络命名空间都有自己独立的网络设备（如 lo, eth0）、IP 地址、路由表、iptables 防火墙规则、端口号等。一个容器默认无法访问另一个容器或宿主机的网络。 veth 设备对：为了让容器能与外部通信，LXC 通常使用 veth (Virtual Ethernet) 设备对。veth 设备总是成对出现，像一根虚拟网线。数据从一端进入，会从另一端出来。 连接过程: 创建一对 veth 设备，例如 veth_host 和 veth_container。 将 veth_host 留在宿主机的网络命名空间中。 将 veth_container \u0026ldquo;移动\u0026rdquo; 到容器的网络命名空间中，并将其重命名为 eth0。 在宿主机上，通常会创建一个网桥（例如 lxcbr0），并将 veth_host 端连接到这个网桥上。 为容器内的 eth0 分配 IP 地址。 数据流: 容器内 eth0 发出的网络包 -\u0026gt; 通过 veth 对到达宿主机的 veth_host -\u0026gt; 进入宿主机的网桥 lxcbr0 -\u0026gt; 通过宿主机的物理网卡和路由规则与外部网络通信。 这种结构使得每个容器都像一台独立的机器连接到了一个虚拟交换机（网桥）上，实现了网络隔离和互联。\n3. 文件系统命名空间 (Mount Namespace) 文件系统（挂载）命名空间允许每个容器拥有自己独立的文件系统视图，尤其是独立的根目录 (/)。\n原理 隔离挂载点：每个挂载命名空间维护着一个独立的挂载点列表。在一个命名空间中的 mount() 和 umount() 操作不会影响到其他命名空间。 独立的根文件系统 (rootfs)：LXC 利用这个特性为每个容器创建一个独立的根文件系统。容器进程看到的文件系统层次结构与宿主机完全不同。 实现方式: 准备 rootfs：首先，需要为容器准备一个目录，其中包含一个完整的 Linux 系统所需的文件和目录（如 /bin, /etc, /lib, /usr 等）。这通常通过复制一个最小化的系统模板来完成。 pivot_root 系统调用：为了将容器的根目录切换到准备好的 rootfs，LXC 使用 pivot_root 系统调用（或者在某些情况下使用 chroot，但 pivot_root 更强大、更安全）。pivot_root 会将当前进程的根文件系统切换到一个新的挂载点，同时将旧的根文件系统挂载到新根下的一个指定目录中，之后可以将其卸载。 隔离挂载：在容器启动后，它可以在自己的文件系统命名空间内自由地挂载其他设备或文件系统（如 proc, sysfs, tmpfs），而这些挂载对宿主机是不可见的。 通过这种方式，容器内的进程被\u0026quot;囚禁\u0026quot;在其自己的文件系统视图中，无法访问或修改宿主机的文件系统（除非特别配置了绑定挂载 bind mount）。\n其他命名空间 除了以上三个，LXC 还使用了其他命名空间来实现全方位隔离：\nUTS Namespace: 隔离主机名和域名。 IPC Namespace: 隔离进程间通信资源，如 System V IPC 和 POSIX 消息队列。 User Namespace: 隔离用户和组 ID。允许容器内的 root 用户（UID 0）映射为宿主机上的一个非特权用户，极大地提升了安全性。 Cgroup Namespace: 隔离控制组视图。 总结 LXC 通过精巧地组合使用 Linux 内核的 Namespaces 和 Cgroups 特性，为用户提供了一个轻量级、高效且隔离性良好的容器环境。PID、网络和文件系统命名空间是实现这种隔离的基础，它们分别创建了独立的进程树、网络协议栈和文件系统视图，使得容器内的环境看起来就像一个独立的操作系统。\n","date":"2025-07-28T20:00:08+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/lxc%E8%AF%A6%E8%A7%A3/","title":"LXC详解"},{"content":"对称加密 加密前的原始数据，叫做 原文（ original text ），或者 明文（ plain text ）； 加密后的不规则（ scrambled ）数据，通常叫做 密文（ cipher text ）； 加密所用的密码，通常叫做 密钥（ secret key ）； 对称加密（symmetric encryption）算法最大的特点是，它只有一把密钥，加密和解密过程用的都是同一把密钥，这也符合大众对加密算法的认知，用密码对数据进行加密之后，必须用同一个密码才能将数据解密出来\nAES ，高级加密标准，新一代加密算法标准，速度快，安全级别高； DES ，数据加密标准，速度较快，适用于加密大量数据，但安全性较弱； Blowfish ，使用变长密钥，运行速度很快，非专利算法，没有使用限制； etc 非对称加密 从前有一个黑帮，老大和手下们之间的通信必须加密确保安全。于此同时，老大希望手下发给他的信息，不能被其他手下知晓。若采用对称加密算法，只能给每个手下都分配一个独立的密钥，但老大觉得太麻烦了。该怎么办呢？\n黑帮老大希望他只维护一份密钥，就能达到这样的效果，有办法做到吗？\n可以用非对称加密（asymmetric encryption）\n非对称加密，顾明思议，在加密和解密环节用的密钥是不同的。\n非对称加密算法需要两把不同的密钥，这两把密钥组成一对：\n公钥（ public key ），公钥用来对数据进行 加密 ； 私钥（ private key ），也称为 密钥（ secret key ），用来对数据进行 解密 ； 公钥和私钥总是成对出现，用公钥加密后得到的密文，必须用对应的私钥才能解密； 这套加密机制完美解决了黑帮老大的难题，他只需要生成一对密钥：公钥分发给手下们，他们先用公钥加密信息，再发老大；老大接到密文，就用自己保管的私钥来解密；手下们就算拿到别人发的密文也解不开，因为私钥只有他们老大才有。\n数学原理 公钥和私钥的加密机制看起来非常不可思议，这一切其实来一个神奇的数学原理。\n我们来做一个数字游戏，您随便写下一个整数 m （1\u0026lt;m\u0026lt;7387 ），然后计算m ^3 mod 7387 并把结果告诉我，我就知道您写下的整数 m 是什么\n1 2 3 4 5 6 7 8 9 10 11 # 520 \u0026gt;\u0026gt;\u0026gt; 520 ** 3 % 7387 3842 \u0026gt;\u0026gt;\u0026gt; 3842 ** 4811 % 7387 520 # 1314 \u0026gt;\u0026gt;\u0026gt; 1314 ** 3 % 7387 7382 \u0026gt;\u0026gt;\u0026gt; 7382 ** 4811 % 7387 1314 公钥参数 3 和 7387 ，私钥参数 4811 和 7387 又是怎么生成的呢？ 第一步，随机选择两个质数 p 和 q ： p = 83 q = 89 第二步，计算 p 和 q 的乘积 n ： n = p * q = 7387 第三步，计算 n 的欧拉函数 ，记为 phi ： φ(n) = (p-1) * (q-1) = 7216 第四步，随机选择一个整数 e ，满足1\u0026lt;e\u0026lt;φ(n)，且 e 和φ(n)互质： 选一个质数 e ，使得不能被 e 整除即可。 第五步，计算 e 对φ(n)的模反元素 d ，即找到一个数 d 使得 ed 除以φ(n)的余数为 1 ： ed ≡ 1 mod(φ ( n )) \u0026lt;=\u0026gt; ed = kφ(n) + 1 可以找到一个d :4811\n安全性分析 那么，有无可能在已知n和e的情况下，推导出d？\n1 2 3 ed≡1 (mod φ(n))。只有知道e和φ(n)，才能算出d。 φ(n)=(p-1)(q-1)。只有知道p和q，才能算出φ(n)。 n=pq。只有将n因数分解，才能算出p和q。 大整数的因数分解，是一件非常困难的事情\n目前，能够被破解的 n 最大位数是 768 位(这里提到的位是指二进制位)，因此有人开始质疑 1024 位密钥的安全性。现在推荐的密钥长度至少要 2048 位，只要长度足够，安全性完全不用担心\n应用场景 加密 公钥加密私钥解密是非对称加密算法最典型的应用场景，特别适用于密钥需要公开的场景，比如 传输层安全协议 TLS ，它为通讯双方提供可靠的加密连接\n如果没有非对称加密算法，TLS 将无法实现。因为对称加密算法要求双方使用同一密钥，加密连接建立之前，只能明文协商密钥。试想浏览器想跟服务器建立安全连接，无论是它选定密钥然后发给服务器，还是服务器选定密钥发给它，只要密钥经过明文传输，加密就失去意义。\n有了非对称加密算法，服务器可以生成一对密钥，私钥自己保管，公钥可以公开。当浏览器请求建立加密连接时，服务器可以将公钥发给浏览器，因为公钥是可以公开的。浏览器将敏感信息用公钥加密后再发给浏览器，只有掌握私钥的服务器才能解密，他人便无法知晓。\n同理，服务器想发敏感信息给客户端，必须由客户端生成的公钥加密。换句话讲，每对密钥解决一个方向的加密问题，通讯双方都需要生成自己的密钥对，负责加密对方发来的数据。\n由于非对称加密算法运算复杂，加密效率不高，通常只是用来加密少量的关键信息，比如协商密钥。回到 TLS 这个例子，其实可以借助非对称加密算法协商密钥，从而直接使用更高效的对称加密算法来加密数据：\n服务器生成公钥和私钥 对； 客户端（浏览器）连接上来后，服务器将公钥发给客户端； 客户端随机生成一个用于对称加密（ AES ）的密钥； 客户端用公钥对生成的密钥进行加密，然后后发给服务器； 服务器收到客户端用公钥加密的密钥后，用自己的私钥解密，至此密钥协商完毕； 由于私钥只有服务器才有，因此第三方无法知晓客户端选定的密钥是啥； 此后通信双方采用对称加密，以该密钥加密数据； 签名 实际上，私钥也可以用来加密数据，加密后的密文只有公钥才能解密。尽管如此，由于公钥是公开的，因此这个机制不能来加密数据，但可以对用来对数据进行签名防伪。\n数字证书(certificate) 信息摘要（ digest ），数据经过哈希算法得到的一串哈希值，代表数据的特征，也称为数据指纹； 摘要算法 ，可以把任意长度的数据，映射成一个定长的字符串（哈希值）； 由于哈希冲突的存在，两份不同的数据，有可能算出相同的摘要值； 摘要算法无法用于数据加密，通常用来校验数据完整性，即 数据防伪 ； 常见的摘要算法有：MD5 、SHA1 、SHA256 、SHA512 。 数字签名（ signature ），摘要由私钥加密后，得到的摘要密文就是数字签名； 签名，由数据发送方生成，这是一个 加密 过程（使用私钥）； 验签，由数据接收方校验，这是一个 解密 过程（使用公钥）； 数字签名只能由私钥生成，因此第三方无法伪造； 在介绍密钥协商时，我们提到服务器先将公钥发给客户端，用公钥保护对称加密密钥，确保通信内容不会被第三方获悉。但如果客户端连接的服务器是假的呢？如果用户对假网站信以为真，输入了账号密码，那么这些敏感信息都会被假网站窃取！\n上节我们也讨论了数字签名，通过它可以实现数据防伪。那么，我们是不是可以利用这项技术来甄别仿冒站点呢\n权威机构生成一对密钥，并提供站点认证审核和数字签名颁发服务； 站点管理员将站点信息，包括域名、运营单位、公钥等信息发给权威机构审核； 权威机构对提交上来的站点信息进行审核，审核通过则用私钥签名后返回给站点管理员； 客户端（浏览器）连接站点服务器，服务器将站点信息以及对应的数字签名发给客户端； 客户端用权威机构提供的公钥来校验数字签名，即可判断站点信息的真伪性； 签名验证通过，客户端从站点信息中取出公钥，与服务端协商密钥，发起加密通信； 由于签名用的私钥只有权威机构掌握，黑客无法伪造数字签名，也就无法架设仿冒站点； 权威机构必须由可信的单位运营； 你可能会觉得，黑客直接盗用站点信息和签名不就可以伪造原站点了嘛？此言差矣！因为公钥属于站点信息\n的一 部分，也会参与签名！客户端和服务端协商密钥时，会使用这个公钥加密密钥。由于黑客不掌握站点私 钥，因此 加密连接无法建立！黑客把公钥替换成自己的吧，签名就不对，肯定会被验出来！\n证书签发实验 CA权威机构 首先，权威机构需要生成一对密钥，cakey.pem 是私钥,\n1 openssl genrsa -out cakey.pem 2048 然后，生成根证书签发申请文件（ csr 文件）：\n1 openssl req -new -key cakey.pem -out ca.csr -subj \u0026#39;/C=CN/ST=Guangdong/L=Guangzhou/O=coding-fans/OU=CA/CN=ca.fasionchan.com\u0026#39; 证书申请文件包含权威机构的信息，包括机构信息(Subject )和公钥(Public Key 部分)可以用下面命令查看：\n1 openssl req -in ca.csr -text -noout 最后，自签根证书（ cer 文件 ）：\n1 openssl x509 -req -days 3650 -sha1 -extensions v3_ca -signkey cakey.pem -in ca.csr -out ca.cer 这一步生成的 cer 文件就是根证书文件，它的主要作用是承载权威机构公钥，以便预装在操作系统或者其他终端。它同样会包含权威机构的信息，公钥，以及对应的签名。\n商业站点（服务端） 首先，站点管理员生成一对密钥\n1 openssl genrsa -out sitekey.pem 2048 然后，生成证书签发申请文件（ csr 文件）：\n1 openssl req -new -key sitekey.pem -out site.csr -subj \u0026#39;/C=CN/ST=Guangdong/L=Guangzhou/O=fasionchan/OU=website/CN=fasionchan.co 证书申请文件包含站点信息和公钥，站点管理员将证书申请文件发给权威机构审核，\n权威机构对申请进行审核，审核通过则用自己的私钥对它进行签名，生成证书(cer 文件):\n1 openssl x509 -req -days 365 -sha1 -extensions v3_req -CA ca.cer -CAkey cakey.pem -CAserial ca.srl -CAcreateserial -in site.csr -out site.cer 证书中保存着包括公钥在内的站点信息，以及权威机构对这些信息的签名。管理员接到权威机构颁发的证书，就可以部署网站了\n浏览器（客户端） 客户端浏览器访问站点，服务端会将其证书发给客户端。客户端先对证书签名进行验证，步骤如下：\n重新对证书中的站点信息计算 摘要值 ； 用公钥对证书中的签名进行解密，得到证书的原始摘要值； 公钥通常由根证书提供，根证书通常预装在系统里； 对比两个摘要值看是否一致； 调用 openssl 工具，一行命令即可完成签名验证\n1 openssl verify -CAfile ca.cer site.cer 总结 数字证书是支撑互联网身份认证的重要技术手段，可以简单理解成经过 CA 权威结构签名认证过的站点信息。由于经过 CA 签名，第三方无法通过伪造手段冒充身份。\n证书由站点信息和 CA 签名组成，站点信息包含站点公钥，公钥用于协商对称加密密钥； 证书由 CA 权威机构审核签发，签名用的是 CA 的私钥； CA 公钥通常以根证书形式预装在系统内，客户端通过它来验证证书签名； 有了数字签名，黑客无法对证书进行篡改，也无法伪造证书，因此无法部署仿冒站点； 若只窃取原站点证书，不做篡改，客户端使用真实站点的公钥，而黑客无法掌握站点私钥，因此加密连接无法建立； 如果篡改原站点证书，换上自己的公钥，但因为没有 CA 私钥无法生成合法签名，也会被识别出来； 转载自数字证书身份认证原理与签发步骤详解 | 小菜学网络\n","date":"2025-07-28T16:36:08+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/%E8%AF%81%E4%B9%A6%E8%AF%A6%E8%A7%A3/","title":"证书详解"},{"content":"RESTful API 一、RESTful API概述 1.1 定义 REST（Representational State Transfer）即表现层状态转移，是一种针对网络应用的设计风格，主要用于设计分布式超媒体系统。RESTful API 则是遵循 REST 架构原则的应用程序接口，允许客户端和服务器通过 HTTP 协议进行交互。它采用资源定位的思维模式，将所有的操作都视为对资源的操作，以使系统更加简洁、易于理解和扩展。\n1.2 核心概念 资源（Resource）：RESTful API 中的每一个对象、实体或数据都被抽象为一个资源。例如，用户、文章等都可以作为资源。每个资源都通过一个唯一的 URI（统一资源标识符）标识。比如，/users/123 表示 id 为 123 的用户资源，/posts/456 表示 id 为 456 的文章资源。 URI（统一资源标识符）：用于标识资源的地址，通常使用 URL（统一资源定位符）作为 URI。 HTTP 动作（HTTP Methods）：依赖于 HTTP 协议的常见方法来对资源进行操作，每个 HTTP 方法对应不同的操作： GET：获取服务器上的资源。 POST：在服务器上创建新的资源。 PUT：更新服务器上的资源。 DELETE：删除服务器上的资源。 无状态（Statelessness）：每个请求都应该是独立的，服务器不会在请求之间保存客户端的状态。每次请求都必须包含理解请求所必需的信息。 表现层状态转移（Representational State Transfer）：资源的表现形式可以是 JSON、XML、HTML 等格式，通常 RESTful API 使用 JSON 作为数据交换格式，因为它轻量且易于解析。客户端通过接收资源的表现形式（如 JSON、XML）来感知资源的变化，从而实现状态的“转移”。 二、RESTful API的特点和优势 2.1 特点 资源导向：所有内容都被抽象为资源（如 User、Order、Article 等），每个资源都有一个唯一的标识符（URI）。例如，/users 表示用户资源，/users/1 表示 ID 为 1 的用户。 使用标准协议：基于 HTTP 协议，直接使用其方法（GET、POST 等）来操作资源。 无状态通信：每次请求都包含所有上下文，不依赖服务器保存状态。这使得服务器可以更加容易地进行扩展和负载均衡，因为每个请求都是独立的，不需要考虑之前的请求状态。 统一接口：接口风格统一、易于理解和使用。通过标准的 HTTP 方法（GET、POST、PUT、DELETE 等）和资源标识符（URI）访问资源，简化了系统的整体架构，提升了互操作性。 可缓存：客户端可根据响应头对资源进行缓存，提高性能。利用 HTTP 协议的缓存机制，允许中间件或客户端缓存响应结果，减少不必要的网络请求，从而提升响应速度和减轻服务器负担。 分层架构：客户端无需知道请求最终由谁处理（例如中间层、负载均衡等）。允许通过中间层（如代理服务器、网关）来处理请求，每层只需与相邻层通信，增强了系统的安全性、可扩展性和灵活性。 按需代码（可选）：客户端可以从服务器下载代码或脚本，以扩展其功能，增加了系统的灵活性和可扩展性。 2.2 优势 简洁易懂：使用 HTTP 协议的标准方法和 URI，可以让 API 的设计和使用变得简单。通过 URL 和 HTTP 动词的组合，可以明确地表示对特定资源的操作意图。 灵活性：资源可以有不同的表示形式（JSON、XML 等），同时 HTTP 方法明确区分不同的操作。客户端可以根据自身需求选择合适的数据格式。 扩展性强：通过一致的接口设计，可以很容易地扩展和维护 API。随着应用程序的发展，可以轻松地添加新的资源和操作，而不会影响现有的 API 结构。 无状态性：简化了服务器端的设计，增强了系统的可扩展性。服务器不需要保存客户端的状态信息，使得服务器可以更容易地进行扩展和负载均衡。 跨平台：基于 HTTP 协议，可以被任何支持 HTTP 的客户端调用，适用于各种应用场景，特别是需要跨平台和跨语言交互的系统。 三、RESTful API的设计原则 3.1 基于资源 将网络上的每个实体或概念视为唯一资源是一个关键原则。通过 URL 来表示这些资源，使得资源的定位更加清晰和直观。例如，一个博客文章可以被表示为 /articles/123，其中 “articles” 表示文章资源的集合，“123” 是具体某一篇文章的唯一标识符。这种方式使得开发者和用户都能够轻松地理解和访问特定的资源。以电商平台为例，商品可以表示为 /products，每个具体的商品可以通过 /products/{productId} 来访问，其中 {productId} 是商品的唯一标识。\n3.2 统一接口 资源标识（Resource Identification）：每个资源都应有唯一的 URL。例如，用户资源可以通过 /users/{id} 进行标识，其中 {id} 是用户的具体标识。 资源操作（Resource Manipulation Through Representations）：通过表示（representation）来操作资源，而不是直接操作资源本身。使用标准的 HTTP 方法（GET、POST、PUT、DELETE 等）来操作资源。 自描述消息（Self - descriptive Messages）：响应消息应包含足够的信息以便客户端无需额外文档即可理解。每个请求和响应都包含足够的信息，使得客户端能够理解如何处理它们。 无状态（Stateless）：服务器不保存客户端的上下文信息，每次请求都是独立的。每个请求都必须包含足够的信息，使服务器能够理解和处理该请求，而不依赖于之前的请求。 3.3 使用标准的 HTTP 方法 主要使用 HTTP 方法来定义对资源的操作，常见的 HTTP 方法及其作用如下：\nHTTP 方法 操作 幂等性 安全性 示例 GET 获取资源 ✅ ✅ GET /users 查看所有用户信息；GET /users/id 查看该 id 的用户信息 POST 创建资源 ❌ ❌ POST /users 创建用户，可在 DATA 处带需要的参数 PUT 更新或替换资源 ✅ ❌ PUT /users/id?name='张三'\u0026amp;age=20 修改该 id 的用户信息（name 和 age） PATCH 部分更新资源 ❌ ❌ 对资源进行部分属性的更新 DELETE 删除资源 ✅ ❌ DELETE /users/id 删除该 id 的用户信息 HEAD 获取资源的元数据 ✅ ✅ OPTIONS 获取信息，关于资源的哪些属性是客户端可以改变的 ✅ ✅ 3.4 无状态通信 每个请求必须包含服务器处理该请求所需的所有信息，服务器不依赖之前的请求上下文。这使得服务器可以更加容易地进行扩展和负载均衡，因为每个请求都是独立的，不需要考虑之前的请求状态。例如，当客户端发送多个请求时，服务器不需要记住之前的请求内容，只需要根据当前请求的信息进行处理。\n3.5 返回适当的状态码 API 应返回适当的 HTTP 状态码，准确反映请求结果。常用的状态码如下：\n状态码 含义 说明 200 OK 服务器成功返回用户请求的数据，该操作是幂等的（Idempotent），通用成功。 201 Created 资源已创建，通常用于 POST 请求。 204 No Content 请求成功，但无返回内容，通常用于 DELETE 请求。 400 Bad Request 请求参数有误，服务器无法处理。 401 Unauthorized 认证失败，客户端需要提供身份验证。 403 Forbidden 没有权限访问资源，服务器理解请求，但拒绝执行，通常由于权限问题。 404 Not Found 请求的资源不存在。 500 Internal Server Error 服务器内部错误。 3.6 过滤信息 如果记录数量很多，服务器不可能都将它们返回给用户。API 应该提供参数，过滤返回结果。常见的参数如下：\n?limit=10：指定返回记录的数量。 ?offset=10：指定返回记录的开始位置。 ?page=2\u0026amp;per_page=100：指定第几页，以及每页的记录数。 ?sortby=name\u0026amp;order=asc：指定返回结果按照哪个属性排序，以及排序顺序。 ?animal_type_id=1：指定筛选条件。 3.7 支持 HATEOAS（超媒体作为应用程序状态引擎） HATEOAS 要求客户端能够通过服务器返回的超链接（URL）导航到相关资源。简而言之，HATEOAS 要求 API 的响应不仅包含资源数据，还应该包含与资源相关的操作链接，帮助客户端更好地理解如何进行下一步操作。例如，获取用户信息时，除了返回用户的详细数据外，API 还可以提供相关操作的链接：\n1 2 3 4 5 6 7 8 9 { \u0026#34;user_id\u0026#34;: 123, \u0026#34;name\u0026#34;: \u0026#34;John Doe\u0026#34;, \u0026#34;links\u0026#34;: { \u0026#34;self\u0026#34;: \u0026#34;/users/123\u0026#34;, \u0026#34;update\u0026#34;: \u0026#34;/users/123/update\u0026#34;, \u0026#34;delete\u0026#34;: \u0026#34;/users/123/delete\u0026#34; } } 3.8 数据格式 返回数据格式通常使用 JSON 或 XML，其中 JSON 因其轻量级和易读性，已成为 RESTful API 事实上的数据交换格式。统一返回 JSON 格式，包含数据、状态码和错误信息，例如：\n1 2 3 4 5 { \u0026#34;status\u0026#34;: 200, \u0026#34;data\u0026#34;: { \u0026#34;id\u0026#34;: 123, \u0026#34;name\u0026#34;: \u0026#34;Alice\u0026#34; }, \u0026#34;error\u0026#34;: null } 3.9 版本控制 当 API 发生变化时，可以通过版本号来管理不同版本的 API，以保持向后兼容性。常见的版本控制策略有：\nURL 路径版本：如 /v1/resource，优点是简单、显式、易缓存；缺点是不够优雅、URL 膨胀。 请求头版本：如 X - API - Version: 1，优点是 URL 干净、松耦合；缺点是难调试、可能被代理移除。 内容协商版本：如 Accept: application/vnd.example.v1+json，优点是 RESTful、标准 HTTP 头；缺点是复杂、客户端支持不一。 查询参数版本：如 /resource?version=1，优点是简单、显式；缺点是不是 RESTful、URL 污染。 四、RESTful API的设计示例 以一个简单的博客平台为例，设计其 RESTful API：\n4.1 资源列表 用户（/users） 文章（/articles） 评论（/comments） 4.2 操作设计 操作 HTTP 方法 URL 说明 获取所有用户 GET /users 返回所有用户的列表 获取特定用户 GET /users/{id} 返回指定 ID 用户的详细信息 创建用户 POST /users 根据请求体中的数据创建新用户 更新用户信息 PUT /users/{id} 更新指定 ID 用户的信息 删除用户 DELETE /users/{id} 删除指定 ID 的用户 获取所有文章 GET /articles 返回所有文章的列表 获取特定文章 GET /articles/{id} 返回指定 ID 文章的详细信息 创建文章 POST /articles 根据请求体中的数据创建新文章 更新文章信息 PUT /articles/{id} 更新指定 ID 文章的信息 删除文章 DELETE /articles/{id} 删除指定 ID 的文章 获取特定文章的评论 GET /articles/{id}/comments 返回指定 ID 文章的所有评论 创建评论 POST /articles/{id}/comments 在指定 ID 文章下创建新评论 删除评论 DELETE /comments/{id} 删除指定 ID 的评论 五、RESTful API的实现 5.1 服务端实现（以 Node.js 为例） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 const express = require(\u0026#39;express\u0026#39;); const app = express(); app.use(express.json()); // 模拟用户数据 const users = [ { id: 1, name: \u0026#39;John Doe\u0026#39;, email: \u0026#39;john@example.com\u0026#39; }, { id: 2, name: \u0026#39;Jane Smith\u0026#39;, email: \u0026#39;jane@example.com\u0026#39; } ]; // 获取所有用户 app.get(\u0026#39;/api/v1/users\u0026#39;, (req, res) =\u0026gt; { res.status(200).json({ status: 200, data: users }); }); // 创建新用户 app.post(\u0026#39;/api/v1/users\u0026#39;, (req, res) =\u0026gt; { const newUser = req.body; users.push(newUser); res.status(201).json({ status: 201, data: newUser }); }); // 获取特定用户 app.get(\u0026#39;/api/v1/users/:id\u0026#39;, (req, res) =\u0026gt; { const userId = parseInt(req.params.id); const user = users.find(u =\u0026gt; u.id === userId); if (user) { res.status(200).json({ status: 200, data: user }); } else { res.status(404).json({ status: 404, error: \u0026#39;User not found\u0026#39; }); } }); // 更新用户信息 app.put(\u0026#39;/api/v1/users/:id\u0026#39;, (req, res) =\u0026gt; { const userId = parseInt(req.params.id); const updatedUser = req.body; const index = users.findIndex(u =\u0026gt; u.id === userId); if (index!== -1) { users[index] = updatedUser; res.status(200).json({ status: 200, data: updatedUser }); } else { res.status(404).json({ status: 404, error: \u0026#39;User not found\u0026#39; }); } }); // 删除用户 app.delete(\u0026#39;/api/v1/users/:id\u0026#39;, (req, res) =\u0026gt; { const userId = parseInt(req.params.id); const index = users.findIndex(u =\u0026gt; u.id === userId); if (index!== -1) { users.splice(index, 1); res.status(204).send(); } else { res.status(404).json({ status: 404, error: \u0026#39;User not found\u0026#39; }); } }); const port = process.env.PORT || 3000; app.listen(port, () =\u0026gt; { console.log(`Server is running on port ${port}`); }); 5.2 客户端调用（以 JavaScript Fetch 为例） 1 2 3 4 5 6 7 8 9 10 11 12 // 获取用户数据 fetch(\u0026#39;https://api.example.com/users/123\u0026#39;) .then(response =\u0026gt; response.json()) .then(data =\u0026gt; console.log(data)) .catch(error =\u0026gt; console.error(\u0026#39;Error:\u0026#39;, error)); // 提交新文章 fetch(\u0026#39;https://api.example.com/articles\u0026#39;, { method: \u0026#39;POST\u0026#39;, headers: { \u0026#39;Content - Type\u0026#39;: \u0026#39;application/json\u0026#39; }, body: JSON.stringify({ title: \u0026#39;Hello REST\u0026#39;, content: \u0026#39;...\u0026#39; }) }); 六、RESTful API的应用场景 6.1 Web 服务 提供 Web 服务，如社交媒体、电商网站等。前端（如 JavaScript、Angular、React 等）可以通过 RESTful API 与后端服务器进行通信，获取和更新数据。例如，一个电商网站的前端可以使用 RESTful API 从服务器获取商品列表、用户信息等，并将用户的订单信息发送到服务器进行处理。\n6.2 移动应用 移动应用通过 RESTful API 与服务器交互，获取和更新数据，实现用户登录、数据同步等功能。Android 和 iOS 应用可以使用 RESTful API 与服务器交互，提供丰富的用户体验。\n6.3 物联网（IoT） 设备通过 RESTful API 与服务器通信，实现数据采集和控制。物联网设备可以通过 RESTful API 将采集到的数据发送到服务器，同时接收服务器的控制指令。\n6.4 微服务架构 微服务之间通过 RESTful API 进行通信和协作。每个微服务都可以暴露自己的 RESTful API，其他微服务可以通过调用这些 API 来获取所需的数据或执行特定的操作。例如，一个电商系统可能由用户服务、商品服务、订单服务等多个微服务组成，这些微服务之间可以通过 RESTful API 进行数据交互和业务协作。\n6.5 企业级应用集成 企业内部的不同系统之间可以使用 RESTful API 进行集成。例如，企业的客户关系管理系统（CRM）和企业资源规划系统（ERP）可以通过 RESTful API 进行数据交换，实现信息共享和业务流程的协同。\n七、RESTful API与传统 API的对比 比较项 RESTful API 传统 API 风格 接口风格 资源导向，结构清晰 动作导向，接口混乱 动作表示 使用 HTTP 方法表示动作 接口路径中包含动词（如 /getUser） 可读性 高，可直观理解操作含义 低，需要阅读文档才能理解 维护性 易于扩展和维护 扩展性差，接口膨胀 数据传输格式 通常使用 JSON 或 XML，有明确标准 可能使用多种格式，无明确标准 状态与缓存 强调状态无关性，可利用 HTTP 缓存机制 可能依赖服务器端状态，缓存策略不一致 安全性和认证 支持各种安全性措施，如 HTTPS、认证、授权等 可能缺乏统一的安全标准 接口一致性 统一接口，易于使用 接口设计松散，不一致 资源关联性 在响应中提供相关资源的链接，具有自描述性 通常不提供自描述性 综上所述，RESTful API 以其简洁、灵活、可扩展等优点，成为现代 Web 开发中主流的 API 设计风格之一，广泛应用于各种网络应用场景中。在设计和开发 RESTful API 时，遵循其设计原则和最佳实践，能够构建出高效、易用、可维护的 API 系统。\n","date":"2025-06-26T15:22:59+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/restful-api/","title":"RESTful API"},{"content":"创建public仓库用来存放照片 创建token token将来PicGo操作你的github仓库来上传图片时要用到，在 GitHub 账户下 Setting - Developer setting - Personal access tokens(classic) 下创建一个不过期(no expiration)的 Token，权限需要开启 repo.这个我们在用Github action 来部署博客仓库时已经创建了，用那个就好.token 在创建时只显示一次，要保存好哦！\n配置PicGo github 搜索PicGo 然后安装 图床具体参数配置 仓库名 分支名 对应于之前你创建的GitHub仓库\nToken就是前面创建的Token,被PicGo用来上传照片到长仓库\n路径可以自定义\n自定义域名格式:https://cdn.jsdelivr.net/gh/用户名/仓库名@分支名\nTypora Typora 可搭配PicGo使用\n若PicGo显示unable to verify the first certificate at TLS,无法上传，则可能是你的网络加速工具造成的某些网络加速工具可能会修改网络流量，可能与 SSL证书验证机制发生冲突。这可能导致 SSL 证书验证失败，因为服务器的证书无法正常验证，从而出现类似 \u0026ldquo;unable to verify the first certificate\u0026rdquo; 的错误。例如我之前用Watt Toolkit就出现了：\n如果Typora显示failed to fetch ；检查PicGo server 设置的监听地址是否一致（点击Typora图片设置中的验证图片上传）\njsDelivr jsDelivr是一个免费、开源的加速CDN公共服务,托管了许多大大小小的项目,可加速访问托管的项目目录或图片资源。 他支持提供npm、Github、WordPress上资源cdn服务。\nCDN (全称 Content Delivery Network)，即内容分发网络。\nCDN构建在现有网络基础之上的智能虚拟网络，依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等功能模块，使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。\nCDN 的关键技术主要有内容存储和分发技术，简单来讲，CDN就是根据用户位置分配最近的资源，于是，用户在上网的时候不用直接访问源站，而是访问离他“最近的”一个 CDN 节点(也叫做“边缘节点”、edge node)，其实就是缓存了源站内容的代理服务器\n","date":"2025-06-12T19:33:46+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/github--picgo-%E6%90%AD%E5%BB%BA%E5%9B%BE%E5%BA%8A/","title":"Github + PicGo 搭建图床"},{"content":" 创建仓库 首先在github创建两个仓库，一个用于存储hugo new site创建的workspace，这个设置为private私密；另一个仓库用来存储hugo -D生成的网页文件 ，设置为公开:\n本地获取ssh密钥 终端输入命令：\n1 2 git config --global user.email \u0026#34;you@example.com\u0026#34; #you@example.com替换为你的邮箱 git config --global user.name \u0026#34;Your Name\u0026#34; #Your Name替换为你的名字并回车 生成ssh key,在git bash中输入以下命令:\nssh-keygen -t rsa -C \u0026quot;your_email@example.com\u0026quot; 生成的密钥将存储在C:\\uers\\username\\.ssh\\路径下 打开公钥文件 id_rsa.pub， 复制所有内容，在GitHub上打开Setting -\u0026gt; SSH and GPG keys -\u0026gt; add SSH key，将复制的内容粘贴在里边，保存。\n若配置完后，还是显示无法连接到github,可能是你的Windows电脑的username 是中文导致的bug 或者尝试在.ssh 下创建一个config 文件\n1 2 3 4 5 6 Host github.com HostName ssh.github.com # **这是最重要的部分** User git Port 443 PreferredAuthentications publickey IdentityFile ~/.ssh/id_rsa 创建github token 在 GitHub 账户下 Setting - Developer setting - Personal access tokens(classic) 下创建一个不过期(no expiration)的 Token，权限需要开启 repo 与 workflow。\n（注意：token只会显示一次，请及时保存） 私密源仓库设置token 在博客源仓库的 Settings-\u0026gt;Secrets-\u0026gt;Actions 中添加 PERSONAL_TOKEN 环境变量为刚才的 Token,\n这样 GitHub Action 就可以获取到Token 了。 本地首次创建博客 1 2 3 hugo new site hugo-stack-blog-dev git init git submodule add https://github.com/CaiJimmy/hugo-theme-stack/ themes/hugo-theme-stack git submodule主要是将自己的改动，与引用的stack主题仓库分开。hugo-theme-stack 下的目录结构基本与站点源目录结构一致 hugo 生成网站时优先寻找站点源目录下的，找不到，才会去stack主题对应目录下寻找\n接下来将 exampleSite样例数据中的 Content 和 hugo.yaml 复制到主文件夹中，并删掉hugo.toml\n可以hugo server -D看一下初始网站长啥样\n创建一篇新文章(在主目录下)\n1 hugo new post/blog1/index.zh-cn.md 初始化博客源仓库，提交到github\n1 2 3 4 5 git add . git commit -m \u0026#34;first commit\u0026#34; git branch -M main git remote add origin git@github.com:charles-7777/hugo-stack-blog-dev.git git push -u origin main 创建workflows发布文件 在本地博客主目录下创建 .github/workflows目录，然后创建xxxx.yaml文件。我的 GitHub Action 配置为，自动发布示例配置如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 name: deploy # 代码提交到main分支时触发github action on: push: branches: - main jobs: deploy: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v2 with: submodules: recursive fetch-depth: 0 - name: Setup Hugo uses: peaceiris/actions-hugo@v3 with: hugo-version: \u0026#34;0.147.7\u0026#34; extended: true - name: Build Web run: hugo -D - name: Deploy Web uses: peaceiris/actions-gh-pages@v4 with: PERSONAL_TOKEN: ${{ secrets.TOKEN }} EXTERNAL_REPOSITORY: charles-7777/hugo-stack PUBLISH_BRANCH: main PUBLISH_DIR: ./public commit_message: auto deploy 提交github action的改动后，每次push hugo-stack-blog-dev ,就会把基于这个厂库 hugo -D 生成的文件 自动push 到仓库 hugo-stack\nGitHub Pages 前往hugo-stack 仓库的settings--\u0026gt;Pages去添加deploy GitHub Pages 在别的电脑拉取源仓库修改 1 2 3 git clone git@github.com:charles-7777/hugo-stack-blog-dev.git git submodule init git submodule update 参考链接\nhttps://letere-gzj.github.io/hugo-stack/tags/hugo/\n参考博主letere-gzj的视频 markdown中的图片也可以不用本地的图片，可以使用网络url，可以自己创建一个图床，方便管理。 github图床\n","date":"2025-06-09T00:00:00Z","image":"https://cdn.jsdelivr.net/gh/charles-7777/ImageBed@main/blog/hugo.png","permalink":"https://charles-7777.github.io/hugo-stack/p/hugo-stack-blog-%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/","title":"hugo stack blog 搭建记录"}]