[{"content":"I/O 模型概览 一个输入操作通常包括两个阶段：\n等待数据准备好 从内核向进程复制数据 对于一个套接字上的输入操作，第一步通常涉及等待数据从网络中到达。当所等待数据到达时，它被复制到内核中的某个缓冲区。第二步就是把数据从内核缓冲区复制到应用进程缓冲区\nUnix 有五种 I/O 模型：\n阻塞 I/O：调用阻塞到数据复制完成。 非阻塞 I/O：立即返回，需要轮询。 I/O 复用：select/poll/epoll 等待多个 fd。 信号驱动 I/O：数据就绪时发 SIGIO，再读取。 异步 I/O：提交请求后由内核完成并通知。 实践侧重：\n阻塞模型简单，适合连接数少且延迟不敏感的 CLI/工具脚本； 非阻塞模型常与事件循环/定时器配合，否则轮询会耗 CPU； I/O 复用是高并发网络服务的基础； 信号驱动在 Linux 上使用较少，更多见于嵌入式/老项目； 异步 I/O 需要平台支持（如 Linux AIO/io_uring、Windows IOCP）。 阻塞 I/O 应用进程被阻塞，直到数据从内核缓冲区复制到应用进程缓冲区中才返回。 应该注意到，在阻塞的过程中，其它应用进程还可以执行，因此阻塞不意味着整个操作系统都被阻塞。因为其它应用进程还可以执行，所以不消耗 CPU 时间，这种模型的 CPU 利用率会比较高。 例如，recvfrom() 用于接收 Socket 传来的数据，并复制到应用进程的缓冲区 buf 中。这里把 recvfrom() 当成系统调用。\n1 ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags, struct sockaddr *src_addr, socklen_t *addrlen); sequenceDiagram participant App as 应用进程 participant Kernel as 内核 App-\u0026gt;\u0026gt;Kernel: recvfrom() Note left of App: 调用recvform()进程阻塞 Note right of Kernel: 等待数据到达并存入内核缓冲 Kernel--\u0026gt;\u0026gt;App: 数据复制完成后返回 特点：实现简单，CPU 利用率高（阻塞期间不占用 CPU），但吞吐受限。\n典型用法：短连接 RPC、小工具一次性读写； 隐患：若对端长时间不发数据或网络抖动，线程被长期占用，需要超时控制（如 SO_RCVTIMEO）； 在多线程服务器中，线程数与连接数线性相关，易受线程栈内存与调度开销限制。 非阻塞 I/O 应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知 I/O 是否完成，这种方式称为轮询（polling）。 由于 CPU 要处理更多的系统调用，因此这种模型的 CPU 利用率比较低。\nsequenceDiagram participant App as 应用 participant Kernel as 内核 App-\u0026gt;\u0026gt;Kernel: recvfrom() (非阻塞) Kernel--\u0026gt;\u0026gt;App: EWOULDBLOCK App-\u0026gt;\u0026gt;Kernel: recvfrom() 轮询直至可读 Kernel--\u0026gt;\u0026gt;App: 数据复制完成 I/O 复用（事件驱动） 使用 select 或者 poll 等待数据，并且可以等待多个套接字中的任何一个变为可读。这一过程会被阻塞，当某一个套接字可读时返回，之后再使用 recvfrom 把数据从内核复制到进程中。\n它可以让单个进程具有处理多个 I/O 事件的能力。又被称为 Event Driven I/O，即事件驱动 I/O。\n如果一个 Web 服务器没有 I/O 复用，那么每一个 Socket 连接都需要创建一个线程去处理。如果同时有几万个连接，那么就需要创建相同数量的线程。相比于多进程和多线程技术，I/O 复用不需要进程线程创建和切换的开销，系统开销更小。\nsequenceDiagram participant App as 应用层 participant Kernel as 内核 App-\u0026gt;\u0026gt;Kernel: select Note left of App: 调用select()进程阻塞,等待某一个套接字可读 Kernel--\u0026gt;\u0026gt;App: 数据就绪 App-\u0026gt;\u0026gt;Kernel: recvfrom() Note left of App: 在数据拷贝到应用的buffer的过程中，进程阻塞 Kernel--\u0026gt;\u0026gt;App: 返回数据 Note right of Kernel: copy data form kernel to user App-\u0026gt;\u0026gt;App: 处理数据 适合单线程/单进程管理多连接，减少线程切换\n事件循环典型结构：注册 fd -\u0026gt; 等待 -\u0026gt; 处理就绪 -\u0026gt; 重新注册或继续等待； 需要把 fd 设置为非阻塞，避免单个 read/write 卡住事件循环； 回调里要尽量快，耗时任务应投递到工作线程池； 要关注粘包/拆包，事件驱动只告诉“可读/可写”，应用层需处理协议边界。 信号驱动 I/O 应用进程使用 sigaction 系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送 SIGIO 信号，应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中。\n相比于非阻塞式 I/O 的轮询方式，信号驱动 I/O 的 CPU 利用率更高。\nsequenceDiagram participant App as 应用 participant Kernel as 内核 App-\u0026gt;\u0026gt;Kernel: sigaction(SIGIO) Kernel--\u0026gt;\u0026gt;App: return App--\u0026gt;\u0026gt;App: 继续执行其他逻辑 Kernel--\u0026gt;\u0026gt;App: 发送SIGIO App-\u0026gt;\u0026gt;Kernel: recvfrom() Note left of App: blocked Kernel--\u0026gt;\u0026gt;App: data copy 完成 减少轮询开销，但信号处理需谨慎。\n需设置 F_SETOWN/F_SETSIG 等，且信号处理函数中能做的事情有限（不可重入操作要避免）； 可与 signalfd 结合在 Linux 上统一为 fd 事件，但通用性较差； 在复杂网络服务中通常被 epoll 等方案取代。 异步 I/O（AIO） 应用进程执行 aio_read 系统调用会立即返回，应用进程可以继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号。\n异步 I/O 与信号驱动 I/O 的区别在于，异步 I/O 的信号是通知应用进程 I/O 完成，而信号驱动 I/O 的信号是通知应用进程可以开始 I/O\nsequenceDiagram participant App as 应用 participant Kernel as 内核 App-\u0026gt;\u0026gt;Kernel: aio_read() Kernel--\u0026gt;\u0026gt;App: return App--\u0026gt;\u0026gt;App: 继续执行 Kernel--\u0026gt;\u0026gt;Kernel: copy data from kernel to user Kernel--\u0026gt;\u0026gt;App: deliver signal specified in aio_read App--\u0026gt;\u0026gt;App: signal handler处理data Linux 传统 AIO 限制较多，推荐现代接口如 io_uring； Windows IOCP、.NET async/await、Node.js libuv 都属于异步完成通知模型； 适合高吞吐文件 I/O 或网络 I/O，减少上下文切换和拷贝。 五大模型对比 同步 vs 异步：同步在“数据复制到用户缓冲”阶段会阻塞；异步不会。\n阻塞/非阻塞/I/O 复用/信号驱动：都属同步 I/O，本质差别在“等待数据”阶段是否阻塞。\nCPU 利用率：阻塞高、非阻塞低、复用和信号介于其间、AIO 最优但实现/平台支持差异大。\n拷贝次数：经典模型仍需用户态/内核态拷贝；部分异步框架支持零拷贝（如 sendfile, splice）。\n编程复杂度：阻塞 \u0026lt; 非阻塞 \u0026lt; I/O 复用 \u0026lt; 异步 AIO；\n适用连接规模：阻塞/非阻塞适合少量连接；复用/异步适合大量连接。\nI/O 复用详解 select/poll/epoll 都是 I/O 多路复用的具体实现，select 出现的最早，之后是 poll，再是 epoll\nselect 1 int select(int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); select 允许应用程序监视一组文件描述符，等待一个或者多个描述符成为就绪状态，从而完成 I/O 操作。\nfd_set 使用数组实现，数组大小使用 FD_SETSIZE 定义，所以只能监听少于 FD_SETSIZE 数量的描述符。有三种类型的描述符类型：readset、writeset、exceptset，分别对应读、写、异常条件的描述符集合。\ntimeout 为超时参数，调用 select 会一直阻塞直到有描述符的事件到达或者等待的时间超过 timeout。\n成功调用返回结果大于 0，出错返回结果为 -1，超时返回结果为 0\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 fd_set fd_in, fd_out; struct timeval tv; // Reset the sets FD_ZERO( \u0026amp;fd_in ); FD_ZERO( \u0026amp;fd_out ); // Monitor sock1 for input events FD_SET( sock1, \u0026amp;fd_in ); // Monitor sock2 for output events FD_SET( sock2, \u0026amp;fd_out ); // Find out which socket has the largest numeric value as select requires it int largest_sock = sock1 \u0026gt; sock2 ? sock1 : sock2; // Wait up to 10 seconds tv.tv_sec = 10; tv.tv_usec = 0; // Call the select int ret = select( largest_sock + 1, \u0026amp;fd_in, \u0026amp;fd_out, NULL, \u0026amp;tv ); // Check if select actually succeed if ( ret == -1 ) // report error and abort else if ( ret == 0 ) // timeout; no event detected else { if ( FD_ISSET( sock1, \u0026amp;fd_in ) ) // input event on sock1 if ( FD_ISSET( sock2, \u0026amp;fd_out ) ) // output event on sock2 } poll 1 int poll(struct pollfd *fds, unsigned int nfds, int timeout); poll 的功能与 select 类似，也是等待一组描述符中的一个成为就绪状态。 poll 中的描述符是 pollfd 类型的数组，pollfd 的定义如下：\n1 2 3 4 5 struct pollfd { int fd; /* file descriptor */ short events; /* requested events */ short revents; /* returned events */ }; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 // The structure for two events struct pollfd fds[2]; // Monitor sock1 for input fds[0].fd = sock1; fds[0].events = POLLIN; // Monitor sock2 for output fds[1].fd = sock2; fds[1].events = POLLOUT; // Wait 10 seconds int ret = poll( \u0026amp;fds, 2, 10000 ); // Check if poll actually succeed if ( ret == -1 ) // report error and abort else if ( ret == 0 ) // timeout; no event detected else { // If we detect the event, zero it out so we can reuse the structure if ( fds[0].revents \u0026amp; POLLIN ) fds[0].revents = 0; // input event on sock1 if ( fds[1].revents \u0026amp; POLLOUT ) fds[1].revents = 0; // output event on sock2 } select vs poll 功能: select 和 poll 的功能基本相同，不过在一些实现细节上有所不同。 select 会修改描述符，而 poll 不会； select 的描述符类型使用数组实现，FD_SETSIZE 大小默认为 1024，因此默认只能监听少于 1024 个描述符。 如果要监听更描述符的话，需要修改 FD_SETSIZE 之后重新编译；而 poll 没有描述符数量的限制； poll 提供了更多的事件类型，并且对描述符的重复利用上比 select 高。 如果一个线程对某个描述符调用了 select 或者 poll，另一个线程关闭了该描述符，会导致调用结果不确定。 速度: select 和 poll 速度都比较慢，每次调用都需要将全部描述符从应用进程缓冲区复制到内核缓冲区。 可移植性: 几乎所有的系统都支持 select，但是只有比较新的系统支持 poll。 epoll 1 2 3 int epoll_create(int size); int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)； int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); epoll_ctl() 用于向内核注册新的描述符或者是改变某个文件描述符的状态。已注册的描述符在内核中会被维护在一棵红黑树上，通过回调函数内核会将 I/O 准备好的描述符加入到一个链表中管理，进程调用 epoll_wait() 便可以得到事件完成的描述符。\n从上面的描述可以看出，epoll 只需要将描述符从进程缓冲区向内核缓冲区拷贝一次，并且进程不需要通过轮询来获得事件完成的描述符。\nepoll 仅适用于 Linux OS。\nepoll 比 select 和 poll 更加灵活而且没有描述符数量限制。\nepoll 对多线程编程更有友好，一个线程调用了 epoll_wait() 另一个线程关闭了同一个描述符也不会产生像 select 和 poll 的不确定情况。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 // Create the epoll descriptor. Only one is needed per app, and is used to monitor all sockets. // The function argument is ignored (it was not before, but now it is), so put your favorite number here int pollingfd = epoll_create( 0xCAFE ); if ( pollingfd \u0026lt; 0 ) // report error // Initialize the epoll structure in case more members are added in future struct epoll_event ev = { 0 }; // Associate the connection class instance with the event. You can associate anything // you want, epoll does not use this information. We store a connection class pointer, pConnection1 ev.data.ptr = pConnection1; // Monitor for input, and do not automatically rearm the descriptor after the event ev.events = EPOLLIN | EPOLLONESHOT; // Add the descriptor into the monitoring list. We can do it even if another thread is // waiting in epoll_wait - the descriptor will be properly added if ( epoll_ctl( epollfd, EPOLL_CTL_ADD, pConnection1-\u0026gt;getSocket(), \u0026amp;ev ) != 0 ) // report error // Wait for up to 20 events (assuming we have added maybe 200 sockets before that it may happen) struct epoll_event pevents[ 20 ]; // Wait for 10 seconds, and retrieve less than 20 epoll_event and store them into epoll_event array int ready = epoll_wait( pollingfd, pevents, 20, 10000 ); // Check if epoll actually succeed if ( ret == -1 ) // report error and abort else if ( ret == 0 ) // timeout; no event detected else { // Check if any events detected for ( int i = 0; i \u0026lt; ready; i++ ) { if ( pevents[i].events \u0026amp; EPOLLIN ) { // Get back our connection pointer Connection * c = (Connection*) pevents[i].data.ptr; c-\u0026gt;handleReadEvent(); } } } epoll的工作模式 epoll 的描述符事件有两种触发模式：LT（level trigger）和 ET（edge trigger）。\nLT（Level Trigger，默认）：当 epoll_wait() 检测到描述符事件到达时，将此事件通知进程，进程可以不立即处理该事件，下次调用 epoll_wait() 会再次通知进程。是默认的一种模式，并且同时支持 Blocking 和 No-Blocking。 ET（Edge Trigger）：和 LT 模式不同的是，通知之后进程必须立即处理事件，下次再调用 epoll_wait() 时不会再得到事件到达的通知。很大程度上减少了 epoll 事件被重复触发的次数，因此效率要比 LT 模式高。只支持 No-Blocking，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。。 select vs poll vs epoll select: timeout 参数精度为微秒，而 poll 和 epoll 为毫秒，因此 select 更加适用于实时性要求比较高的场景，比如核 反应堆的控制。select 可移植性更好，几乎被所有主流平台所支持。\npoll: 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用 poll 而不是 select。\nepoll: 只需要运行在 Linux 平台上，有大量的描述符需要同时轮询，并且这些连接最好是长连接。 需要同时监控小于 1000 个描述符，就没有必要使用 epoll，因为这个应用场景下并不能体现 epoll 的优势。 需要监控的描述符状态变化多，而且都是非常短暂的，也没有必要使用 epoll。因为 epoll 中的所有描述符都存储在内核中，造成 每次需要对描述符的状态改变都需要通过 epoll_ctl() 进行系统调用，频繁系统调用降低效率。并且 epoll 的描述符存储在内 核，不容易调试。\ncopy from\nhttps://github.com/CyC2018/CS-Notes/blob/master/notes/Socket.md\n","date":"2026-01-08T15:51:28+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/socket-i/o/","title":"Socket I/O"},{"content":"均值与期望 离散随机变量 均值（期望） 设离散随机变量 $X$ 的概率分布函数为 $P(X = x_i) = p_i$，则其数学期望（均值）定义为： $$ \\mu = E[X] = \\sum_{i=1}^{\\infty} x_i p_i $$方差 离散随机变量 $X$ 的方差定义为： $$ \\sigma^2 = D(X) = E[(X - E[X])^2] = \\sum_{i} (x_i - E[X])^2 p_i $$ 也可等价表示为： $$ D(X) = E[X^2] - (E[X])^2 $$ 连续随机变量 均值（期望） 设连续随机变量 $X$ 的概率密度函数为 $f(x)$，则其期望为： $$ \\mu = E[X] = \\int_{-\\infty}^{\\infty} x f(x) \\, dx $$方差 连续随机变量 $X$ 的方差为： $$ \\sigma^2 = D(X) = E[(X - E[X])^2] = \\int_{-\\infty}^{\\infty} (x - E[X])^2 f(x) \\, dx $$ 同样有简化公式： $$ D(X) = E[X^2] - (E[X])^2 $$ 样本方差 给定一个容量为 $n$ 的样本 $x_1, x_2, \\dots, x_n$，其样本均值为： $$ \\bar{X} = \\frac{1}{n} \\sum_{i=1}^{n} x_i $$ 样本方差（无偏估计）定义为： $$ s^2 = \\frac{1}{n - 1} \\sum_{i=1}^{n} (x_i - \\bar{X})^2 $$ 注：分母使用 $n-1$（而非 $n$）是为了使 $s^2$ 成为总体方差 $\\sigma^2$ 的无偏估计量，这一修正称为 贝塞尔修正（Bessel\u0026rsquo;s correction）。\n无偏估计简介 在统计学中，我们常常无法获取整个总体的数据，只能通过样本来推断总体的某些特征（如均值、方差等）。用于推断总体参数的样本函数称为估计量。一个重要的评价标准是该估计量是否“无偏”。\n设 $\\theta$ 是某个总体参数（例如总体均值 $\\mu$ 或总体方差 $\\sigma^2$），$\\hat{\\theta}$ 是基于样本构造的估计量。如果满足： $$ E[\\hat{\\theta}] = \\theta $$ 则称 $\\hat{\\theta}$ 是 $\\theta$ 的无偏估计量（unbiased estimator）。\n换句话说：无偏估计的期望等于它所要估计的真实参数值。这意味着，如果我们反复从总体中抽样并计算该估计量，其平均值会趋近于真实参数。\n无偏估计常见例子 样本均值是总体均值的无偏估计 设总体均值为 $\\mu$，样本为 $x_1, x_2, \\dots, x_n$，样本均值为： $$ \\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i $$ 可以证明： $$ E[\\bar{x}] = E[\\frac{1}{n} \\sum_{i=1}^{n} x_i] =\\frac{1}{n} \\sum_{i=1}^{n} E[x_i] = \\frac{1}{n} n \\mu = \\mu $$ 因此，$\\bar{x}$ 是 $\\mu$ 的无偏估计。\n样本方差是总体方差的无偏估计 总体方差定义为 $\\sigma^2 = E[(X - \\mu)^2]$。若使用： $$ s^2 = \\frac{1}{n - 1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2 $$ 则有： $$ E[s^2] = \\sigma^2 $$ 所以 $s^2$ 是 $\\sigma^2$ 的无偏估计。\n为什么样本方差是总体方差的无偏估计 如果已知随机变量 $ X $ 的期望为 $ \\mu $，那么可以如下计算方差 $ \\sigma^2 $： $$ \\sigma^2 = E[(X - \\mu)^2] $$上面的式子需要知道 $ X $ 的具体分布是什么（在现实应用中往往不知道准确分布），计算起来也比较复杂。\n所以实践中常常采样之后，用下面这个 $ S^2 $ 来近似 $ \\sigma^2 $：\n$$ S^2 = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\mu)^2 $$其实现实中，往往连 $ X $ 的期望 $ \\mu $ 也不清楚，只知道样本的均值：\n$$ \\bar{X} = \\frac{1}{n} \\sum_{i=1}^{n} x_i $$那可以这么来计算 $ s^2 $：\n$$ s^2 = \\frac{1}{n - 1} \\sum_{i=1}^{n} (x_i - \\bar{X})^2 $$$$ \\begin{aligned} E(s^2) \u0026= E\\left(\\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{X})^2\\right) \\\\ \u0026= E\\left[\\frac{1}{n-1} \\sum_{i=1}^{n} (x_i)^2 - \\frac{2}{n-1} \\sum_{i=1}^{n} (x_i)(\\bar{x}) + \\frac{1}{n-1} \\sum_{i=1}^{n} (\\bar{X})^2\\right] \\\\ \u0026= E\\left[\\frac{1}{n-1} \\sum_{i=1}^{n} \\left\\{ (x_i)^2 - 2(\\bar{X})^2 + (\\bar{X})^2 \\right\\} \\right] \\\\ \u0026= E\\left[\\frac{1}{n-1} \\sum_{i=1}^{n} \\left\\{ (x_i)^2 - (\\bar{X})^2 \\right\\} \\right] \\\\ \u0026= E\\left[\\frac{1}{n-1} \\sum_{i=1}^{n} \\left\\{ (x_i)^2 - E[(\\bar{X})^2]\\right\\} \\right] \\\\ \u0026= \\frac{1}{n-1} \\sum_{i=1}^{n} \\left\\{ E[(x_i)^2] - E[(\\bar{x})^2] \\right\\} \\\\ \u0026= \\frac{1}{n-1} \\sum_{i=1}^{n} \\left\\{ D[(x_i)] + (E[x_i])^2 - (D[\\bar{X}] + (E[\\bar{X}])^2) \\right\\} \\\\ \u0026= \\frac{1}{n-1} n \\left\\{ (\\sigma^2 + \\mu^2)- (\\frac{1}{n} \\sigma^2 + \\mu^2 ) \\right\\} \\\\ \u0026=\\sigma^2 \\end{aligned} $$ $D(X) = E[X^2] - (E[X])^2$ $D[\\bar{X}]=D[\\frac{1}{n} \\sum_{i=1}^{n} x_i]= \\frac{1}{n^2} \\sum_{i=1}^{n} D[x_i] = \\frac{1}{n^2} n \\sigma^2 = \\frac{1}{n} \\sigma^2 $ 故样本方差是总体方差的无偏估计，分母使用 $n-1$（而非 $n$）是为了使 $s^2$ 成为总体方差 $\\sigma^2$ 的无偏估计量，这一修正称为 贝塞尔修正（Bessel\u0026rsquo;s correction）\n从自由度的方面看，n 个样本$x_1$ ~ $x_n$ , 但加入了一个约束$\\bar{X} = \\frac{1}{n} \\sum_{i=1}^{n} x_i$, 在已知 $n-1$ 个样本和 $\\bar{X}$ 的情况下，第n个也就确定了(一个n维向量，若有一个线性约束$k_1x_1 +\u0026hellip;+k_nx_n=c$,则其中任意一个向量可以由其余向量线性表出，且这n个向量的秩维n-1),所以$s^2$的自由度就是n-1了，也正是因为除以了正确的自由度，才得到了无偏的方差统计量。\n","date":"2025-12-31T15:17:20+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/%E6%A0%B7%E6%9C%AC%E6%96%B9%E5%B7%AE/","title":"样本方差"},{"content":"IPv6同一前缀地址通信 具有相同前缀的主机间互访的时候，不会查找路由表，只会发NS（Neighbor Solicitation）请求，获取目的地址对应的链路层地址，然后使用该链路层地址封装要发送的数据报文\nsequenceDiagram participant PC1 participant Switch as 交换机（透明） participant PC2 note over PC1,PC2: 统一前缀：2001:db8:1::/64 PC1-\u0026gt;\u0026gt;PC2: NS (请求 2001:db8:1::20 的 MAC) PC2-\u0026gt;\u0026gt;PC1: NA (回应自己的 MAC) PC1-\u0026gt;\u0026gt;Switch: 数据帧 {dst MAC = PC2 的 MAC}\u0026lt;br/\u0026gt;IP: src=2001:db8:1::10, dst=2001:db8:1::20 Switch-\u0026gt;\u0026gt;PC2: 转发数据帧 IPv6不同前缀地址通信 PC先查看目标地址，发现不在本地前缀中；查路由表 → 下一跳 = 默认网关。如果已有 默认网关的 MAC 地址， 直接封装帧发送；如果没有 ，先发 NS（Neighbor Solicitation）请求 默认网关的 MAC，要到网关的mac再封装帧发送\nsequenceDiagram participant PC1 participant RouterA as Router (接口A) participant RouterB as Router (接口B) participant PC2 note right of RouterA: 2001:db8:1::1/64 note right of RouterB: 2001:db8:2::1/64 PC1-\u0026gt;\u0026gt;RouterA: NS (请求网关 2001:db8:1::1 的 MAC) RouterA-\u0026gt;\u0026gt;PC1: NA (回应自己的 MAC) PC1-\u0026gt;\u0026gt;RouterA: IP 数据包 {src=2001:db8:1::10, dst=2001:db8:2::20} RouterA-\u0026gt;\u0026gt;RouterB: 路由查找，准备从接口B转发 RouterB-\u0026gt;\u0026gt;PC2: NS (请求 2001:db8:2::20 的 MAC) PC2-\u0026gt;\u0026gt;RouterB: NA RouterB-\u0026gt;\u0026gt;PC2: IP 数据包 {src=2001:db8:1::10, dst=2001:db8:2::20} IPv6 ND proxy 具有相同前缀的主机间互访的时候，不会查找路由表，只会发NS（Neighbor Solicitation）请求，获取目的地址对应的链路层地址，然后使用该链路层地址封装要发送的数据报文。\n在实际组网中，具有相同前缀的主机可能不在一个网络广播域当中，这种情况下NS（Neighbor Solicitation）报文不能发送到目的主机，导致主机间不能互访。\n为了避免此问题，可以开启路由器的ND Proxy功能，用于替代目的主机回应NA（Neighbor Advertise）报文，报文中会携带路由器的链路层地址。采用这种方式，两个主机可以通过路由器设备完成互访\nsequenceDiagram participant PC1 participant 路由器 as A-路由器-B participant PC2 Note over PC1, PC2: PC1 需要向 PC2 发送数据报文 PC1-\u0026gt;\u0026gt;路由器: NS(请求 1234::2/64 的 MAC 地址)\u0026lt;br\u0026gt;通过接口A 路由器--\u0026gt;\u0026gt;PC1: NA(回应 1234::2/64 的 MAC 地址是接口A的MAC地址) PC1-\u0026gt;\u0026gt;路由器: 目的是 1234::2/64 的数据报文\u0026lt;br\u0026gt;通过接口A 路由器-\u0026gt;\u0026gt;PC2: 目的是 1234::2/64 的数据报文\u0026lt;br\u0026gt;通过接口B Note over PC2, PC1: PC2 需要向 PC1 发送数据报文 PC2-\u0026gt;\u0026gt;路由器: NS(请求 1234::1/64 的 MAC 地址)\u0026lt;br\u0026gt;通过接口B 路由器--\u0026gt;\u0026gt;PC2: NA(回应 1234::1/64 的 MAC 地址是接口B的MAC地址) PC2-\u0026gt;\u0026gt;路由器: 目的是 1234::1/64 的数据报文\u0026lt;br\u0026gt;通过接口B 路由器-\u0026gt;\u0026gt;PC1: 目的是 1234::1/64 的数据报文\u0026lt;br\u0026gt;通过接口A ","date":"2025-12-29T16:28:14+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/ipv6-nd-proxy/","title":"IPv6 ND proxy"},{"content":"DHCPv6 (Dynamic Host Configuration Protocol for IPv6) 为 IPv6 主机提供了一种有状态的地址配置机制。与 IPv4 DHCP 类似，DHCPv6 分配的地址也是有租期的，但其生命周期管理引入了更细致的状态和计时器机制。\n核心概念 在理解生命周期之前，需要了解以下几个关键参数，这些参数通常由 DHCPv6 服务器在 IA Address Option (IAADDR) 中下发：\nPreferred Lifetime (首选生命周期):\n地址处于“首选 (Preferred)”状态的时间长度。 在此期间，地址可以无限制地用于新的和现有的通信。 Valid Lifetime (有效生命周期):\n地址处于“有效 (Valid)”状态的总时间长度。 它总是大于或等于首选生命周期。 一旦超过这个时间，地址即变为“无效 (Invalid)”，不能再使用。 T1 (Renew Timer - 更新计时器):\n客户端向分配该地址的特定服务器发起续租请求的时间点。 通常建议设置为首选生命周期的 0.5 倍。 T2 (Rebind Timer - 重绑定计时器):\n如果 T1 时刻续租失败，客户端向任意可用的服务器发起续租请求的时间点。 通常建议设置为首选生命周期的 0.8 倍。 地址状态流转 IPv6 地址在生命周期中会经历以下几种状态：\nTentative (试探态): 客户端刚收到地址，正在进行重复地址检测 (DAD - Duplicate Address Detection)。 此时地址还不能用于通信。 如果 DAD 成功（无冲突），进入 Preferred 状态；如果失败，地址不可用。 Preferred (首选态): DAD 通过后，且当前时间 \u0026lt; Preferred Lifetime。 地址可以用于建立新的连接，也可以用于现有的连接。 这是地址正常工作的状态。 Deprecated (弃用态): Preferred Lifetime \u0026lt; 当前时间 \u0026lt; Valid Lifetime。 地址依然“有效”，现有的连接可以继续使用该地址（为了不中断正在进行的会话）。 但是，上层应用不应使用该地址建立新的连接（源地址选择算法会避免选它）。 Invalid (无效态): 当前时间 \u0026gt; Valid Lifetime。 地址从接口上删除，彻底不可用。Microsoft 365 生命周期流程详解 分配 (Allocation): 客户端通过 Solicit/Advertise/Request/Reply 四步交互（或两步 Rapid Commit）获取地址及 T1, T2, Lifetimes 参数。 DAD 检测: 客户端对新地址进行 DAD 检测。 使用 (Usage): 进入 Preferred 状态，T1, T2, Lifetime 倒计时开始。 更新 (Renew - T1): 当达到 T1 时间，客户端发送 Renew 报文给原服务器。 如果服务器回复 Reply 并刷新了时间，生命周期重置，回到初始 Preferred 状态。 重绑定 (Rebind - T2): 如果 T1 期间没收到回复，客户端继续使用地址。 当达到 T2 时间，客户端发送 Rebind 报文广播给所有服务器。 如果有服务器回复，生命周期重置。 弃用 (Deprecation): 如果 T2 也没成功，且时间超过了 Preferred Lifetime，地址进入 Deprecated 状态。 停止建立新连接。 过期 (Expiration): 时间超过 Valid Lifetime，地址被回收。 stateDiagram-v2 [*] --\u0026gt; Tentative Tentative --\u0026gt; Preferred : DAD 成功 Tentative --\u0026gt; [*] : DAD 失败 Preferred --\u0026gt; Deprecated : t \u0026gt; Preferred Lifetime Deprecated --\u0026gt; Invalid : t \u0026gt; Valid Lifetime Preferred --\u0026gt; Invalid : t \u0026gt; Valid Lifetime Preferred --\u0026gt; Preferred : Renew/Rebind 成功 ","date":"2025-12-24T11:39:28+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/dhcpv6-address-lifecycle/","title":"DHCPv6 Address Lifecycle"},{"content":"本文介绍 Wi-Fi 物理层协商速率（PHY Rate）的计算方法，并提供 802.11ac (Wi-Fi 5) 和 802.11ax (Wi-Fi 6) 的 MCS (Modulation and Coding Scheme) 表。\n计算公式 Wi-Fi 的理论物理层速率可以通过以下公式计算：\n$$ \\text{Data Rate} = N_{ss} \\times \\frac{N_{sd} \\times N_{bps} \\times R}{T_{sym}} $$例如 ac 40Mhz 4x4 的最大速率 $ \\text{Rate} = 4 \\times \\frac{108 \\times 8 \\times (5/6)}{3.6 \\mu s} = 800 Mbps$\n其中各参数含义如下：\n参数 含义 说明 $N_{ss}$ Spatial Streams 空间流数量 (MIMO)，例如 1x1, 2x2, 3x3, 4x4。$Nss,max=min(N_{Tx},N_{Rx})$ $N_{sd}$ Data Subcarriers 数据子载波数量。取决于信道带宽 (20/40/80/160 MHz) 和协议标准 (11n/ac/ax)。 $N_{bps}$ Bits per Symbol 每个符号携带的比特数。由调制方式决定 (e.g., 64-QAM = 6 bits, 256-QAM = 8 bits, 1024-QAM = 10 bits)。 $R$ Coding Rate 编码率。有效数据位与总传输位（含纠错码）的比率 (e.g., 3/4, 5/6)。 $T_{sym}$ Symbol Duration 符号持续时间。$T_{sym} = T_{base} + T_{GI}$ (Guard Interval)。 简化理解 速率主要由以下几个维度决定：\n频宽 (Bandwidth): 车道越宽，通过的车越多 (20MHz vs 160MHz)。\n调制方式 (Modulation): 车装的货越多 (QAM 阶数越高)。\nMIMO (Spatial Streams): 高架桥层数越多 (天线数)。\n保护间隔 (Guard Interval): 车距越小，发车越快。 符号持续时间 标准 子载波间隔 基础符号时间 ($T_{base}$) 保护间隔 ($T_{GI}$) 总符号时间 ($T_{sym}$) 802.11n/ac 312.5 kHz 3.2 µs 0.4 µs (Short GI) 3.6 µs 802.11n/ac 312.5 kHz 3.2 µs 0.8 µs (Long GI) 4.0 µs 802.11ax 78.125 kHz 12.8 µs 0.8 µs 13.6 µs 802.11ax 78.125 kHz 12.8 µs 1.6 µs 14.4 µs 802.11ax 78.125 kHz 12.8 µs 3.2 µs 16.0 µs 数据子载波数量 频宽 (Bandwidth) 802.11ac (Wi-Fi 5) 802.11ax (Wi-Fi 6) 20 MHz 52 234 40 MHz 108 468 80 MHz 234 980 160 MHz 468 1960 802.11ac: 使用 312.5 kHz 的子载波间隔, 802.11ax: 使用更密集的 78.125 kHz 子载波间隔（是 ac 的 1/4） 20MHz/312.5kHz=64,这个 64 正是 Wi-Fi (802.11ac) 在 20MHz 频宽下的 FFT 大小 (总子载波数量)。但在实际传输中，并不是这 64 个子载波都能用来传数据。为了避免干扰和同步信号.它们被分配如下52(数据子载波)+4(导频子载波)+1(直流子载波)+7(保护子载波)=64;802.11ax的 234+8+3+11=256\n802.11ac (Wi-Fi 5) MCS 表 标准特性:\n最高支持 256-QAM (MCS 8, 9)。\n支持 20/40/80/160 MHz 频宽。\nGuard Interval (GI): Long (800ns), Short (400ns)。\n以下表格展示 单流 (1 Spatial Stream) 在 Short GI (400ns) 下的速率 (Mbps)。\n如果是多流 (如 2x2)，将下表速率乘以 2 即可。\nMCS Index Modulation Coding Rate 20 MHz 40 MHz 80 MHz 160 MHz 0 BPSK 1/2 7.2 15.0 32.5 65.0 1 QPSK 1/2 14.4 30.0 65.0 130.0 2 QPSK 3/4 21.7 45.0 97.5 195.0 3 16-QAM 1/2 28.9 60.0 130.0 260.0 4 16-QAM 3/4 43.3 90.0 195.0 390.0 5 64-QAM 2/3 57.8 120.0 260.0 520.0 6 64-QAM 3/4 65.0 135.0 292.5 585.0 7 64-QAM 5/6 72.2 150.0 325.0 650.0 8 256-QAM 3/4 86.7 180.0 390.0 780.0 9 256-QAM 5/6 N/A 200.0 433.3 866.7 注: 常见的 \u0026ldquo;433 Mbps\u0026rdquo; 就是 11ac 1x1 80MHz MCS9 的速率；\u0026ldquo;866 Mbps\u0026rdquo; 是 2x2 的速率。\n802.11ax (Wi-Fi 6) MCS 表 标准特性:\n引入 1024-QAM (MCS 10, 11)。\n更高效的子载波利用率 (更多的数据子载波)。\nGuard Interval (GI): 0.8us, 1.6us, 3.2us。通常使用 0.8us 获得最高速率。\n以下表格展示 单流 (1 Spatial Stream) 在 0.8us GI 下的速率 (Mbps)。\nMCS Index Modulation Coding Rate 20 MHz 40 MHz 80 MHz 160 MHz 0 BPSK 1/2 8.6 17.2 36.0 72.1 1 QPSK 1/2 17.2 34.4 72.1 144.1 2 QPSK 3/4 25.8 51.6 108.1 216.2 3 16-QAM 1/2 34.4 68.8 144.1 288.2 4 16-QAM 3/4 51.6 103.2 216.2 432.4 5 64-QAM 2/3 68.8 137.6 288.2 576.5 6 64-QAM 3/4 77.4 154.9 324.3 648.5 7 64-QAM 5/6 86.0 172.1 360.3 720.6 8 256-QAM 3/4 103.2 206.5 432.4 864.7 9 256-QAM 5/6 114.7 229.4 480.4 960.8 10 1024-QAM 3/4 129.0 258.1 540.4 1080.9 11 1024-QAM 5/6 143.4 286.8 600.5 1201.0 注: Wi-Fi 6 的 \u0026ldquo;1201 Mbps\u0026rdquo; 是 2x2 80MHz MCS11 的速率 (600.5 * 2)。\n参考链接\nhttps://zhuanlan.zhihu.com/p/1944204299568677330\nhttps://www.openwrt.pro/post-74.html\n","date":"2025-12-12T15:25:55+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/wi-fi-%E9%80%9F%E7%8E%87%E8%AE%A1%E7%AE%97/","title":"Wi-Fi 速率计算"},{"content":" 聚类（clustering）是一种寻找数据之间内在结构的技术。聚类把全体数据实例组织成一些相似组，而这些相似组被称作簇。处于相同簇中的数据实例彼此相同，处于不同簇中的实例彼此不同。K-Means、AgglomerativeClustering、DBSCAN、MeanShift、SpectralClustering 等是常用的聚类方法。 K-Means 算法又名 K 均值算法，K-Means 算法中的 K 表示的是聚类为 K 个簇，Means 代表取每一个聚类中数据值的均值作为该簇的中心，或者称为质心，即用每一个类的质心对该簇进行描述。\nK-Means 算法原理 简介 K-Means 是一种广泛使用的无监督学习(没标准答案下去学习)算法，用于将数据点划分为 k 个簇（Cluster）。其目标是使同一簇内的数据点尽可能相似，而不同簇之间的数据点尽可能不同。\n算法原理 K-Means 算法是一个迭代过程，主要包含以下步骤：\n初始化 (Initialization): 随机选择 k 个数据点作为初始质心（Centroids）。 分配 (Assignment): 计算每个数据点到这 k 个质心的距离，并将每个数据点分配给最近的质心所代表的簇。 更新 (Update): 重新计算每个簇的质心。新的质心是该簇内所有数据点的平均值（均值）。 重复 (Repeat): 重复步骤 2 和 3，直到满足停止条件（例如：质心不再发生变化、达到最大迭代次数或误差平方和收敛） 数学公式 目标函数 K-Means 的目标是最小化簇内误差平方和(Within-Cluster Sum of Squares, WCSS)，也称为惯性（Inertia）。\n$$ J =SEE= \\sum_{i=1}^k\\sum_{x\\in C_i}||x-\\mu_i||^2 $$其中：\nJ 是目标函数值:整个数据集的误差平方和（Sum of Squared Error，SSE）。 k 是簇的数量。 $C_i$​ 是第 i 个簇。 X 是簇 $C_i$中的数据点。 $\\mu_i$是簇 $C_i$的质心。 $||x-\\mu_i||^2$ 是数据点 x 到质心 $\\mu_i$​ 的欧几里得距离的平方 质心更新公式 在第 t+1 次迭代中，簇$C_i$ 的新质心$\\mu_i^{(t+1)}$ 计算如下：\n$$ \\mu_i^{(t+1)} = \\frac{1}{|C_i^{(t)}|} \\sum_{x\\in C_i^{(t)}} x $$其中 $|C_i^{(t)}|$ 是第 t 次迭代中簇 $C_i$内数据点的数量。\n简单样例说明 假设我们有以下一维数据点：[2, 4, 10, 12, 3, 20, 30, 11, 25]，我们想将其分为 k=2 个簇。\n初始化: 随机选 2 和 30 为质心。 μ1​=2, μ2​=30 分配: 靠近 2 的点: {2, 3, 4, 10, 11, 12} -\u0026gt; 簇 1 靠近 30 的点: {20, 25, 30} -\u0026gt; 簇 2 更新: 新 μ1​=(2+3+4+10+11+12)/6=42/6=7 新 μ2​=(20+25+30)/3=75/3=25 迭代: 使用新质心 7 和 25 重新分配，直到质心稳定 Python 代码样例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 import numpy as np import matplotlib.pyplot as plt from sklearn.datasets import make_blobs from matplotlib.animation import FuncAnimation # ========================================== # 1. 数据准备 # ========================================== print(\u0026#34;Generating data...\u0026#34;) X, y_true = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=0) # ========================================== # 2. K-Means 算法手动实现 (为了记录每一步) # ========================================== class KMeansManual: def __init__(self, X, k=4): self.X = X self.k = k # 随机选择k个点作为初始质心 indices = np.random.choice(X.shape[0], k, replace=False) self.centroids = X[indices] self.labels = None self.history = [] # 用于存储每一步的状态: (centroids, labels, title) def run(self, max_iters=10): # 记录初始状态 self.history.append((self.centroids.copy(), None, \u0026#34;Initialization\u0026#34;)) for i in range(max_iters): # --- 步骤 1: 分配 (Assignment) --- # 计算距离矩阵: (k, n_samples) # 利用广播机制计算每个点到每个质心的欧氏距离 distances = np.linalg.norm(self.X[:, np.newaxis] - self.centroids, axis=2) # 获取最近质心的索引 self.labels = np.argmin(distances, axis=1) # 记录分配后的状态 self.history.append((self.centroids.copy(), self.labels.copy(), f\u0026#34;Iteration {i+1}: Assignment\u0026#34;)) # --- 步骤 2: 更新 (Update) --- new_centroids = np.array([ self.X[self.labels == j].mean(axis=0) if np.sum(self.labels == j) \u0026gt; 0 else self.centroids[j] for j in range(self.k) ]) # 记录更新质心后的状态 self.history.append((new_centroids.copy(), self.labels.copy(), f\u0026#34;Iteration {i+1}: Update Centroids\u0026#34;)) # --- 检查收敛 --- if np.allclose(self.centroids, new_centroids): print(f\u0026#34;Converged at iteration {i+1}\u0026#34;) break self.centroids = new_centroids # 运行算法 k = 4 kmeans = KMeansManual(X, k=k) kmeans.run() # ========================================== # 3. 动画可视化 # ========================================== print(\u0026#34;Starting animation...\u0026#34;) fig, ax = plt.subplots(figsize=(10, 7)) def update(frame_idx): ax.clear() centroids, labels, title = kmeans.history[frame_idx] # 绘制数据点 if labels is None: # 初始状态，未分类，显示为灰色 ax.scatter(X[:, 0], X[:, 1], c=\u0026#39;gray\u0026#39;, s=50, alpha=0.5) else: # 已分类，按类别着色 ax.scatter(X[:, 0], X[:, 1], c=labels, s=50, cmap=\u0026#39;viridis\u0026#39;, alpha=0.6) # 绘制质心 (红色大叉) ax.scatter(centroids[:, 0], centroids[:, 1], c=\u0026#39;red\u0026#39;, s=200, marker=\u0026#39;X\u0026#39;, edgecolors=\u0026#39;white\u0026#39;, linewidths=2, label=\u0026#39;Centroids\u0026#39;) # 绘制质心移动轨迹 (可选，如果不是第一帧) if frame_idx \u0026gt; 0: prev_centroids, _, _ = kmeans.history[frame_idx-1] # 简单的绘制从上一个位置到当前位置的线 for i in range(k): ax.plot([prev_centroids[i, 0], centroids[i, 0]], [prev_centroids[i, 1], centroids[i, 1]], \u0026#39;k--\u0026#39;, alpha=0.5) ax.set_title(title, fontsize=14) ax.set_xlabel(\u0026#34;Feature 1\u0026#34;) ax.set_ylabel(\u0026#34;Feature 2\u0026#34;) ax.legend() ax.grid(True, alpha=0.3) # 创建动画 # interval=1000 表示每帧停留 1000ms (1秒) ani = FuncAnimation(fig, update, frames=len(kmeans.history), interval=2000, repeat=True) plt.show() K-Means算法的问题 K如何确定 手肘法 算法所需要预设的参数至少有2个：簇个数K和初始簇质心\n聚类的目标是使得每个样本点到距离其最近的聚类中心的总误差平方和(SSE)尽可能小。\n理论上随着K的增加，SSE会单调递减，因为类数的增加意味着总有一部分样本点会因为归属到新的类簇而节约下一段距离，直到K=N时，情况将演变为每个样本自成一类，此时SSE值就会降为0,这也就没意义了。\n根据学者们的长期实践经验，K值最大不应超过样本量的开平方根，即$K_{max}\u0026lt;= \\sqrt N$ 。而确定了范围后，最优K值又应该怎么判断？一种简单的思路是：试图找到某一个K值，要求当K大于该值时，SSE的下降变化幅度（或速度）明显变小。换句话说，当K超过某一个数后，每个类簇的聚合程度不再获得显著提升，此时我们就可以认为已找到最佳K的取值。这也是手肘法通过画出不同K值与SSE值的折线图，若SSE值下降过程中存在“肘点”（下降速度骤减的拐点处），该点所对应的K值即合适的聚类数。不过遗憾的是，若SSE的下降是均匀的，传统的肘部图法也就失灵了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 import numpy as np import matplotlib.pyplot as plt from sklearn.cluster import KMeans from sklearn.datasets import make_blobs # ========================================== # 1. 数据准备 # ========================================== print(\u0026#34;Generating data...\u0026#34;) # 生成稍微复杂一点的数据，以便观察肘部 X, y_true = make_blobs(n_samples=500, centers=5, cluster_std=0.8, random_state=42) # ========================================== # 2. 计算不同 K 值的 WCSS (Inertia) # ========================================== wcss = [] # Within-Cluster Sum of Squares (簇内误差平方和) k_range = range(1, 11) # 测试 k 从 1 到 10 print(\u0026#34;Calculating WCSS for different k values...\u0026#34;) for k in k_range: kmeans = KMeans(n_clusters=k, random_state=42) kmeans.fit(X) wcss.append(kmeans.inertia_) # inertia_ 属性就是 WCSS print(f\u0026#34;k={k}, WCSS={kmeans.inertia_:.2f}\u0026#34;) # ========================================== # 3. 绘制肘部图 (Elbow Plot) # ========================================== plt.figure(figsize=(10, 6)) plt.plot(k_range, wcss, marker=\u0026#39;o\u0026#39;, linestyle=\u0026#39;-\u0026#39;, color=\u0026#39;b\u0026#39;) # 标注轴和标题 plt.title(\u0026#39;Elbow Method For Optimal k (肘部法则)\u0026#39;, fontsize=16) plt.xlabel(\u0026#39;Number of clusters (k)\u0026#39;, fontsize=12) plt.ylabel(\u0026#39;WCSS (Inertia)\u0026#39;, fontsize=12) plt.xticks(k_range) plt.grid(True) # 标记可能的肘部点 (在这个例子中，我们知道真实中心是5，所以肘部应该在5附近) # 这里为了演示，我们简单标注一下 k=5 的位置 optimal_k = 5 plt.annotate(f\u0026#39;Possible Elbow Point (k={optimal_k})\u0026#39;, xy=(optimal_k, wcss[optimal_k-1]), xytext=(optimal_k+1, wcss[optimal_k-1]+1000), arrowprops=dict(facecolor=\u0026#39;red\u0026#39;, shrink=0.05), fontsize=12, color=\u0026#39;red\u0026#39;) plt.show() 轮廓系数（Silhouette Coefficient）法 是一种用于评估聚类效果并帮助确定最优聚类数 K 的方法。它结合了凝聚度（cohesion）和分离度（separation）两个指标\n轮廓系数的定义 对于数据集中的每一个样本点 $x_i$​，其轮廓系数 $s(i)$ 定义为：\n$$ s(i) = \\frac{b(i) - a(i)}{\\max\\{a(i), b(i)\\}} $$其中： a(i)：样本 xi​ 到同簇内其他点的平均距离（衡量凝聚度）。 b(i)：样本 xi​ 到最近的其他簇中所有点的平均距离（衡量分离度）。\n轮廓系数的取值范围为 [−1,1]： - 接近 1：表示样本聚类合理，簇内紧密、簇间分离良好。 - 接近 0：表示样本在两个簇边界上。 - 接近 -1：表示样本可能被分配到了错误的簇。\n使用轮廓系数确定 K 值的步骤 对不同的 K 值（如 K=2,3,\u0026hellip;,Kmax​）运行 K-means 聚类。 对每次聚类结果，计算每个样本的轮廓系数，再求所有样本的平均轮廓系数。 选择使平均轮廓系数最大的 K 值作为最优聚类数. 注意：轮廓系数法假设簇是凸形且大小相近的，对于非球形或密度差异大的簇可能不适用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 import numpy as np import matplotlib.pyplot as plt from sklearn.cluster import KMeans from sklearn.datasets import make_blobs from sklearn.metrics import silhouette_score # ========================================== # 1. 数据准备 # ========================================== print(\u0026#34;Generating data...\u0026#34;) # 生成与之前类似的模拟数据，预设中心为 5 X, y_true = make_blobs(n_samples=500, centers=5, cluster_std=0.8, random_state=42) # ========================================== # 2. 计算不同 K 值的轮廓系数 (Silhouette Score) # ========================================== silhouette_scores = [] # 注意：轮廓系数至少需要 2 个簇才能计算，所以从 k=2 开始 k_range = range(2, 11) print(\u0026#34;Calculating Silhouette Scores for different k values...\u0026#34;) for k in k_range: kmeans = KMeans(n_clusters=k, random_state=42) labels = kmeans.fit_predict(X) # 计算所有样本的平均轮廓系数 # 轮廓系数范围是 [-1, 1]，越接近 1 表示聚类效果越好 score = silhouette_score(X, labels) silhouette_scores.append(score) print(f\u0026#34;k={k}, Silhouette Score={score:.4f}\u0026#34;) # ========================================== # 3. 绘制轮廓系数图 # ========================================== plt.figure(figsize=(10, 6)) plt.plot(k_range, silhouette_scores, marker=\u0026#39;o\u0026#39;, linestyle=\u0026#39;-\u0026#39;, color=\u0026#39;g\u0026#39;, linewidth=2) # 标注轴和标题 plt.title(\u0026#39;Silhouette Method For Optimal k\u0026#39;, fontsize=16) plt.xlabel(\u0026#39;Number of clusters (k)\u0026#39;, fontsize=12) plt.ylabel(\u0026#39;Silhouette Score (Avg)\u0026#39;, fontsize=12) plt.xticks(k_range) plt.grid(True, alpha=0.3) # 标记最高分 (最佳 K 值) best_k_idx = np.argmax(silhouette_scores) best_k = k_range[best_k_idx] best_score = silhouette_scores[best_k_idx] plt.annotate(f\u0026#39;Best k={best_k}\\nScore={best_score:.3f}\u0026#39;, xy=(best_k, best_score), xytext=(best_k, best_score - 0.1), # 文本位置稍微往下一点 arrowprops=dict(facecolor=\u0026#39;red\u0026#39;, shrink=0.05), fontsize=12, color=\u0026#39;red\u0026#39;, ha=\u0026#39;center\u0026#39;) print(f\u0026#34;The optimal k according to Silhouette Score is {best_k}\u0026#34;) plt.show() 间隔统计法（gap statistic） Gap统计量基于以下假设：如果聚类是有意义的，那么数据集中的样本点应该比随机数据更紧密地聚集在一起。因此，Gap统计量计算了实际数据集的WCSS与随机数据集WCSS的期望值之间的差异。\n对于每一个K值，首先运行K-means算法，得到一个群内平方和。 然后，生成一组随机数据，并用相同的K值运行K-means算法。 比较真实数据的群内平方和和随机数据的结果，并计算他们之间的差距（称之为间隔值）。 对于多个K值，重复以上步骤，并选择拥有最大间隔值的K 初始的簇质心的选取 常用分析软件中的功能模块或函数包，基本上都已经代替使用者们自动预设了随机初始点，只需填入目标K值，就可以跑动算法。但实际上，K-Means对初始聚类中心的位置十分敏感，每次迭代，初始点的不同往往会导致不同的聚类结果。此外过于临近的初始中心点，有时还会导致模型的收敛时间变长（即Step4中迭代时间变长）。一种简单粗暴的解决方式是，选择不同的初始聚类中心，多次运行算法，挑出聚类效果更佳（SSE更小）、解释性更强的一组结果。\n当然了，我们或许更想知道算法上的改进手段。一种常见的优化方法是采用最大距离法，如：首先选取数据集中距离最大的两个点作为初始聚类中心，将剩余数据对象依据到聚类中心点距离的远近分配到相应的簇中，并更新聚类中心，然后继续寻找与聚类中心距离最远的点作为下一个中心点……\n与此类似地还有K-Means++ 算法，它是传统K-Means的改良版，同样是基于最大距离，这里结合加权概率的思想优化了对K个初始中心的选取，使得在选取第n+1(n+1\u0026lt;k)个聚类中心时，距离当前n个聚类中心越远的点会有更高的概率被选为第n+1个聚类中心。还有学者从点集密度的角度改进，又或者将优化搜索算法（如模拟退火、生物遗传算法等）运用到了聚类中心的选取中\u0026hellip;\u0026hellip;\n相似性与距离度量问题 特征量化后，不同个体的相似性反映在了向量之间的空间距离大小，常见的度量方法包括欧几里得距离、曼哈顿距离等等，有时我们还会用到余弦相似度等（如计算文档相似性）。而通常情况下，欧氏距离计算就可以满足我们对实现K-Means的需要。根据距离的度量方式容易发现，K-Means所划分出的类别是类球形的，换句话说，只有类球型分布的连续型样本数据，才能得到较好的聚类效果，而如果非数值型、样本类别极不平衡、非球形的分类，则聚类效果会受限。对于非理想情形的数据，有时我们就需要做一些灵活变通了。如，若数据为离散型，均值没有定义，我们可以采用K-众数(每个簇的质心不是均值，而是每个维度上出现频率最高的类别)的方法。如果样本类别极不平衡或者是非球型，则可能考虑更换聚类方法，如使用基于密度的聚类（经典的DBSCAN算法）、层次聚类法等等。\n聚类时间问题 上面的流程中提到，当聚类中心不再改变时（数学上即要求SSE函数收敛），我们认为聚类过程结束，但是这并不是唯一的结束信号。为了节省计算时间，有时我们也会通过设置迭代次数、设置簇内平方和或SSE下降阈值，又或者替换为“直到仅有1%的点改变簇”这样的弱条件，来控制算法的进程。出于对问题复杂度和计算量的合理预判，若聚类中心的更新超过了迭代次数上限，或者代价函数SSE已经小于所设定的阈值，我们都有理由提前终止。\n此外，为了提高收敛速度，还可以考虑采用二分K-Means法，将所有点作为一个簇，将该簇一分为二，然后选择能最大程度降低聚类代价函数的簇划分为两个簇，以此进行下去，直到簇的数目等于给定的个数K为止。值得一提的是，该法更突出的优点在于能够很好地解决K-Means收敛到局部最优的问题，帮助我们找到全局最优解\n标准化问题 考虑到我们所研究的对象通常包含多列数据，这些数据代表不同方面的属性值，在单位和数量级上可能存在较大的差别，因此为了避免这些差异可能引发的计算精度下降等问题，对于连续属性，可以先对数据进行规范化处理（如零均值规范化、最大最小值规范化等），再进行距离的计算\n","date":"2025-12-01T17:11:41+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/k-means-%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/","title":"K-Means 聚类算法"},{"content":" 智能体（Agent）与 MCP 简介 智能体（AI Agent） 发展脉络：\n2023 年：AutoGPT 等自治代理出现，将 GPT-4 与工具循环结合，标志着“让 LLM 自主执行复杂任务”的探索开始，被视为 智能体元年。 2024 年：LangChain、HuggingGPT、MetaGPT 等框架涌现，支持构建单/多智能体系统；产业界高度关注，IDC 预测 2026 年 50% 的大型企业数据团队将使用 AI Agent，Gartner 将 “Agentic AI” 列为 2025 年首要技术趋势。 核心机制：\n智能体赋予 LLM 自主决策与行动能力，不再只是被动回答。\n采用 “思考–行动–观察”循环机制：\n思考：LLM 接收目标后进行推理； 行动：决定调用工具（如搜索、执行代码）； 观察：获取环境反馈，继续迭代直至任务完成。 在大模型生态中的角色：\n智能体是 连接大模型与实际应用的桥梁。\n封装业务逻辑、工具调用（如 Function Calling、RAG），将企业知识库、数据库、第三方服务融入决策。\n扮演“大脑指挥官”，协调记忆、规划、工具接口等模块，驱动任务流程。\n例如：客服场景中，智能体可自主引导对话、查询数据库、转接人工，提升解决率。\nMCP（Model Context Protocol，模型上下文协议） 起源与概念：\n由 Anthropic 团队于 2024 年 11 月提出，受“语言服务器协议（LSP）”启发。 被誉为 AI 世界的“USB-C 接口”，提供模型与外部工具/数据交互的统一标准。 解决问题：此前各模型厂商的 Function Calling 实现五花八门，开发者需为每种模型+工具编写特定集成代码，繁琐且难扩展。 作用： 通过 标准化协议，让 LLM 能便捷接入数据库、搜索引擎、插件等外部资源。 支持 检索增强（RAG）、实时数据查询、API 调用等，突破训练语料限制。 提升回答的 准确性、实时性与行动能力。 LLM、智能体、MCP 定位与职责 组件 角色 职责 智能体（Agent） MCP 主机 / 用户交互入口 接收用户请求，调用 LLM，整合工具结果，返回最终答案 大模型（LLM） 智能体的“大脑” 理解用户意图，推理决策，判断是否调用工具，生成结构化调用指令或最终回复 MCP 客户端（Client） LLM 与外部资源的“信使” 解析 LLM 的工具调用请求，按 MCP 协议转发给对应服务器 MCP 服务器（Server） 工具/数据提供者 提供 Tools（可执行函数） 和 Resources（数据源），执行操作并返回结果 💡 补充：智能体应用通常内置 MCP 客户端，可同时连接多个 MCP 服务器。开发者只需将工具以 MCP Server 形式暴露，即可被任意兼容 MCP 的 LLM 调用。\n调用与通信顺序（完整交互流程） 以下以“用户询问：明天想在上海玩一天，看看天气，怎么安排行程？”为例：\n用户提问 → 在前端输入问题。\n智能体转发问题 → 将用户请求 + 上下文 + 可用工具列表发送给 LLM。\nLLM 理解与决策 → 判断是否需外部信息。若需（如查天气），进入工具调用流程。\nLLM 发出函数调用请求 → 输出结构化指令，例如：\n1 2 3 4 5 6 7 8 { \u0026#34;tool_calls\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;get_weather\u0026#34;, \u0026#34;arguments\u0026#34;: { \u0026#34;city\u0026#34;: \u0026#34;上海\u0026#34; } } ] } MCP 客户端解析并调用工具 → 识别调用请求，通过 MCP 协议（如 JSON-RPC 2.0）转发给对应 MCP 服务器。\nMCP 服务器执行操作 → 调用内部函数（如访问天气 API），获取实时数据。\n返回执行结果 → 服务器将结果（如 JSON 或文本）返回给客户端，客户端传回 LLM。\nLLM 生成最终答案 → 结合原始问题 + 外部数据，生成完整回复（如包含天气的游玩攻略）。\n结果返回用户 → 智能体将最终答案展示给用户，任务完成。\n✅ 整个流程形成闭环：用户 → Agent → LLM → MCP Client → MCP Server → LLM → Agent → 用户\n总结 LLM 是推理核心，但缺乏实时性和行动力；\nAgent 赋予 LLM 目标导向的自主性，是落地关键；\nMCP 提供标准化“插拔式”接口，极大降低工具集成成本；\n三者协作，使大模型从“聊天机器人”进化为“数字员工”，真正解决复杂业务问题。\n转载自 https://zhuanlan.zhihu.com/p/1910411281988588717\n","date":"2025-11-24T14:44:59+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/agentmcp%E4%B8%8Ellm/","title":"Agent、MCP与LLM"},{"content":"修改/etc下的文件 通常/etc下的文件都是read-only的，但是可以通过临时 overlay 或 bind mount去绕过只读限制\n1 2 3 4 5 6 7 8 9 10 mkdir /tmp/etc # 挂载一个可写的 tmpfs 到 /tmp/etc mount -t tmpfs tmpfs /tmp/etc # 复制原 /etc 内容 cp -a /etc/* /tmp/etc/ # 重新挂载到 /etc（需要支持 bind mount） mount --bind /tmp/etc /etc 这样 /etc 就可写了，但重启后失效。适用于临时调试\n","date":"2025-09-28T16:37:56+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/linux%E6%9D%82%E8%AE%B0/","title":"Linux杂记"},{"content":"Linux网桥的实现 linux内核实现虚拟的网桥设备，并绑定若干个以太网口（目前网桥只支持以太网接口）。 交换机对收到的数据包，只能丢弃或转发。但是linux内核设备不一样，他可能本身就是数据包的目的地。所以除了丢弃转发，他还会发往协议层自己消化。 网桥是在数据链路层实现的，他的上面是邻居子系统和网络层。\nlinux网桥数据结构 虚拟网桥也是一个网络设备，基本结构体为net_device，net_device –\u0026gt; priv下存储了网桥数据结构的私有变量net_bridge。上图中一些重要的数据结构如下：\nnet_bridge：网桥私有数据\nnet_bridge_port网桥要绑定的以太网端口的结构体\nnet_bridge_fdb_entry：单播转发数据库条目\nnet_bridge_mdb_entry：组播转发数据库条目\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 int br_add_bridge(struct net *net, const char *name) { struct net_device *dev; int res; dev = alloc_netdev(sizeof(struct net_bridge), name, NET_NAME_UNKNOWN, br_dev_setup); ////// if (!dev) return -ENOMEM; dev_net_set(dev, net); dev-\u0026gt;rtnl_link_ops = \u0026amp;br_link_ops; res = register_netdevice(dev); if (res) free_netdev(dev); return res; } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 void br_dev_setup(struct net_device *dev) { struct net_bridge *br = netdev_priv(dev); ///////// eth_hw_addr_random(dev); ether_setup(dev); dev-\u0026gt;netdev_ops = \u0026amp;br_netdev_ops; dev-\u0026gt;needs_free_netdev = true; dev-\u0026gt;ethtool_ops = \u0026amp;br_ethtool_ops; SET_NETDEV_DEVTYPE(dev, \u0026amp;br_type); dev-\u0026gt;priv_flags = IFF_EBRIDGE | IFF_NO_QUEUE; dev-\u0026gt;features = COMMON_FEATURES | NETIF_F_LLTX | NETIF_F_NETNS_LOCAL | NETIF_F_HW_VLAN_CTAG_TX | NETIF_F_HW_VLAN_STAG_TX; dev-\u0026gt;hw_features = COMMON_FEATURES | NETIF_F_HW_VLAN_CTAG_TX | NETIF_F_HW_VLAN_STAG_TX; dev-\u0026gt;vlan_features = COMMON_FEATURES; br-\u0026gt;dev = dev; ////////////////// spin_lock_init(\u0026amp;br-\u0026gt;lock); INIT_LIST_HEAD(\u0026amp;br-\u0026gt;port_list); //////////// INIT_HLIST_HEAD(\u0026amp;br-\u0026gt;fdb_list); //////////// INIT_HLIST_HEAD(\u0026amp;br-\u0026gt;frame_type_list); #if IS_ENABLED(CONFIG_BRIDGE_MRP) INIT_HLIST_HEAD(\u0026amp;br-\u0026gt;mrp_list); #endif #if IS_ENABLED(CONFIG_BRIDGE_CFM) INIT_HLIST_HEAD(\u0026amp;br-\u0026gt;mep_list); #endif spin_lock_init(\u0026amp;br-\u0026gt;hash_lock); br-\u0026gt;bridge_id.prio[0] = 0x80; br-\u0026gt;bridge_id.prio[1] = 0x00; ether_addr_copy(br-\u0026gt;group_addr, eth_stp_addr); br-\u0026gt;stp_enabled = BR_NO_STP; br-\u0026gt;group_fwd_mask = BR_GROUPFWD_DEFAULT; br-\u0026gt;group_fwd_mask_required = BR_GROUPFWD_DEFAULT; br-\u0026gt;designated_root = br-\u0026gt;bridge_id; br-\u0026gt;bridge_max_age = br-\u0026gt;max_age = 20 * HZ; br-\u0026gt;bridge_hello_time = br-\u0026gt;hello_time = 2 * HZ; br-\u0026gt;bridge_forward_delay = br-\u0026gt;forward_delay = 15 * HZ; br-\u0026gt;bridge_ageing_time = br-\u0026gt;ageing_time = BR_DEFAULT_AGEING_TIME; dev-\u0026gt;max_mtu = ETH_MAX_MTU; br_netfilter_rtable_init(br); br_stp_timer_init(br); br_multicast_init(br); INIT_DELAYED_WORK(\u0026amp;br-\u0026gt;gc_work, br_fdb_cleanup); } 1 2 3 4 static inline void *netdev_priv(const struct net_device *dev) { return (char *)dev + ALIGN(sizeof(struct net_device), NETDEV_ALIGN); } 简单来说，struct net_device 是桥的“外壳”或“接口”，而 struct net_bridge 是桥的“大脑”或“核心逻辑”。它们通过一个关键的指针相互关联。下面我们进行详细分解。\n核心数据结构\nstruct net_device： 这个结构体代表一个网络接口，无论它是物理的（如 eth0）还是虚拟的（如 br-lan, veth0）。它包含了所有网络设备共有的信息，例如：\n接口名称（name，如 \u0026ldquo;br-lan\u0026rdquo;）\nMAC 地址（dev_addr）\n接口状态（UP/DOWN）\n发送和接收数据包的函数指针（netdev_ops）\n统计信息（包计数、错误计数等）\n一个非常重要的成员：priv_flags 和 rx_handler（后面会讲到）\n指向net_device私有数据的一个通用指针：priv（对于桥设备，它指向 struct net_bridge,通过 netdev_priv(dev) 宏来获取 priv 指针的地址\nstruct net_bridge： 这个结构体是专门为桥接功能定义的，它包含了管理一个桥所需的所有信息，例如：\n桥的 STP（生成树协议）状态和配置。\n桥的 MAC 地址（通常取自第一个被加入的端口）。\n端口列表（port_list）： 一个链表，包含了所有加入这个桥的端口（如 eth0, eth1）。每个端口由一个 struct net_bridge_port 表示。\n转发数据库（FDB）：一个哈希表，用于学习和管理 MAC 地址到端口的映射。\n指向其对应的 net_device 的指针。\n关键关联机制 关联是在创建桥设备（例如使用 brctl addbr br-lan 或 ip link add br-lan type bridge）时建立的。整个过程的核心是 netdev_priv() 机制。\n分配 net_device 并嵌入 net_bridge 当内核需要创建一个新的桥设备时，它并不是先分配一个 net_device，再分配一个 net_bridge，然后用指针连接它们。相反，它使用了一种更高效、更常见的“嵌入式”方法：\n一次性分配内存： 内核调用 alloc_netdev(sizeof(struct net_bridge), \u0026ldquo;br-lan\u0026rdquo;, NET_NAME_UNKNOWN, br_dev_setup)。 alloc_netdev 会分配一块足够大的内存，这块内存的大小 = sizeof(struct net_device) + sizeof(struct net_bridge) + 一些对齐填充。这样，net_bridge 结构体就直接内嵌在 net_device 结构体之后的内存中。\n关联指针： 在 br_dev_setup 初始化函数中，会进行关键设置:设置 net_device-\u0026gt;priv_flags 为 IFF_EBRIDGE，标记这是一个桥设备。设置 net_device-\u0026gt;netdev_ops 为 br_netdev_ops，这意味着所有针对 br-lan 这个网络设备的操作（如打开、关闭、发送数据包）都由桥接模块提供的函数处理。最关键的一步：通过 netdev_priv(dev) 宏来获取 priv 指针的地址。由于内存布局是内嵌的，也就是紧跟着 net_device 结构体的那块内存的起始地址——而这正好就是我们为 net_bridge 分配的地方。 br-\u0026gt;dev = dev; // net_bridge 也保存一个指回 net_device 的指针\n数据包流向（接收路径） 关联建立后，数据包如何被桥处理呢？这涉及到另一个关键机制：RX 处理程序（RX handler）。当一个网络接口（例如 eth0）被加入到桥 br-lan 时（使用 brctl addif br-lan eth0），内核会调用 br_add_if()。 在这个函数中，会为 eth0 这个 net_device 安装一个RX处理程序：dev-\u0026gt;rx_handler = br_handle_frame。从此以后，所有从 eth0 接收到的数据包，在进入网络协议栈的更上层（如IP层）之前，会先被 br_handle_frame 这个函数截获。br_handle_frame 函数可以判断这个数据包所属的桥（通过 eth0 对应的 struct net_bridge_port 找到其所属的 struct net_bridge），然后进行桥接逻辑（学习MAC地址、转发、过滤等）。\n网桥私有数据：net_bridge 网桥相关信息保存在这里：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 struct net_bridge { spinlock_t lock; spinlock_t hash_lock; struct hlist_head frame_type_list; struct net_device *dev; /////// unsigned long options; /* These fields are accessed on each packet */ #ifdef CONFIG_BRIDGE_VLAN_FILTERING __be16 vlan_proto; u16 default_pvid; struct net_bridge_vlan_group __rcu *vlgrp; #endif struct rhashtable fdb_hash_tbl; ///// struct list_head port_list; ///// #if IS_ENABLED(CONFIG_BRIDGE_NETFILTER) union { struct rtable fake_rtable; struct rt6_info fake_rt6_info; }; #endif u16 group_fwd_mask; u16 group_fwd_mask_required; /* STP */ bridge_id designated_root; bridge_id bridge_id; unsigned char topology_change; unsigned char topology_change_detected; u16 root_port; unsigned long max_age; unsigned long hello_time; unsigned long forward_delay; unsigned long ageing_time; unsigned long bridge_max_age; unsigned long bridge_hello_time; unsigned long bridge_forward_delay; unsigned long bridge_ageing_time; u32 root_path_cost; u8 group_addr[ETH_ALEN]; enum { BR_NO_STP, /* no spanning tree */ BR_KERNEL_STP, /* old STP in kernel */ BR_USER_STP, /* new RSTP in userspace */ } stp_enabled; struct net_bridge_mcast multicast_ctx; #ifdef CONFIG_BRIDGE_IGMP_SNOOPING struct bridge_mcast_stats __percpu *mcast_stats; u32 hash_max; spinlock_t multicast_lock; struct rhashtable mdb_hash_tbl; //////// struct rhashtable sg_port_tbl; struct hlist_head mcast_gc_list; struct hlist_head mdb_list; ////// struct work_struct mcast_gc_work; #endif struct timer_list hello_timer; struct timer_list tcn_timer; struct timer_list topology_change_timer; struct delayed_work gc_work; struct kobject *ifobj; u32 auto_cnt; #ifdef CONFIG_NET_SWITCHDEV /* Counter used to make sure that hardware domains get unique * identifiers in case a bridge spans multiple switchdev instances. */ int last_hwdom; /* Bit mask of hardware domain numbers in use */ unsigned long busy_hwdoms; #endif struct hlist_head fdb_list; ///// #if IS_ENABLED(CONFIG_BRIDGE_MRP) struct hlist_head mrp_list; #endif #if IS_ENABLED(CONFIG_BRIDGE_CFM) struct hlist_head mep_list; #endif }; 网桥端口：net_bridge_port 一个网桥可以和若干以太网端口绑定，每个端口信息保存在net_bridge_port结构中，并被net_bridge{} –\u0026gt;port_list链接。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 struct net_bridge_port { struct net_bridge *br; //// struct net_device *dev; //// netdevice_tracker dev_tracker; struct list_head list; unsigned long flags; #ifdef CONFIG_BRIDGE_VLAN_FILTERING struct net_bridge_vlan_group __rcu *vlgrp; #endif struct net_bridge_port __rcu *backup_port; /* STP */ u8 priority; u8 state; u16 port_no; unsigned char topology_change_ack; unsigned char config_pending; port_id port_id; port_id designated_port; bridge_id designated_root; bridge_id designated_bridge; u32 path_cost; u32 designated_cost; unsigned long designated_age; struct timer_list forward_delay_timer; struct timer_list hold_timer; struct timer_list message_age_timer; struct kobject kobj; struct rcu_head rcu; struct net_bridge_mcast_port multicast_ctx; #ifdef CONFIG_BRIDGE_IGMP_SNOOPING struct bridge_mcast_stats __percpu *mcast_stats; u32 multicast_eht_hosts_limit; u32 multicast_eht_hosts_cnt; struct hlist_head mglist; #endif #ifdef CONFIG_SYSFS char sysfs_name[IFNAMSIZ]; #endif #ifdef CONFIG_NET_POLL_CONTROLLER struct netpoll *np; #endif #ifdef CONFIG_NET_SWITCHDEV /* Identifier used to group ports that share the same switchdev * hardware domain. */ int hwdom; int offload_count; struct netdev_phys_item_id ppid; #endif u16 group_fwd_mask; u16 backup_redirected_cnt; struct bridge_stp_xstats stp_xstats; }; 单播转发数据库条目：net_bridge_fdb_entry net_bridge中有两个字段与该结构体相关，fdb_hash_tbl与fdb_list，函数fdb_create（）可以看到net_bridge_fdb_entry与这连个字段的关系。每一条新建的fdb表项会加入br-\u0026gt;fdb_hash_tbl这个哈希表中，准确的说是br-\u0026gt;fdb_hash_tbl-\u0026gt;tbl，对应的键值是fdb表项的key字段（addr与vlan）。插入成功，则将该fdb表项的fdb_node插入br-\u0026gt;fdb_hash_tbl中。 也就说fdb表项分别以哈希表与链表的形式存储在br中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 struct net_bridge_fdb_entry { struct rhash_head rhnode; struct net_bridge_port *dst; struct net_bridge_fdb_key key; struct hlist_node fdb_node; unsigned long flags; /* write-heavy members should not affect lookups */ unsigned long updated ____cacheline_aligned_in_smp; unsigned long used; struct rcu_head rcu; }; 组播转发数据库条目：net_bridge_mdb_entry 该条目描述一个多播组转发项，将多播形式的mac地址与一组端口对应，timer链表为这些端口的失效定时器链表，某一个端口定时器超时则将其移除\n1 2 3 4 5 6 7 8 9 10 11 12 13 struct net_bridge_mdb_entry { struct rhash_head rhnode; struct net_bridge *br; struct net_bridge_port_group __rcu *ports; struct br_ip addr; bool host_joined; struct timer_list timer; struct hlist_node mdb_node; struct net_bridge_mcast_gc mcast_gc; struct rcu_head rcu; }; 网桥设备对数据包处理 以收包为例。\n网络中有数据包到来，当网卡接受到数据时，网卡向cpu发中断，cpu调用驱动程序，将数据包放到对应的cpu输入队列。接着唤醒软中断，调用netif_receive_skb函数，在这里判断数据包需要转到上层协议栈，还是向网桥接口处理。数据流向如下，这里默认网桥设备为非disable状态\n具体流程：\n1 2 3 4 5 6 7 8 9 10 1. netif_receive_skb 2. --\u0026gt;netif_receive_skb_internal /* 记录收包时间, rps机制，将报文在多个cpu之间做负载均衡以及提高报文处理的缓存命中率 */ 3. --\u0026gt;__netif_receive_skb 4. --\u0026gt;__netif_receive_skb_core 5. --\u0026gt; skb_reset_network_header //重置network_header字段 6. --\u0026gt; skb_vlan_untag //802.1Q、802.1AD,剥除vxlan头 7. --\u0026gt; paket_type.func() //处理 ptype_all 上所有的 packet_type-\u0026gt;func() 8. --\u0026gt; vlan_do_receive 9. --\u0026gt; dev-\u0026gt;rx_handler () //实际执行函数br_handle_frame(),数据包逻辑分发，网桥处理转发就在这里进行 10. --\u0026gt; deliver_ptype_list_skb //向L3分发 __netif_receive_skb_core 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 static int __netif_receive_skb_core(struct sk_buff **pskb, bool pfmemalloc, struct packet_type **ppt_prev) { struct packet_type *ptype, *pt_prev; rx_handler_func_t *rx_handler; struct sk_buff *skb = *pskb; struct net_device *orig_dev; bool deliver_exact = false; int ret = NET_RX_DROP; __be16 type; net_timestamp_check(!READ_ONCE(netdev_tstamp_prequeue), skb); trace_netif_receive_skb(skb); orig_dev = skb-\u0026gt;dev; skb_reset_network_header(skb); if (!skb_transport_header_was_set(skb)) skb_reset_transport_header(skb); skb_reset_mac_len(skb); pt_prev = NULL; another_round: skb-\u0026gt;skb_iif = skb-\u0026gt;dev-\u0026gt;ifindex; __this_cpu_inc(softnet_data.processed); if (static_branch_unlikely(\u0026amp;generic_xdp_needed_key)) { int ret2; migrate_disable(); ret2 = do_xdp_generic(rcu_dereference(skb-\u0026gt;dev-\u0026gt;xdp_prog), skb); migrate_enable(); if (ret2 != XDP_PASS) { ret = NET_RX_DROP; goto out; } } if (eth_type_vlan(skb-\u0026gt;protocol)) { skb = skb_vlan_untag(skb); if (unlikely(!skb)) goto out; } if (skb_skip_tc_classify(skb)) goto skip_classify; if (pfmemalloc) goto skip_taps; list_for_each_entry_rcu(ptype, \u0026amp;ptype_all, list) { if (pt_prev) ret = deliver_skb(skb, pt_prev, orig_dev); pt_prev = ptype; } list_for_each_entry_rcu(ptype, \u0026amp;skb-\u0026gt;dev-\u0026gt;ptype_all, list) { if (pt_prev) ret = deliver_skb(skb, pt_prev, orig_dev); pt_prev = ptype; } skip_taps: #ifdef CONFIG_NET_INGRESS if (static_branch_unlikely(\u0026amp;ingress_needed_key)) { bool another = false; skb = sch_handle_ingress(skb, \u0026amp;pt_prev, \u0026amp;ret, orig_dev, \u0026amp;another); if (another) goto another_round; if (!skb) goto out; if (nf_ingress(skb, \u0026amp;pt_prev, \u0026amp;ret, orig_dev) \u0026lt; 0) goto out; } #endif skb_reset_redirect(skb); skip_classify: if (pfmemalloc \u0026amp;\u0026amp; !skb_pfmemalloc_protocol(skb)) goto drop; if (skb_vlan_tag_present(skb)) { if (pt_prev) { ret = deliver_skb(skb, pt_prev, orig_dev); pt_prev = NULL; } if (vlan_do_receive(\u0026amp;skb)) goto another_round; else if (unlikely(!skb)) goto out; } rx_handler = rcu_dereference(skb-\u0026gt;dev-\u0026gt;rx_handler); if (rx_handler) { if (pt_prev) { ret = deliver_skb(skb, pt_prev, orig_dev); pt_prev = NULL; } switch (rx_handler(\u0026amp;skb)) { case RX_HANDLER_CONSUMED: ret = NET_RX_SUCCESS; goto out; case RX_HANDLER_ANOTHER: goto another_round; case RX_HANDLER_EXACT: deliver_exact = true; break; case RX_HANDLER_PASS: break; default: BUG(); } } if (unlikely(skb_vlan_tag_present(skb)) \u0026amp;\u0026amp; !netdev_uses_dsa(skb-\u0026gt;dev)) { check_vlan_id: if (skb_vlan_tag_get_id(skb)) { /* Vlan id is non 0 and vlan_do_receive() above couldn\u0026#39;t * find vlan device. */ skb-\u0026gt;pkt_type = PACKET_OTHERHOST; } else if (eth_type_vlan(skb-\u0026gt;protocol)) { /* Outer header is 802.1P with vlan 0, inner header is * 802.1Q or 802.1AD and vlan_do_receive() above could * not find vlan dev for vlan id 0. */ __vlan_hwaccel_clear_tag(skb); skb = skb_vlan_untag(skb); if (unlikely(!skb)) goto out; if (vlan_do_receive(\u0026amp;skb)) /* After stripping off 802.1P header with vlan 0 * vlan dev is found for inner header. */ goto another_round; else if (unlikely(!skb)) goto out; else /* We have stripped outer 802.1P vlan 0 header. * But could not find vlan dev. * check again for vlan id to set OTHERHOST. */ goto check_vlan_id; } /* Note: we might in the future use prio bits * and set skb-\u0026gt;priority like in vlan_do_receive() * For the time being, just ignore Priority Code Point */ __vlan_hwaccel_clear_tag(skb); } type = skb-\u0026gt;protocol; /* deliver only exact match when indicated */ if (likely(!deliver_exact)) { deliver_ptype_list_skb(skb, \u0026amp;pt_prev, orig_dev, type, \u0026amp;ptype_base[ntohs(type) \u0026amp; PTYPE_HASH_MASK]); } deliver_ptype_list_skb(skb, \u0026amp;pt_prev, orig_dev, type, \u0026amp;orig_dev-\u0026gt;ptype_specific); if (unlikely(skb-\u0026gt;dev != orig_dev)) { deliver_ptype_list_skb(skb, \u0026amp;pt_prev, orig_dev, type, \u0026amp;skb-\u0026gt;dev-\u0026gt;ptype_specific); } if (pt_prev) { if (unlikely(skb_orphan_frags_rx(skb, GFP_ATOMIC))) goto drop; *ppt_prev = pt_prev; } else { drop: if (!deliver_exact) atomic_long_inc(\u0026amp;skb-\u0026gt;dev-\u0026gt;rx_dropped); else atomic_long_inc(\u0026amp;skb-\u0026gt;dev-\u0026gt;rx_nohandler); kfree_skb(skb); /* Jamal, now you will not able to escape explaining * me how you were going to use this. :-) */ ret = NET_RX_DROP; } out: /* The invariant here is that if *ppt_prev is not NULL * then skb should also be non-NULL. * * Apparently *ppt_prev assignment above holds this invariant due to * skb dereferencing near it. */ *pskb = skb; return ret; } CONFIG_NET_INGRESS 是 Linux 内核的一个配置选项，用于启用或禁用网络设备的 Ingress 功能。启用 CONFIG_NET_INGRESS 配置选项后，Linux 内核将支持对网络设备的入口流量进行控制和处理。网络设备的 Ingress 功能可以用于实现以下功能：\nØ 数据包过滤：根据预先设置的过滤规则，判断数据包是否符合要求。如果数据包被过滤，可以根据策略进行丢弃或处理。\nØ 数据包处理：根据网络设备的配置，对数据包进行处理。例如，进行 QoS 处理、修改数据包头部、更改目标端口等操作。\nØ 数据包转发：根据策略和路由表，决定数据包的转发目的地，并将数据包发送到相应的网络接口。\n上述功能通过函数sch_handle_ingress实现\n对vlan的处理 判断skb协议是否为8021Q 8021AD，若是vlan包，则调用skb_vlan_untag()函数，该函数读出数据流中的vlan_id，并填写入skb-\u0026gt;vlan_tci中，然后删除vlan_head，从而实现对上层的透明。注意这里的skb-\u0026gt;vlan_tci标志仅是为了保存skb数据的vlan头信息，而skb中的数据是透明的以太网包.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 static inline bool eth_type_vlan(__be16 ethertype) { switch (ethertype) { case htons(ETH_P_8021Q): case htons(ETH_P_8021AD): return true; default: return false; } } if (eth_type_vlan(skb-\u0026gt;protocol)) { skb = skb_vlan_untag(skb); if (unlikely(!skb)) goto out; } vlan信息转移到skb结构中后，会获取数据包真实协议类型（三层协议类型），更新到skb的protocol字段，替换了之前的ETH_P_8021Q或者ETH_P_8021AD。将vlan信息存在skb字段后，调用vlan_do_receive，该函数由skb-\u0026gt;vlan_tci得到该skb包所要发往的vlan_dev，并且重定向skb-\u0026gt;dev为该vlan_dev，最后消除skb中的vlan_tci标志。\n1 2 3 4 5 6 7 8 9 10 11 12 13 if (skb_vlan_tag_present(skb)) { if (pt_prev) { ret = deliver_skb(skb, pt_prev, orig_dev); pt_prev = NULL; } if (vlan_do_receive(\u0026amp;skb)) goto another_round; else if (unlikely(!skb)) goto out; } rx_handler = rcu_dereference(skb-\u0026gt;dev-\u0026gt;rx_handler); if (rx_handler) { 样之后vlan_do_receive()返回，不过此时的skb已经是一个普通的数据包了（实现了对上层的透明），且它看起来就像是由vlan_dev接收的数据包。\n接下来是关键处理dev-\u0026gt;rx_handler，这个函数在之前将网口添加到网桥设备的过程，调用br_add_if函数中定义\n1 2 3 4 5 br_add_if () --\u0026gt;netdev_rx_handler_register --\u0026gt;netdev_rx_handler_register(dev, br_get_rx_handler(dev), p); // {rcu_assign_pointer(dev-\u0026gt;rx_handler_data, p) rcu_assign_pointer(dev-\u0026gt;rx_handler, br_get_rx_handler)} 看到在netdev_rx_handler_register函数：\n将dev-\u0026gt;rx_handle与br_get_rx_handler绑定\ndev-\u0026gt;rx_handler_data与以太网端口p绑定\n所以这里网桥操作skb包，主要在br_get_rx_handler函数中进行。\n经过dev-\u0026gt;rx_handler函数处理，返回值有四种类型：\nØ RX_HANDLER_CONSUMED：数据包已处理消化，无需进一步处理。（什么场景） 直接跳转到out标签退出。\nØ RX_HANDLER_ANOTHER：修改了skb-\u0026gt;dev，再处理一次，比如数据包设备是网桥设备，但经过判断，需要经过网桥设备转发到另一个网桥关联的端口，这时就从bridge_dev转换到了port_dev\nØ RX_HANDLER_EXACT：精确指定要传递到ptype-\u0026gt;dev == skb-\u0026gt;dev（什么场景）\nØ RX_HANDLER_PASS：1.数据包类型是回环类型PACKET_LOOPBACK\n后两种情况会继续往下执行，最终将数据包提交到L3层协议栈\n网桥设备处理skb: br_handle_frame 从这里开始才是对数据包的处理分流转发，之前可以看作netif_receive_skb函数对数据包的预处理。br_get_rx_handler被设置为br_handle_frame，具体路径：net/bridge/br_input.c。\nbr_handle_frame函数根据数据包的类型，对数据的处理进行分流.\nØ 网桥处于disable状态：\n1.数据包目的地址是网桥端口地址：将pkt_type设为PACKET_HOST\n1 2 if (ether_addr_equal(p-\u0026gt;br-\u0026gt;dev-\u0026gt;dev_addr, dest)) skb-\u0026gt;pkt_type = PACKET_HOST; 2.否则，br_handle_local_finish函数设置到网桥预处理节点，该函数在网桥状态部位disable时，会学习mac与端口信息并记录fdb表中\n1 2 3 4 5 if (NF_HOOK(NFPROTO_BRIDGE, NF_BR_PRE_ROUTING, dev_net(skb-\u0026gt;dev), NULL, skb, skb-\u0026gt;dev, NULL, br_handle_local_finish) == 1) { return RX_HANDLER_PASS; } Ø 网桥处于learning或forwarding状态：\n调用函数nf_hook_bridge_pre-\u0026gt; br_handle_frame_finish\nbr_handle_frame_finish br_handle_frame_finish：决策将不同类别的数据包做不同的分发路径。具体处理逻辑如下图.\n首先这里有一个比较重要的特性，arp proxy，接口如果是能了此功能，对于收到的arp request，通过查询本地的arp表构造arp reply报文回应。\n根据目标地址skb-\u0026gt;hdr-\u0026gt;h_dest判断是单播、广播、多播的哪一种：\nØ 单播：调用br_fdb_find_rcu查找fdb表项， （1）若命中，调用br_forward()将数据包转发， （2）若表项为空，调用函数br_flood() br_flood(br, skb, pkt_type, local_rcv, false); 注意，如果发现目标地址是本地地址（判断方法目标表项dst-\u0026gt;flags为BR_FDB_LOCAL），则直接调用br_pass_frame_up()发往本地，该函数会再次进入netif_receive_skb函数。\nØ 广播：由于广播目标地址包含本机，所以会再次调用br_pass_frame_up()，并调用br_flood()\nØ 多播：因为当目的mac地址是0x01开头时，既可以是igmp类型的多播协议控制报文，也可以是多播数据流报文。先调用br_multicast_rcv处理igmp类型数据包，多播数据表也通过该类型数据表维护。接着查看多播数据表项， （1）如果命中，调用br_multicast_flood()， （2）如果未命中也会调用br_flood()。 最后多播也会判断本机是否加入多播组，加入的话也会调用函数br_pass_frame_up()将数据发往本地。\n这里看到单播，多播，广播都会调用br_flood()函数，分别在以下情况：\n单播，fdb表项未命中\n广播下都会调用\n多播，mdb表未命中\n不同情况，通过函数参数pkt_type进行的区分。\n单播：pkt_type = BR_PKT_UNICAST\n广播：pkt_type = BR_PKT_BROADCAST\n多播：pkt_type = BR_PKT_MULTICAST\n数据包发往本地：br_pass_frame_up 数据进入br_pass_frame_up，是打算经由Bridge设备，输入到本地Host的。数据包从网桥端口设备进入，经过网桥设备，然后再进入协议栈，其实是“两次经过net_device”，一次是端口设备，另一次是网桥设备。现在数据包离开网桥端口进入网桥设备，需要修改skb-\u0026gt;dev字段。\n1 2 indev = skb-\u0026gt;dev; skb-\u0026gt;dev = brdev 递交的最后一步是经过NF_BR_LOCAL_IN钩子点，然后是我们熟悉的netif_receive_skb，只不过这次进入该函数的时候skb-\u0026gt;dev已经被换成了Bridge设备。这可以理解为进入了Bridge设备的处理。它的skb-\u0026gt;dev-\u0026gt;rx_handler 为空，所以不会再次进入br_handler_frame，而是会进上层协议栈。\n1 2 3 return NF_HOOK(NFPROTO_BRIDGE, NF_BR_LOCAL_IN, dev_net(indev), NULL, skb, indev, NULL, br_netif_receive_skb); 数据被修改skb-\u0026gt;dev后再次进入netif_receive_skb，上次执行的netif_receive_skb因为rx_handler返回CONSUMED而结束。\n数据包转发 单端口转发：br_forward\nbr_forward经过一系列的检查与前期准备，最终调用dev_queue_xmit(skb)将数据包放到网卡输出队列中发送出去。之后对应具体的网卡驱动函数。\n多播：br_multicast_flood\n桥的多播功能需要使能igmp snooping功能\n转发端口获取：\n从mdb中获取多播组的端口p1， 从br-\u0026gt;router_list获取桥接端口p2 p = p1\u0026gt;p2? p1: p2 （为什么这样比较） 若p=p1时，如果该端口支持多播对单播转发， 则以单播形式转发（也是调用br_forward，与普通多播貌似没有不同） 复制skb数据，调用br_forward从p端口转发数据 下面br_flood一样每次转发的端口都是上次遍历得到的端口，最后一次端口使用原始skb数据，这样减少一次clone操作\nflood到各端口br_flood\n如果没有查找到对应的表项（单播、组播），或者要进行广播模式，系统调用br_flood，向网桥的每个端口转发。br_flood函数遍历网桥下的每个端口，根据允许的flags条件，调用deliver_clone或__br_forward将sbk从该端口转发出去\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 void br_flood(struct net_bridge *br, struct sk_buff *skb, enum br_pkt_type pkt_type, bool local_rcv, bool local_orig) { struct net_bridge_port *prev = NULL; struct net_bridge_port *p; list_for_each_entry_rcu(p, \u0026amp;br-\u0026gt;port_list, list) { /* Do not flood unicast traffic to ports that turn it off, nor * other traffic if flood off, except for traffic we originate */ switch (pkt_type) { case BR_PKT_UNICAST: if (!(p-\u0026gt;flags \u0026amp; BR_FLOOD)) continue; break; case BR_PKT_MULTICAST: if (!(p-\u0026gt;flags \u0026amp; BR_MCAST_FLOOD) \u0026amp;\u0026amp; skb-\u0026gt;dev != br-\u0026gt;dev) continue; break; case BR_PKT_BROADCAST: if (!(p-\u0026gt;flags \u0026amp; BR_BCAST_FLOOD) \u0026amp;\u0026amp; skb-\u0026gt;dev != br-\u0026gt;dev) continue; break; } /* Do not flood to ports that enable proxy ARP */ if (p-\u0026gt;flags \u0026amp; BR_PROXYARP) continue; if ((p-\u0026gt;flags \u0026amp; (BR_PROXYARP_WIFI | BR_NEIGH_SUPPRESS)) \u0026amp;\u0026amp; BR_INPUT_SKB_CB(skb)-\u0026gt;proxyarp_replied) continue; prev = maybe_deliver(prev, p, skb, local_orig); if (IS_ERR(prev)) goto out; } if (!prev) goto out; if (local_rcv) deliver_clone(prev, skb, local_orig); else __br_forward(prev, skb, local_orig); return; out: if (!local_rcv) kfree_skb(skb); } 在向每个端口转发时，都会复制一份新的skb数据。 maybe_deliver是deliver_clone的包装，每次遍历端口后，会在下一个遍历周期，将数 据从本次遍历端口发送，最后一个端口的数据则是直接使用原始的skb，这样可以少一次数据复制开销。\n参考链接 linux网桥驱动与二层对数据包分发 - 知乎\n","date":"2025-09-26T16:36:08+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/linux-%E7%BD%91%E6%A1%A5/","title":"Linux 网桥"},{"content":"\n光滑的地面上放着大小两个滑块，左边是墙。大滑块的质量是小滑块的N倍。给大滑块一个向左的初速度，两个滑块之间会发生多次碰撞。假设碰撞没有能量损失，问一共会发生多少次碰撞？\n能量守恒 $$ \\frac{1}{2}mv^2 + \\frac{1}{2}MV^2 = \\frac{1}{2}MV_0^2 $$$$ \\frac{v^2}{M/m} + V^2 = V_0^2 $$由M=Nm\n$$ \\frac{v^2}{N}+V^2=V_0^2 $$$$ \\frac{v^2}{NV_0^2}+\\frac{V^2}{V_0^2}=1 $$ 碰撞过程满足动量守恒\n设向右为正\n第一次碰撞\n$$ mv_1+MV_1=MV_0 $$$$ V_1=-\\frac{1}{N}v_1+V_0 $$初始$V_0$向左为负，此时$V_1$ 为负，$v_1$为负\n第二次碰撞\n小滑块m 撞墙以后，被墙反弹，速度反向变为 $-v_1$\n$$ mv_2+MV_2=m(-v_1)+MV_1 $$ $$ V_2=-\\frac{1}{N}(v_2+v_1)+V_1 $$ 相当于$V_2=-\\frac{1}{N}v_2+V_1$向右平移了$|v_1|$\n上述过程可以重复下去，直到 $V\\geq v \\gt 0$时为止\n$\\frac{v^2}{NV_0^2}+\\frac{V^2}{V_0^2}=1$ 变量代换$x=\\frac{v}{\\sqrt N |V_0|}$ $y=\\frac {V}{|V_0|}$ ===\u0026gt;$x^2+y^2=1$； $ V_1=-\\frac{1}{N}v_1+V_0$ ==\u0026gt;$y=-\\frac {1}{\\sqrt N}x-1$\n$\\tan \\theta = -\\frac {1}{\\sqrt N} $\n滑块的每一次碰撞，都可以看成是从单位圆上切下两段长度为 $l=\\theta R$\n的圆弧，即每次切下$s=2 l= 2 \\times \\theta \\times R = 2\\arctan \\frac {1}{\\sqrt N} $\n整个单位圆的周长为$2 \\pi$\n直到剩下的圆弧不足$s= 2\\arctan \\frac {1}{\\sqrt N}$时不会再碰撞\n故总的碰撞次数为\n$$ \\lceil \\frac {2 \\pi}{2\\arctan \\frac {1}{\\sqrt N}} \\rceil -1 $$由上式可以算出，当两个滑块质量相等时，$s= \\arctan \\frac {1}{\\sqrt N}$ 为$\\frac {\\pi}{4}$，碰撞总次数为 3。而当两个滑块质量悬殊时， $\\frac {1}{\\sqrt N}$就很小，由$\\arctan (x) = x - \\frac {x^3} {3}+\\frac {x^5} {5}-\\frac {x^7} {7}-\u0026hellip;$此时就可以直接用 $\\frac {1}{\\sqrt N}$来近似$\\arctan \\frac {1}{\\sqrt N}$，于是碰撞总次数就约为$\\lfloor \\sqrt N \\pi \\rfloor$ 。当两个滑块的质量之比 N是 100 的幂时，$\\sqrt N$就是 10 的幂，这就难怪碰撞总次数会恰好是$\\pi$的前若干位了\n","date":"2025-09-19T14:10:10+08:00","image":"https://cdn.jsdelivr.net/gh/charles-7777/ImageBed@main/blog/2025-09-19-13-54-10-image.png","permalink":"https://charles-7777.github.io/hugo-stack/p/%E5%BC%B9%E6%80%A7%E7%A2%B0%E6%92%9E%E4%B8%8Epi/","title":"弹性碰撞与pi"},{"content":"什么是 UPnP？ UPnP（Universal Plug and Play，通用即插即用）是一种网络协议标准，旨在让网络设备（如计算机、打印机、摄像头、智能电视、路由器、IoT设备等）在接入网络时能够自动发现彼此并建立功能性的网络服务，无需用户手动配置。其设计目标是实现“零配置”网络体验。 UPnP 基于开放的互联网标准和技术，如 TCP/IP、HTTP、XML、SOAP 和 SSDP，使其能在多种操作系统和硬件平台上运行。\nUPnP 基本原理 UPnP 网络通常包含三种角色：\n设备 (Device)：提供一项或多项服务的网络实体（如智能灯泡、网络摄像头）。\n服务 (Service)：设备提供的最小功能控制单元（如开关服务、亮度调节服务）。\n控制点 (Control Point)：发现并控制设备的控制器（如手机App、电脑上的软件）。\nUPnP 的工作流程可分为以下几个核心阶段：\n寻址（Addressing） 设备接入网络后，首先通过 DHCP 获取 IP 地址；若 DHCP 不可用，则使用 Auto-IP（如 169.254.x.x）自行分配一个局域网内可用的 IP。\n发现（Discovery） 设备使用 SSDP（Simple Service Discovery Protocol，简单服务发现协议）向局域网广播自己的存在：\n广播消息：设备发送 M-SEARCH 请求或 NOTIFY 通知。\n响应机制：控制点（如手机App或PC）监听这些广播，并向感兴趣的设备发送请求获取详细信息。\n使用组播地址 239.255.255.250:1900 进行通信。\n描述（Description） 控制点通过 HTTP GET 请求从设备提供的 URL 获取 XML 描述文件，该文件包含：\n设备类型、厂商信息、型号、序列号\n支持的服务列表（如端口映射、音量控制等）\n每个服务的控制URL、事件URL、描述URL\n控制（Control） 控制点通过 SOAP（Simple Object Access Protocol）协议向设备发送控制指令，调用其服务方法。例如：\n调用“AddPortMapping”在路由器上添加端口转发规则\n调用“SetVolume”调节音响音量 请求和响应均使用 XML 格式封装，通过 HTTP POST 发送。\n事件通知（Eventing） 设备状态变化时（如播放状态改变、端口映射成功），可通过 GENA（General Event Notification Architecture）协议向订阅的控制点推送事件通知（也是 XML 格式），实现状态同步。\n展示（Presentation，可选） 设备可提供一个内置的 Web 界面（URL 包含在描述文件中），用户可通过浏览器访问进行图形化控制或查看状态。\nUPnP 主要功能 自动设备发现与互操作 局域网内设备自动广播身份，无需手动输入 IP 或配置。\n不同厂商设备只要遵循 UPnP 标准即可互通（如智能灯泡 + 手机App）。\n自动端口映射（NAT 穿透） 最重要功能之一：允许内网设备（如游戏主机、P2P软件、监控摄像头）自动在路由器上创建端口转发规则，实现从外网访问。\n应用场景：在线游戏联机、远程访问家庭摄像头、BT下载加速等。\n无需用户登录路由器后台手动设置端口转发。\n设备控制与状态同步 可远程控制设备功能（播放/暂停、开关机、调节参数等）。\n实时接收设备状态变更通知（如“播放结束”、“电量低”）。\n零配置网络体验 用户无需了解网络知识，插上网线或连上WiFi即可使用设备功能。\n特别适合家庭用户和 IoT 设备。\n支持多种设备类型 路由器、打印机、NAS、媒体服务器（DLNA）、智能家电、安防设备等均可支持 UPnP。 UPnP 的优缺点 ✅ 优点： 简单易用：真正实现“即插即用”。\n跨平台兼容：基于标准互联网协议，支持 Windows、Linux、macOS、Android、iOS 等。\n自动化程度高：减少人工配置错误。\n❌ 缺点与风险： 安全风险：恶意软件可能利用 UPnP 自动在路由器上开洞，暴露内网服务（如勒索软件、僵尸网络）。\n缺乏认证机制：默认无用户权限控制，局域网内任何设备都可操作。\n稳定性问题：部分设备实现不规范，可能导致冲突或失效。\n🛡️ 安全建议：\n家庭用户如无远程访问需求，建议在路由器中关闭 UPnP 功能。 企业网络应严格禁用 UPnP。 使用支持 UPnP-IGD v2 的设备，其安全性有所增强（支持 PIN 验证等）。 典型应用场景 场景 说明 在线游戏主机联网 Xbox/PS 自动请求端口映射，实现 NAT 开放或中等。 P2P 下载（如 BitTorrent） 客户端自动映射端口，提高连接数和下载速度。 远程访问家庭摄像头/NAS 自动在路由器上映射端口，便于外网访问。 DLNA 媒体共享 电视自动发现局域网内的媒体服务器并播放影片。 智能家居控制 手机 App 自动发现并控制智能插座、灯泡等。 相关协议与标准组织 标准组织：UPnP Forum（现由 Open Connectivity Foundation 接管） 核心协议： SSDP（发现） HTTP + XML（描述） SOAP（控制） GENA（事件） 扩展标准： UPnP-IGD（Internet Gateway Device）：专用于路由器端口映射。 DLNA（Digital Living Network Alliance）：基于 UPnP 的媒体共享标准。 总结 UPnP 是一项旨在简化家庭和小型办公网络设备互联的技术，通过标准化的发现、描述、控制和事件机制，实现了真正的“零配置”体验。尤其在自动端口映射方面极大地方便了普通用户。然而，其安全机制的缺失也带来潜在风险，用户应根据实际需求权衡是否启用。 随着 IoT 和智能家居的普及，UPnP 仍在广泛使用，但正逐步被更安全的替代方案（如 NAT-PMP、PCP、mDNS + DNS-SD）所补充或取代。\n📚 参考资料：UPnP Device Architecture 2.0, IETF RFC 6970, OCF Specifications\n","date":"2025-09-15T14:53:06+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/upnp%E9%80%9A%E7%94%A8%E5%8D%B3%E6%8F%92%E5%8D%B3%E7%94%A8%E5%8D%8F%E8%AE%AE%E4%BB%8B%E7%BB%8D/","title":"upnp(通用即插即用)协议介绍"},{"content":"docker 搭建 hwdsl2/docker-ipsec-vpn-server: Docker image to run an IPsec VPN server, with IPsec/L2TP, Cisco IPsec and IKEv2\n1 2 3 4 5 6 7 8 9 10 docker run \\ --name ipsec-vpn-server \\ --restart=always \\ --env-file ./vpn.env \\ -v ikev2-vpn-data:/etc/ipsec.d \\ -v /lib/modules:/lib/modules:ro \\ -p 500:500/udp \\ -p 4500:4500/udp \\ -d --privileged \\ hwdsl2/ipsec-vpn-server vpn.env\n1 2 3 4 5 6 VPN_IPSEC_PSK=ipsec VPN_USER=vpnuser VPN_PASSWORD=123456 VPN_PUBLIC_IP=x.x.x.x VPN_ADDL_USERS=vpnuser1 vpnuser2 VPN_ADDL_PASSWORDS=123456 123456 查看docker启动log\ndocker logs ipsec-vpn-server\n一些client 连接可能遇到的问题\nsetup-ipsec-vpn/docs/clients.md at master · hwdsl2/setup-ipsec-vpn\n连接ipsec/l2tp 可能遇到的问题 Windows error 809\nError 809: The network connection between your computer and the VPN server could not be established because the remote server is not responding. This could be because one of the network devices (e.g, firewalls, NAT, routers, etc) between your computer and the remote server is not configured to allow VPN connections. Please contact your Administrator or your service provider to determine which device may be causing the problem.\n1 REG ADD HKLM\\SYSTEM\\CurrentControlSet\\Services\\PolicyAgent /v AssumeUDPEncapsulationContextOnSendRule /t REG_DWORD /d 0x2 /f 配置Ikev2 可参考docker-ipsec-vpn-server/README-zh.md at master · hwdsl2/docker-ipsec-vpn-server\ndocker logs ipsec-vpn-server查看IKEv2 相关配置信息\n1 2 3 4 5 6 7 IKEv2 is already set up. Details for IKEv2 mode: VPN server address: 208.216.217.35 VPN client name: vpnclient Client configuration is available inside the Docker container at: 首次启动时，可能使用的是默认配置，需要手动更改\n进入dockerdocker exec -it ipsec-vpn-server /bin/sh\n1 2 wget https://get.vpnsetup.net/ikev2addr -O ikev2addr.sh bash ikev2addr.sh 执行ikev2addr.sh去手动更改vpnserver address\n配置IKEv2 client（windows) 1 2 3 4 # 查看容器内的 /etc/ipsec.d 目录的文件 docker exec -it ipsec-vpn-server ls -l /etc/ipsec.d # 示例：将一个客户端配置文件从容器复制到 Docker 主机当前目录 docker cp ipsec-vpn-server:/etc/ipsec.d/vpnclient.p12 ./ 在创建IKEv2连接之前，需要在windows 客户端 导入证书\n1 2 # Import .p12 file (replace with your own value) certutil -f -importpfx \u0026#34;\\path\\to\\your\\file.p12\u0026#34; NoExport 可能遇到的问题 IKE authentication credentials are unacceptable\n可能是IKEv2 vpn server中 server address配置不对，可以尝试更改VPN server address\nPolicy match error\n1 REG ADD HKLM\\SYSTEM\\CurrentControlSet\\Services\\RasMan\\Parameters /v NegotiateDH2048_AES256 /t REG_DWORD /d 0x1 /f 在windows server 上搭建vpn server 可参考Windows Server 2012 R2 安装SSTP/L2TP/PPTP – Noname\n在windows 上安装并使用openvpn 参考链接\nopenvpn安装配置说明(windows系统) OpenVPN Windows 平台安装部署教程 安装openvpn https://github.com/OpenVPN/openvpn\nhttps://openvpn.net/community-downloads/\nopenvpn软件服务端和客户端都是同一个安装包 安装服务端的时候要选择Customize，勾选openvpn service和EasyRSA3 安装，用于服务端配置和证书生成使用。 安装客户端时可直接点击Install Now进行安装 证书生成 安装服务端的时候已经安装了证书生成工具**EasyRSA3，**使用此工具即可生成所需证书\n进入EasyRSA shell 环境dos窗口\n进入C:\\Program Files\\OpenVPN\\easy-rsa目录，双击EasyRSA-Start.bat 进入EasyRSA shell 环境dos窗口中\n初始化证书生成程序\n弹出的dos窗口中输入./easyrsa init-pki 初始化证书生成程序，初始化成功后会在C:\\Program Files\\OpenVPN\\easy-rsa目录下新建文件夹kpi\n生成ca证书\n在dos窗口中输入./easyrsa build-ca nopass生成无密码CA证书，生成过程中会要求输入证书名称，随意输入即可，生成结束后会打印出证书所在目录easy-rsa\\pki\\ca.crt\n生成服务端证书\n输入./easyrsa build-server-full server nopass 生成无密码服务端证书,生成后证书文件在C:\\Program Files\\OpenVPN\\easy-rsa\\pki\\issued文件夹\n生成客户端证书\n输入./easyrsa build-client-full client nopass生成无密码客户端证书,生成后证书在C:\\Program Files\\OpenVPN\\easy-rsa\\pki\\issued文件夹\n生成DH密钥交换协议\n输入./easyrsa gen-dh生成DH密钥交换协议文件,生成文件在C:\\Program Files\\OpenVPN\\easy-rsa\\pki目录下\n目录C:\\Program Files\\OpenVPN\\easy-rsa\\pki\\private下为证书key\nopenvpn --genkey tls-auth ta.keyto help block DoS attacks and UDP port flooding.\n配置文件 服务端配置文件模板为server.ovpn，客户端配置文件client.ovpn，在 C:\\Program Files\\OpenVPN\\sample-config目录下有。在服务端或客户端的windows主机上复制对应配置文件模板到C:\\Program Files\\OpenVPN\\config目录下\n配置文件中 ； # 都可以用作注释，但是不支持在配置指令的同一行后面添加注释\n例如 cipher AES-256-CBC #选择加密算法 这样写是错误的，解析时会将cipher 后的AES-256-CBC #选择加密算法整个字符串当成参数值，从而导致错误\n服务端server.ovpn 修改\n端口：（公网需要对应开通此端口）port udp 1194 协议文件名：dh dh2048.pem修改为dh dh.pem 运行多用户使用同一客户端证书：;duplicate-cn取消注释（前面;号删除）修改为duplicate-cn 客户端client.ovpn修改\n修改连接服务器地址: remote my-server-1 1194修改为remote 服务器公网ip 1194 取消注释掉此行: ;tls-auth ta.key 1修改为 tls-auth ta.key 1（前面;号删除） 证书复制 配置文件server.ovpn client.ovpn 中的证书 和 key 都是只有文件名 ，没有规定具体路径\n需要将其copy 到C:\\Program Files\\OpenVPN\\config 下\n将服务端证书，服务端key，ca证书，dh文件, ta.key复制到文件夹C:\\Program Files\\OpenVPN\\config下\n将客户端证书，客户端key，ca证书 , ta.key复制到目录C:\\Program Files\\OpenVPN\\config下\n连接 右键点击任务栏带锁小电脑图标，点击连接,连接成功后系统分配ip，小电脑变绿\n其它 tls-auth ta.key 配置为防御 DoS,UDP 淹没等恶意攻击行为的选项，如配置需要生成ta.key证书，生成方式：跳转到openvpn软件的bin目录下，在dos窗口中输入：openvpn.exe --genkey --secret ta.key ，便在bin目录下生成ta.key证书了，复制到配置文件目录即可。 证书时间等参数可以在vars文件中设置，设置后重新启动EasyRSA-Start即可加载新配置。 ;client-to-client为客户端之间是否能直接访问的配置，去掉注释后生效。 ;push \u0026ldquo;redirect-gateway def1 bypass-dhcp\u0026rdquo; 配置开启后客户端所有流量将路由至服务器，需要在访问端服务器上配置路由转发后才可以访问公网。 开启第4步后，可在客户端配置文件中增加route 192.168.1.0 255.255.255.0 net_gateway配置，使该网段不通过openvpn路由 ","date":"2025-09-01T19:31:02+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/%E6%90%AD%E5%BB%BAvpn-server/","title":"搭建vpn server"},{"content":"官方文档\nCORE (Common Open Research Emulator) 是一个强大的、开源的网络模拟和仿真工具，广泛应用于网络研究、教学、协议开发和网络应用测试\n主题 描述 Architecture 体系结构概述，介绍如何使用Python、gRPC直接控制Core Installation CORE的安装方法及要求 GUI 如何使用GUI Node Types CORE支持的节点类型概述 (BETA) Python GUI 如何使用基于Python的BETA GUI Python API 介绍如何使用Python直接控制Core (自己实现core-daemon) gRPC API 介绍如何使用gRPC控制Core (连接core-daemon 调用其api) Distributed 在多个服务器上运行CORE的分布式细节 CTRLNET 如何控制网络从主机与节点通信 Services 概述所提供的服务并创建自定义服务 Performance 使用CORE时的性能说明 Developers Guide 概述如何对CORE开发 Core Emane CORE中运行和使用EMANE的高级主题和示例 Emane开发手册 Emane的架构介绍 开发相关 ","date":"2025-08-18T20:01:30+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/corecommon-open-research-emulator%E7%BD%91%E7%BB%9C%E4%BB%BF%E7%9C%9F%E5%B7%A5%E5%85%B7/","title":"CORE(Common Open Research Emulator)网络仿真工具"},{"content":"IPv6 地址结构 一个 IPv6 地址由 128 个比特（bits）组成，通常分为 8 个 16 比特的块，每个块用冒号（:）分隔，并以十六进制表示。\n例如：2001:0db8:85a3:0000:0000:8a2e:0370:7334\n地址压缩规则 为了简化书写，IPv6 地址可以被压缩：\n省略前导零 每个块中开头的\n1 0 可以省略。\n0db8 -\u0026gt; db8 0000 -\u0026gt; 0 0370 -\u0026gt; 370 压缩连续的零: 可以使用双冒号 :: 来替代地址中任意一段连续的、全为 0 的块。注意：在一个地址中 :: 只能使用一次。\n应用上述规则后，上面的地址可以被简化为：\n1 2001:db8:85a3::8a2e:370:7334 IPv6 地址类型 IPv6 地址主要分为三种类型：单播（Unicast）、多播（Multicast）和任播（Anycast）。\n单播地址 (Unicast) 单播地址标识一个唯一的网络接口，发往单播地址的数据包将被送到该地址所标识的唯一接口。\n全球单播地址 (Global Unicast Address - GUA)\n范围: 全球唯一，可在公网路由。\n前缀: 通常以 2000::/3 开头。\n结构:\n全局路由前缀 (Global Routing Prefix): 通常为 48 位，由 ISP 分配给组织。 子网 ID (Subnet ID): 通常为 16 位，由组织内部规划子网。 接口 ID (Interface ID): 64 位，用于标识子网中的具体设备接口。 链路本地地址 (Link-Local Address)\n范围: 仅在同一物理或逻辑链路上有效，不能跨路由器路由。\n前缀: fe80::/10。\n用途: 用于邻居发现、自动地址配置等链路内部通信。设备启动后会自动生成。\n唯一本地地址 (Unique Local Address - ULA)\n范围: 仅在有限范围内（如一个组织或站点内部）使用，功能类似 IPv4 的私有地址。它不会在公网路由。\n前缀: fc00::/7。\n特殊地址\n环回地址: ::1/128，相当于 IPv4 的 127.0.0.1。\n多播地址 (Multicast) 多播地址标识一组网络接口，发往多播地址的数据包将被送到该组中的所有接口。\n前缀: ff00::/8。\n常见示例:\nff02::1: 链路本地范围内的所有节点。 ff02::2: 链路本地范围内的所有路由器。 任播地址 (Anycast) 任播地址也标识一组网络接口，但发往任播地址的数据包只会被送到这组接口中距离最近（根据路由协议的度量）的一个。任播地址的格式与单播地址相同，但通过路由配置实现。\nIPv6 地址分配方法 设备获取 IPv6 地址主要有以下几种方式：\n无状态地址自动配置 (SLAAC) SLAAC 是 IPv6 的核心特性之一，允许设备在没有 DHCP 服务器的情况下自动配置地址。\n过程:\n设备启动后，首先为自己生成一个链路本地地址。 设备向本地链路发送一个路由器请求 (Router Solicitation - RS) 多播消息。 链路上的路由器收到 RS 后，会回复一个路由器通告 (Router Advertisement - RA) 消息。RA 消息中包含了网络前缀（如 GUA 前缀）和其他网络信息。 设备使用 RA 中通告的前缀，并结合自己的接口 ID（通常通过 EUI-64 算法或随机生成）来构成一个完整的全球单播地址。 有状态 DHCPv6 (Stateful) 工作方式类似于 IPv4 的 DHCP，由 DHCPv6 服务器集中管理和分配 IPv6 地址。\n优点: 便于集中管理和审计，可以精确控制地址分配。 适用场景: 需要严格管理地址分配的企业网络。 无状态 DHCPv6 (Stateless) 这是一种混合模式。\n设备通过 SLAAC 获取 IPv6 地址。 同时，设备通过 DHCPv6 获取其他网络配置信息，例如 DNS 服务器地址、域名等。 这种方式既利用了 SLAAC 的便捷性，又弥补了其无法提供 DNS 等附加信息的不足。 静态配置 (Manual) 管理员手动为设备配置静态的 IPv6 地址、网关和 DNS 等信息。适用于服务器、路由器等需要固定地址的设备。\nDHCPv6 交互过程 DHCPv6 客户端和服务器之间的通信过程，用于获取 IPv6 地址和/或其他网络配置参数。标准的交互过程涉及四次消息交换，这确保了客户端可以选择最合适的服务器。\n四步交换 (Four-Way Exchange):\nSolicit (请求): 客户端在本地链路上发送一个 Solicit 多播消息，以发现可用的 DHCPv6 服务器。 消息发送到所有 DHCP 中继代理和服务器的多播地址 ff02::1:2。 Advertise (通告): 收到 Solicit 消息的 DHCPv6 服务器会回复一个 Advertise 单播消息。 此消息中包含了服务器可以为客户端提供的地址和/或配置信息。一个客户端可能会收到多个 Advertise 消息。 Request (请求): 客户端从收到的一个或多个 Advertise 消息中选择一个服务器，并向其发送一个 Request 单播消息，正式请求分配地址和/或配置参数。 消息中会包含它所选择的服务器的标识符。 Reply (回复): 被选中的服务器收到 Request 消息后，会发送一个 Reply 单播消息，确认地址分配和配置信息。 此时，客户端完成配置，可以开始使用获取到的地址。 两步交换 (Two-Way Exchange) - 快速提交 (Rapid Commit): 为了加速地址分配过程，DHCPv6 引入了快速提交选项。 Solicit (请求): 客户端在 Solicit 消息中加入 \u0026ldquo;Rapid Commit\u0026rdquo; 选项，表示希望立即完成地址分配。 Reply (回复): 支持快速提交的服务器如果愿意立即分配地址，会直接回复一个 Reply 消息，跳过 Advertise 和 Request 步骤。 这种两步交换减少了延迟，在许多场景下（如网络中只有一个 DHCPv6 服务器）非常高效 关键协议与技术 在一个部署 IPv6 的广播域中，相比 IPv4 一个最明显的区别就是 IPv6 路由通告；在 IPv4 时代，一个广播域中的 ipv4 网段并没有显式说明，或者说并没有一个 ipv4 网段宣称占据了这个广播域，仅使用这个广播域的广播/组播能力，多个ipv4网段共用一个广播域的情况也不鲜见；而在ipv6中，运行ipv6协议的路由器会主动发送名为路由通告 Router Advertisement的 ICMPv6 报文，在广播域中宣告/广播*此 ipv6 网段占据了该广播域；\n*（准确的讲应该是组播，IPv6 已经没有广播概念了，这里使用广播这个说法为了说明是公开发送的，在一个广播域中，广播和组播达成的功能类似，且在低端交换机中，广播和组播的转发方式是一致的）\nRA（路由通告 Router Advertisement）使用 ICMPv6 报文（type 134），属于 NDP 协议的一部分\nIPv6 的功能实现严重依赖于一些关键的底层协议，特别是 ICMPv6 和在其基础上构建的邻居发现协议 (NDP)，以及用于动态分配网络前缀的 DHCPv6-PD。\nICMPv6 IPv6 时代的ip层控制协议（类比ipv4中的arp、icmp等）均使用icmpv6报文，取消了IP层的广播，转而广泛使用组播。ICMPv6 中的 type 133 ~ 137 报文由NDP协议使用，用于发现网关、邻居、地址配置等等。\nICMPv6 ICMPv6 是 IPv6 的一个核心组成部分，其功能远超 IPv4 中的 ICMP。它不仅用于传输网络错误和诊断信息，还承载了许多关键的网络控制功能。如果防火墙错误地完全阻止 ICMPv6，将导致 IPv6 网络中断。\n主要功能:\n错误报告: 如 \u0026ldquo;目标不可达\u0026rdquo;、\u0026ldquo;数据包过大\u0026rdquo;、\u0026ldquo;超时\u0026rdquo; 等。 诊断查询: 如 ping 命令所使用的 \u0026ldquo;Echo Request\u0026rdquo; 和 \u0026ldquo;Echo Reply\u0026rdquo;。 网络控制: 为 NDP、MLD (多播侦听发现) 等协议提供消息支持。 NDP (邻居发现协议) NDP 是 IPv6 中一个至关重要的协议，它取代了 IPv4 中的 ARP、ICMP 路由器发现和 ICMP 重定向等多个协议的功能。NDP 基于 ICMPv6 实现，是实现即插即用和 SLAAC 的基础。\nNDP 的核心功能:\n地址解析: 将 IPv6 地址解析为链路层地址（如 MAC 地址），取代了 ARP。 路由器发现: 主机可以发现本地链路上的路由器。 前缀发现: 主机可以发现用于自动配置的地址前缀。 重复地址检测 (DAD): 节点可以确认其想要使用的地址在链路上是唯一的。 可达性跟踪: 判断邻居节点是否仍然可达。 NDP 使用的五种 ICMPv6 消息类型:\n路由器请求 (Router Solicitation - RS): 通常由终端主动发送，用于在未收到周期性 RA 的情况下，请求 RA 路由器通告 (Router Advertisement - RA):由路由器周期性发送，也可以响应 RS 发送，用于宣告本广播域中 IPv6 相关信息。比如前缀、网关、DNS等 邻居请求 (Neighbor Solicitation - NS): 用于解析邻居的链路层地址或执行 DAD,和 IPv4 的 ARP request 功能一致。 邻居通告 (Neighbor Advertisement - NA): 对 NS 消息的响应，或在链路层地址变化时主动发送和 ,IPv4 的 ARP reply功能一致。 重定向 (Redirect): 路由器告知主机有更优的下一跳路径,类似于 IPv4 的icmp redirect功能。 RS/RA RS/RA 是IPv6 环境下独有的控制信令，此信令明确了一个广播域中各节点所代表的角色。\n广播域中发送RA的为路由器\n广播域中可以存在多个路由器\nRA 组播周期性发送\nRS 用于在未收到 RA 情况下请求 RA\nRA 中的Flags表明当前广播域中 IPv6 地址的配置方式\n这些 Flags 分布在两个位置\u0026mdash;-ICMPv6 报头和 prefix option，后者称为 PIO(Prefix Information Option) flag。\nM(Managed address configuration):位于报头，M=1 表明终端应该使用 DHCPv6 协议配置地址和其他网络参数；如果M=1，则忽略 O Flag；此flag用于DHCPv6 有状态模式。 O(Other configuration):位于报头，O=1且M=0 表明终端应该使用 DHCPv6 设置除了 IPv6 地址之外的其他（dns/ntp等），此 flag 用于 DHCPv6 无状态模式。 A(Autononous address-configuration flag):位于PIO中，A=1 表明终端应该使用 SLAAC 配置 IPv6 地址；PIO可以包含多个 Prefix，这也就意味着一个广播域中可以存在多个 IPv6 网段。 这几种flag是可以复合使用的，以满足不同场景需求,除了手动静态配置ipv6地址，动态/自动配置或者半自动配置ipv6地址的方式都需要从ndp协议的 RA 开始，就好像 RA 引导了IPv6自动配置的开始；RA中的不同flag叠加影响地址自动配置；\nDHCPv6-PD DHCPv6前缀代理DHCPv6-PD(PrefixDelegation)是一种前缀分配机制，通过DHCPv6前缀代理机制，下游 网络设备不需要再手工指定用户侧链路的IPv6地址前缀，它只需要向上游网络设备提出前缀分配申请，上游网 络设备便可以分配合适的地址前缀给下游设备，下游设备把获得的前缀再通过路由通告(RA)至与IPv6主机直连 的用户链路上，实现IPv6主机的地址自动配置，完成整个系统层次的地址布局。\nDHCP-PD 技术最早在RFC3633中提出，经过几次更新目前最新的是RFC8415，其主要思想是把DHCPv6的地址分配方式划分为多层，dhcp client不再是仅仅获取地址用于终端通信，而是可以作为次级路由器身份把地址层层分配下去；这样的好处是便于快速和统一部署大量地址，尤其是在大规模动态地址的情况下，此种地址分配方式在家庭宽带中已经大量部署；光猫从其上级获取一段地址用于本地网络终端的地址分配，甚至从光猫拿到的地址还能再往下一层分配.\n工作原理:\n请求: 家庭路由器（客户端）向其上游 ISP 的路由器（服务器）发送 DHCPv6 请求，希望获得一个 IPv6 地址前缀（例如一个 /56 或 /48 的地址块），而不仅仅是一个地址。 代理: ISP 路由器从其地址池中分配一个前缀块，并通过 DHCPv6 回复将其“代理”或“授权”给家庭路由器。 分配: 家庭路由器获得该前缀后，就拥有了管理这个地址块的权限。它可以将这个前缀进一步划分为更小的子网（例如多个 /64 子网），并为连接到其 LAN 口的各个内部网络（如家庭网络、访客网络）分配这些子网前缀。 通告: 家庭路由器在其内部网络上发送 RA 消息，通告这些 /64 的子网前缀，使得内部网络中的设备可以通过 SLAAC 自动配置 IPv6 地址。 优势:\n自动化: 无需手动配置下游路由器的子网，实现了网络部署的自动化。 结构化: 使得家庭或小型办公室可以轻松地拥有多个独立的 IPv6 子网，便于网络隔离和管理。 高效性: 相比于 NAT，每个设备都能获得全球唯一的公网地址，实现了真正的端到端连接。 link-local 对比IPv4环境，IPv6 地址有所谓的 link-local 地址而且充当比较重要作用；由于一个接口可以配置很多IPv6地址，当这些地址作为下一跳使用的时候会出现混乱，这样不利于管理也不利于设备性能开销,使用Link Local地址唯一标识链路上的一个节点就避免了这个问题。而且在网络重新编址过程中，Link Local并不会发生变化，更利于快速更改编址\nDAD DAD 基于 ICMPv6 Neighbor Solicitation（NS，邻居请求） 和 Neighbor Advertisement（NA，邻居通告） 消息实现，步骤如下：\n节点分配一个 IPv6 地址（如通过 SLAAC 或手动配置），但该地址尚未正式启用（处于 \u0026ldquo;tentative\u0026rdquo; 状态）。 发送 Neighbor Solicitation（NS）： 目标地址（Target Address）设为待检测的 IPv6 地址。 源地址设为 未指定地址（::）（因为该地址尚未正式使用）。 发送到 \u0026ldquo;请求节点组播地址\u0026rdquo;（Solicited-Node Multicast Address，FF02::1:FFXX:XXXX）。 等待响应： 如果没有收到 Neighbor Advertisement（NA），说明地址未被占用，可以正常使用。 如果收到 NA，说明地址已被占用，节点必须放弃该地址并重新配置（如 SLAAC 会生成新地址）。 DAD 完成： 成功通过检测后，地址变为 \u0026ldquo;Preferred\u0026rdquo; 或 \u0026ldquo;Valid\u0026rdquo; 状态，可以正常通信 邻居表 邻居表，在IPv4环境下就是ARP表，系统维护Arp表内容由系统自己决定，比如端口、更新时间等；\n到了IPv6环境，ND表代替了arp表，而且协议规定了5种邻居状态，IPv6 邻居状态，分别是： Incomplete、Reachable、Stale、Delay、Probe，其中只有 Stale 状态是稳定状态。\nIncomplete （未完成状态）：表⽰正在解 析地址，但邻居链路层地址尚未确定。 Reachable （可达状态）：表⽰地址解析 成功，该邻居可达。 Stale（失效状态）：表⽰可达时间耗尽，未确定邻居是否可达。 Delay（延迟状态）：表⽰未确定邻居是否可达。Delay 状态不是⼀个稳定的状态，⽽是⼀个延时等待状态。 Probe （探测状态）：节点会向处于 Probe 状态的邻居持续发送 NS 报⽂。 不同状态之间迁移如下图 1 2 ip neigh ip -6 neigh ","date":"2025-08-15T19:58:16+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/ipv6-%E5%9C%B0%E5%9D%80%E5%88%86%E9%85%8D%E8%AF%A6%E8%A7%A3/","title":"IPv6 地址分配详解"},{"content":"一般情况下如果我们想使用其他文件的函数时，常规操作是将该函数在头文件中声明，然后在需要使用的文件里引用这个头文件 但若是没声明呢？\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 11.c #include \u0026lt;stdio.h\u0026gt; extern char* b; int main() { printf(\u0026#34;aaa--d:%x----%s--p\\n\u0026#34;, aaa(),b,b); char*p = aaa(); printf(\u0026#34;p = %p\\n\u0026#34;, p); if(p) printf(\u0026#34;---\\n\u0026#34;); printf(\u0026#34;value = %s\\n\u0026#34;，p);// 崩溃! return 0; } 2.c char *b=\u0026#34;aaa\u0026#34;; char* aaa(){ return b;} 1 2 3 4 5 6 7 8 9 10 11 12 13 gcc 11.c 2.c -o test 11.c: In function ‘main\u0026#39; 11.c:4:37: warning:: implicit declaration of function ‘aaa\u0026#39;[-Wimplicit-function-declaration] 4| printf(\u0026#34;aaa--d:%x----%s--%p\\n\u0026#34;,aaa(),b,b); | ^~~ 11.c:5:15: warning:： initialization of ‘char *’ fromn‘int\u0026#39; makes pointer from integer without a cast [-Wint-conversion] 5| char *p = aaa(); | ^~~ ./test aaa--d:4b1c032----aaaa--0x560604b1c032 p=0x4b1c032 --- Segmentation fault (core dumped) 这里并没有引用这个头文件，为什么依然可以使用呢？\n这就引出了一个概念：隐式声明。\n简单来讲就是当前文件使用没有声明的函数时，编译器会自动声明一个，但返回值是int类型\n那为什么会出现段错误呢? 上面编译运行的环境是64bit的:\nchar* aaa() 返回的是一个指针8B(64bit) 但是在编译时 已经确定了是返回值类型(由于是隐式声名,编译器默认是int) 是int 4B(32bit) ,所以就会把指针的低32bit 取出来 赋给char* *p 指针p 的值就是一个截断的值, 这个指针就变成了一个非法的了,如果取访问其指向的内存,就会出现 段错误.\n如果是32bit 环境呢\nint 是4B 指针也是4B ,指针不会被截断,还是原来的值,不会出现非法访问.\n如何避免呢: 在Makefile 里加上 -Wall -Werror ,编译时会检测出这种错误\n","date":"2025-08-15T16:22:16+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/implicit-function-declaration/","title":"implicit-function-declaration"},{"content":"什么是虚拟网卡？ 虚拟网卡是软件实现的网络接口，与物理网卡不同，它没有物理硬件，只存在于操作系统的内存中。虚拟网卡可以用来模拟网络环境，进行数据包的捕获、分析和处理。 TUN 和 TAP 的基本概念 Tun （Network TUNnel） TUN 是三层（网络层）的虚拟网络设备，主要用于 IP 数据包的处理。TUN 设备会模拟一个网络层接口，接收到的数据包会被传递给用户空间的程序进行处理，处理完的数据包会被发送回内核网络栈。\nTAP（Network TAP） TAP 是二层（数据链路层）的虚拟网络设备，主要用于以太网帧的处理。TAP 设备可以模拟一个以太网接口，能够接收和发送原始的以太网帧。这使得 TAP 设备非常适合用于桥接不同的网络环境，或者在虚拟机中模拟物理网卡。TAP是数据链路层的虚拟网络设备。\nTun和Tap的异同 Tun是三层的设备，该设备没有MAC地址，从字符设备上读取IP数据包，写入的也是IP数据包，因此不能进行二层的操作，例如发ARP包和以太网广播 Tab是二层的设备，该设备有MAC地址，处理的是数据链路层的数据帧，从字符设备上读取的是数据链路层的数据帧，写入的也是数据。\n在使用上面，两者都是通过字符设备的方式进行读取和写入，Tun是三层网络设备，而Tab是二层网络设备，Tun常用于VPN等技术，由于工作在IP层，无法与物理网卡做bridge，但可以通过三层交换（如 ip_forward）与物理网卡连通，Tab设备工作在第二层，收发的是MAC层数据包，拥有MAC层的功能，可以与物理网卡做bridge，支持MAC层广播 Tun和Tap应用场景 Tun是一个网络层设备，支持点到点的网络通信，常用于tunnel隧道和VPN的构建，tunnel技术是网络设备把网络层数据包封装到另一个协议中以跨过网络传送到另一个网络设备的处理过程，主要用于公网主机和私有网络互联互通。在Linux系统中支持多种隧道技术，其底层实现原理都是基于Tun设备。 TAP接口的典型应用场景是在虚拟化网络中。例如，我们通过KVM创建的多个VM（虚拟机），以LinuxBridge（桥接网络）互通；实际上即是通过像vnet0这样的TAP接口来接入LinuxBridge的。在这种场景下，KVM程序就是向TAP接口读写数据的用户空间程序。当VM0向本机的eth0接口发送数据，KVM会将数据发送到TAP接口vnet0，再通过LinuxBridge将数据转发到vnet1上。然后，KVM将数据发送到VM1的eth0口。 Tun 配置 1 2 3 4 5 6 7 8 \\# 创建网卡并配置IP ip tuntap add dev tun0 mode tun ip link set dev tun0 up ip addr add 10.0.0.1/24 dev tun0 ip route add 10.0.0.0/24 via 10.0.0.1 \\# 清除网卡 ip link set dev tun0 down ip tuntap del dev tun0 mode tun 转载自\nLinux虚拟网卡TUN和TAP - 心若向阳花自开 - 博客园\n参考资料 Universal TUN/TAP device driver Universal TUN/TAP device driver Frequently Asked Question Tun/Tap interface tutorial A simplistic, simple-minded, naive tunnelling program using tun/tap interfaces and TCP ","date":"2025-08-07T15:17:36+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/linux%E8%99%9A%E6%8B%9F%E7%BD%91%E5%8D%A1tun%E5%92%8Ctap/","title":"Linux虚拟网卡TUN和TAP"},{"content":"作业控制 (Job Control) 作业控制是大多数 shell 提供的一个功能，允许用户在单个终端上同时运行和管理多个命令（作业）。\n前台作业 (Foreground Job): 在终端中启动，它会独占终端的输入和输出。在它运行期间，shell 会被挂起，等待该作业完成。\n后台作业 (Background Job): 通过在命令后添加 \u0026amp; 符号启动。它不会占用终端，你可以在它运行时继续在 shell 中输入其他命令。\nCtrl+Z(SIGTSTP）暂停前台进程Ctrl+C(SIGINT）终止当前前台进程Ctrl+D（EOF）\n常用命令: jobs, fg, bg, kill %\u0026lt;job_id\u0026gt;。\n进程组 (Process Group) 进程组是一个或多个进程的集合。系统中的每个进程都属于一个进程组。\n目的: 主要用于作业控制，方便将信号（如 SIGINT, SIGTSTP）发送到一组相关的进程。例如，当你在终端按下 Ctrl+C 时，SIGINT 信号会被发送到当前前台作业的整个进程组。\n进程组ID (PGID): 每个进程组都有一个唯一的 ID。\n进程组领导 (Process Group Leader): 进程组中第一个创建的进程，其 PID 通常就是该进程组的 PGID。\n一个管道（pipeline）中的所有进程（例如 cat file | grep \u0026quot;text\u0026quot; | wc -l）通常属于同一个进程组。\n会话 (Session) 会话是一个或多个进程组的集合。它提供了一个更高层次的进程组织方式。\n目的: 将一个用户登录到退出期间创建的所有进程组织在一起。\n会话ID (SID): 每个会话都有一个唯一的 ID。\n会话领导 (Session Leader): 创建该会话的进程。通常，这是用户登录时启动的 shell 进程。\n控制终端 (Controlling Terminal): 一个会话通常与一个控制终端相关联。当控制终端断开连接时（例如关闭终端窗口或网络断开），内核会向会话领导发送 SIGHUP 信号，后者通常会将其传播给会话中的所有进程，导致它们终止。\nsetsid() 系统调用 setsid() 是一个关键的系统调用，用于创建一个新的会话。\n功能: 1. 调用 setsid() 的进程会成为一个新会话的会话领导。\n2. 该进程会成为一个新进程组的进程组领导。\n3. 该进程会脱离它之前的控制终端。\n前提: 调用 setsid() 的进程不能是某个现有进程组的领导者。为了确保这一点，通常的做法是 fork() 一个子进程，然后让父进程退出，子进程再调用 setsid()。\n用途: 这是创建守护进程（Daemon）的标准方法。通过创建一个没有控制终端的新会hs话，守护进程可以确保自己不会因为终端的关闭而意外终止。\nlxc-attach 后台进程导致退出卡住的原因分析 问题场景 用户在终端中执行 lxc-attach \u0026lt;container_name\u0026gt;。\n在 lxc-attach 创建的 shell 中，启动一个后台作业。\n输入 exit 尝试退出 lxc-attach 的 shell。\n此时，终端卡住，用telnet 连接然后kill 掉才可以回到host 主机的shell\n原因剖析 这个问题的核心在于进程关系和信号处理。\n进程结构: - 当你运行 lxc-attach 时，它会在容器内启动一个新的 shell 进程（如 bash）。\n- 这个新的 shell 是 lxc-attach 进程的子进程。\n- 重要的是，这个新 shell 没有成为新的会话领导。它与 lxc-attach 进程、以及你最初的登录 shell 位于同一个会话中，并共享同一个控制终端。\n启动后台进程: - 当你在 lxc-attach 的 shell 中运行一个后台进程。\n- 这个 后台进程与 lxc-attach 的 shell 属于同一个进程组。\n执行 exit: - 你输入 exit，lxc-attach 的 shell 进程开始退出流程。\n- shell 进程本身会终止。\n- lxc-attach 进程在等待其子进程（即那个 shell）完全终止。\n卡住的根源: - shell 进程虽然终止了，但它启动的后台进程仍然在运行。\n- 这个后台进程仍然是前台进程组的一部分（相对于控制终端而言），或者说它仍然与控制终端关联。\n- 控制终端的驱动程序会发现，虽然前台的 shell 退出了，但该进程组里还有其他进程 在运行。此时，终端会处于一种“挂起”或“等待”状态，因为它需要处理这个仍在运行的后台进程的标准输入/输出（即使它不读写）。\n- lxc-attach 进程本身也在等待，因为它可能需要清理与子进程相关的所有资源。只要 这个后台进程还在运行，整个进程链就无法干净地结束。\n- 只有当 这个后台进程结束后，整个进程组才算完全终结，控制终端的锁定状态被解除，lxc-attach 进程也随之退出，你才能回到原来的 shell 提示符。\n解决办法: nohup setsid disown\n参考链接 Linux session和进程组概述 - Linux程序员 - SegmentFault 思否\nLinux TTY/PTS概述 - Linux程序员 - SegmentFault 思否\n","date":"2025-08-06T15:36:36+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/linux-%E4%BD%9C%E4%B8%9A%E6%8E%A7%E5%88%B6%E8%BF%9B%E7%A8%8B%E7%BB%84%E5%92%8C%E4%BC%9A%E8%AF%9D/","title":"Linux 作业控制、进程组和会话"},{"content":"frok 一个运行的进程,它调用了fork()函数，然后就产生了子进程，原来的进程叫父进程。这个子进程也是进程，但凡是进程，都有自己的虚拟地址空间（让每个进程自己看起来是独占内存，通过段页内存管理映射到不同的物理地址空间）。虚拟地址空间是从0到4G的大小，其中3-4G是属于内核的（32位系统）。创建完子进程后，父进程继续运行程序（即原来的进程）的代码，刚创建出来的子进程拥有和父进程完全一样的代码段，数据段，也就是说完完全全拷贝了一份父进程，和父进程完全一样。即clone父进程0-3G的内容，而3-4G的kernel只需要重新映射一下到物理地址的kernel即可。但是操作系统要如何区分这两个进程呢？答案就是进程ID即pid。pid是存储在PCB当中的类似身份证的东西. kernel会创建子进程自己的PCB,然后clone父进程的PCB(task_struct)的绝大部分信息，如内存映射(mm_struct，采用 COW 机制copy on write),文件描述符表,调度信息（优先级、CPU 时间等）,但某些关键字段会被修改,如pid,ppid等.\nkernel会设置 fork() 的返回值.在子进程的 task_struct 中，kernel会预先设置 eax/rax 寄存器（存储返回值）为 0，因此子进程看到的 fork() 返回 0。父进程的 fork() 返回子进程的 pid。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; int q_val = 100; int main() { printf(\u0026#34;father is running, pid: %d, ppid: %d\\n\u0026#34;, getpid(), getppid()); sleep(2); pid_t id = fork(); int cnt = 3; while(1) { if(id == 0) { // Child process printf(\u0026#34;I am child process, pid: %d, ppid: %d, q_val: %d, \u0026amp;q_val: %p\\n\u0026#34;, getpid(), getppid(), q_val, \u0026amp;q_val); sleep(1); cnt--; if(cnt == 0) { q_val = 300; printf(\u0026#34;I am child, q_val is changed, 100 -\u0026gt; 300\\n\u0026#34;); } } else { // Parent process printf(\u0026#34;I am father process, pid: %d, ppid: %d, q_val: %d, \u0026amp;q_val: %p\\n\u0026#34;, getpid(), getppid(), q_val, \u0026amp;q_val); sleep(1); } } return 0; } fork底层是调用了内核的函数来实现fork的功能的，即先create()先创建进程，此时进程内容为空，然后clone()复制父进程的内容到子进程中，此时子进程就诞生了，接着父进程就return返回了。而子进程诞生后，是直接运行return返回的，然后接着执行后面的程序，这里注意：子进程是不会执行前面父进程已经执行过的程序了得，因为PCB中记录了当前进程运行到哪里，而子进程又是完全拷贝过来的，所以PCB的程序计数器也是和父进程相同的，所以是从fork()后面的程序继续执行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 father is running, pid: 2193928, ppid: 784260 I am father process, pid: 2193928, ppid: 784260, q_val: 100, \u0026amp;q_val: 0x55e878c7f010 I am child process, pid: 2193930, ppid: 2193928, q_val: 100, \u0026amp;q_val: 0x55e878c7f010 I am father process, pid: 2193928, ppid: 784260, q_val: 100, \u0026amp;q_val: 0x55e878c7f010 I am child process, pid: 2193930, ppid: 2193928, q_val: 100, \u0026amp;q_val: 0x55e878c7f010 I am father process, pid: 2193928, ppid: 784260, q_val: 100, \u0026amp;q_val: 0x55e878c7f010 I am child process, pid: 2193930, ppid: 2193928, q_val: 100, \u0026amp;q_val: 0x55e878c7f010 I am father process, pid: 2193928, ppid: 784260, q_val: 100, \u0026amp;q_val: 0x55e878c7f010 I am child process, pid: 2193930, ppid: 2193928, q_val: 100, \u0026amp;q_val: 0x55e878c7f010 I am father process, pid: 2193928, ppid: 784260, q_val: 100, \u0026amp;q_val: 0x55e878c7f010 I am child, q_val is changed, 100 -\u0026gt; 300 I am child process, pid: 2193930, ppid: 2193928, q_val: 300, \u0026amp;q_val: 0x55e878c7f010 I am father process, pid: 2193928, ppid: 784260, q_val: 100, \u0026amp;q_val: 0x55e878c7f010 I am child process, pid: 2193930, ppid: 2193928, q_val: 300, \u0026amp;q_val: 0x55e878c7f010 I am father process, pid: 2193928, ppid: 784260, q_val: 100, \u0026amp;q_val: 0x55e878c7f010 I am child process, pid: 2193930, ppid: 2193928, q_val: 300, \u0026amp;q_val: 0x55e878c7f010 I am father process, pid: 2193928, ppid: 784260, q_val: 100, \u0026amp;q_val: 0x55e878c7f010 I am child process, pid exec族 用fork创建子进程后执行的是和父进程相同的程序（但有可能执行不同的代码分支）， 子进程往往要调用一种exec函数以执行另一个程序。当进程调用一种exec函数时，该进程的 用户空间代码和数据完全被新程序替换，从新程序的启动例程开始执行。调用exec并不创建 新进程，所以调用exec前后该进程的id并未改变\n1 2 3 4 5 6 7 #include int execl(const char *path, const char *arg, ...); int execlp(const char *file, const char *arg, ...); int execle(const char *path, const char *arg, ..., char *const envp[]); int execv(const char *path, char *const argv[]); int execvp(const char *file, char *const argv[]); int execve(const char *path, char *const argv[], char *const envp[]); 这些函数如果调用成功则加载新的程序从启动代码开始执行，不再返回，如果调用出错 则返回-1，所以exec函数只有出错的返回值而没有成功的返回值\nwait/waitpid 僵尸进程: 子进程退出，父进程没有回收子进程资源（PCB），则子进程变成僵尸进程 孤儿进程: 父进程先于子进程结束，则子进程成为孤儿进程,子进程的父进程成为1号 进程init进程，称为init进程领养孤儿进程\n一个进程在终止时会关闭所有文件描述符，释放在用户空间分配的内存，但它的PCB还 保留着，内核在其中保存了一些信息：如果是正常终止则保存着退出状态，如果是异常终止 则保存着导致该进程终止的信号是哪个。这个进程的父进程可以调用wait或waitpid获取这 些信息，然后彻底清除掉这个进程。我们知道一个进程的退出状态可以在Shell中用特殊变 量$?查看，因为Shell是它的父进程，当它终止时Shell调用wait或waitpid得到它的退出状 态同时彻底清除掉这个进程。但是，如果父进程先于子进程结束，则子进程成为孤儿进程。孤儿进程将被 init 进程（进程号为1）领养，并由 init 进程对孤儿进程完成状态收集工作。而如果子进程先于父进程退出，同时父进程太忙了，无瑕回收子进程的资源，子进程残留资源（PCB）存放于内核中，变成僵尸。任何进程在刚终止时都是僵尸进程，正常情况下，僵 尸进程都立刻被父进程清理了.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; int main(void) { pid_t pid; pid = fork(); if (pid == 0) { printf(\u0026#34;I am child, my parent= %d, going to sleep 3s\\n\u0026#34;, getppid()); sleep(3); printf(\u0026#34;-------------child die--------------\\n\u0026#34;); } else if (pid \u0026gt; 0) { printf(\u0026#34;I am parent, pid = %d, myson = %d, going to sleep 5s\\n\u0026#34;, getpid(), pid); sleep(5); system(\u0026#34;ps -o pid,ppid,state,tty,command\u0026#34;); } else { perror(\u0026#34;fork\u0026#34;); return 1; } return 0; } 在这个程序里，父进程创建子进程之后，就休眠 5 秒钟。而子进程只休眠 3 秒钟就退出，在它退出之后，父进程还未苏醒，因此没人给子进程「收尸」，所以它就变成了僵尸进程。\n僵尸进程其实已经就是退出的进程，因此无法再利用kill命令杀死僵尸进程。僵尸进程的罪魁祸首是父进程没有回收它的资源，那我们可以想办法它其它进程去回收僵尸进程的资源，这个进程就是 init 进程。因此，我们可以直接杀死父进程，init 进程就会很善良地把那些僵尸进程领养过来，并合理的回收它们的资源，那些僵尸进程就得到了妥善的处理了\n","date":"2025-07-31T17:22:16+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/%E8%BF%9B%E7%A8%8B%E5%8E%9F%E8%AF%ADfork-exceve-waitpid/","title":"进程原语fork exceve waitpid"},{"content":"openwrt procd启动流程分析 kernel_init Linux内核执行start_kernel函数时会调用kernel_init来启动init进程，流程如下图\nstart_kernel\u0026ndash;\u0026gt;rest_init\u0026ndash;\u0026gt;kernel_init\u0026ndash;\u0026gt;try_to_run_init_process\nkernel_init()(位于 linux-4.1.52/init/main.c)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 /* * We try each of these until one succeeds. * * The Bourne shell can be used instead of init if we are * trying to recover a really broken machine. */ if (execute_command) { ret = run_init_process(execute_command); if (!ret) return 0; panic(\u0026#34;Requested init %s failed (error %d).\u0026#34;, execute_command, ret); } if (!try_to_run_init_process(\u0026#34;/sbin/init\u0026#34;) || !try_to_run_init_process(\u0026#34;/etc/init\u0026#34;) || !try_to_run_init_process(\u0026#34;/bin/init\u0026#34;) || !try_to_run_init_process(\u0026#34;/bin/sh\u0026#34;)) return 0; panic(\u0026#34;No working init found. Try passing init= option to kernel. \u0026#34; \u0026#34;See Linux Documentation/init.txt for guidance.\u0026#34;); } /sbin/init openwrt 源码 openwrt/package/system/procd/Makefile\n1 2 3 4 5 6 7 8 9 10 define Package/procd/install $(INSTALL_DIR) $(1)/sbin $(1)/etc $(1)/lib/functions $(INSTALL_BIN) $(PKG_INSTALL_DIR)/usr/sbin/{init,procd,askfirst,udevtrigger,upgraded} $(1)/sbin/ $(INSTALL_DATA) $(PKG_INSTALL_DIR)/usr/lib/libsetlbf.so $(1)/lib $(INSTALL_BIN) ./files/reload_config $(1)/sbin/ $(INSTALL_CONF) ./files/hotplug*.json $(1)/etc/ $(INSTALL_DATA) ./files/procd.sh $(1)/lib/functions/ $(INSTALL_BIN) ./files/service $(1)/sbin/service endef procd源码procd/CMakeList.txt\n1 2 3 4 5 6 7 8 9 10 IF(DISABLE_INIT) ADD_DEFINITIONS(-DDISABLE_INIT) ELSE() ADD_EXECUTABLE(init initd/init.c initd/early.c initd/preinit.c initd/mkdev.c sysupgrade.c watchdog.c utils/utils.c) TARGET_INCLUDE_DIRECTORIES(init PUBLIC ${SELINUX_INCLUDE_DIRS}) TARGET_LINK_LIBRARIES(init ${LIBS} ${SELINUX_LIBRARIES}) INSTALL(TARGETS init RUNTIME DESTINATION ${CMAKE_INSTALL_SBINDIR} ) procd 启动流程 /sbin/init main 函数入口位于 procd/initd/init.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 int main(int argc, char **argv) { pid_t pid; ulog_open(ULOG_KMSG, LOG_DAEMON, \u0026#34;init\u0026#34;); sigaction(SIGTERM, \u0026amp;sa_shutdown, NULL); sigaction(SIGUSR1, \u0026amp;sa_shutdown, NULL); sigaction(SIGUSR2, \u0026amp;sa_shutdown, NULL); sigaction(SIGPWR, \u0026amp;sa_shutdown, NULL); if (selinux(argv)) exit(-1); early(); cmdline(); watchdog_init(1); pid = fork(); if (!pid) { char *kmod[] = { \u0026#34;/sbin/kmodloader\u0026#34;, \u0026#34;/etc/modules-boot.d/\u0026#34;, NULL }; if (debug \u0026lt; 3) patch_stdio(\u0026#34;/dev/null\u0026#34;); execvp(kmod[0], kmod); ERROR(\u0026#34;Failed to start kmodloader: %m\\n\u0026#34;); exit(EXIT_FAILURE); } if (pid \u0026lt;= 0) { ERROR(\u0026#34;Failed to start kmodloader instance: %m\\n\u0026#34;); } else { const struct timespec req = {0, 10 * 1000 * 1000}; int i; for (i = 0; i \u0026lt; 1200; i++) { if (waitpid(pid, NULL, WNOHANG) \u0026gt; 0) break; nanosleep(\u0026amp;req, NULL); watchdog_ping(); } } uloop_init(); preinit(); uloop_run(); return 0; } kmodloader 先启动的是kmodloader(实现于openwrt/ubox/kmodloader.c),会insmod位于/etc/modules.d/下的kernel module list\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 static int main_loader(int argc, char **argv) { int gl_flags = GLOB_NOESCAPE | GLOB_MARK; char *dir = \u0026#34;/etc/modules.d/\u0026#34;; struct module_node *mn; struct module *m; glob_t gl; char *path; int ret = 0, fail, j; if (argc \u0026gt; 1) dir = argv[1]; path = malloc(strlen(dir) + 2); if (!path) { ULOG_ERR(\u0026#34;out of memory\\n\u0026#34;); return -1; } strcpy(path, dir); strcat(path, \u0026#34;*\u0026#34;); if (scan_module_folders()) { ret = -1; goto free_path; } if (scan_loaded_modules()) { ret = -1; goto free_path; } ULOG_INFO(\u0026#34;loading kernel modules from %s\\n\u0026#34;, path); ...... } int main(int argc, char **argv) { char *exec = basename(*argv); avl_init(\u0026amp;modules, avl_modcmp, true, NULL); if (!strcmp(exec, \u0026#34;insmod\u0026#34;)) return main_insmod(argc, argv); if (!strcmp(exec, \u0026#34;rmmod\u0026#34;)) return main_rmmod(argc, argv); if (!strcmp(exec, \u0026#34;lsmod\u0026#34;)) return main_lsmod(argc, argv); if (!strcmp(exec, \u0026#34;modinfo\u0026#34;)) return main_modinfo(argc, argv); load_options(); if (!strcmp(exec, \u0026#34;modprobe\u0026#34;)) return main_modprobe(argc, argv); ulog_open(ULOG_KMSG, LOG_USER, \u0026#34;kmodloader\u0026#34;); return main_loader(argc, argv); } uloop_init实现位于libubox源码uloop.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 int uloop_init(void) { if (uloop_init_pollfd() \u0026lt; 0) return -1; if (waker_init() \u0026lt; 0) { uloop_done(); return -1; } return 0; } static int uloop_init_pollfd(void) { if (poll_fd \u0026gt;= 0) return 0; poll_fd = epoll_create(32); if (poll_fd \u0026lt; 0) return -1; fcntl(poll_fd, F_SETFD, fcntl(poll_fd, F_GETFD) | FD_CLOEXEC); return 0; } preinit实现位于procd源码文件initd/preinit.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 static struct uloop_process preinit_proc; static struct uloop_process plugd_proc; void preinit(void) { char *init[] = { \u0026#34;/bin/sh\u0026#34;, \u0026#34;/etc/preinit\u0026#34;, NULL }; char *plug[] = { \u0026#34;/sbin/procd\u0026#34;, \u0026#34;-h\u0026#34;, \u0026#34;/etc/hotplug-preinit.json\u0026#34;, NULL }; int fd; LOG(\u0026#34;- preinit -\\n\u0026#34;); plugd_proc.cb = plugd_proc_cb; plugd_proc.pid = fork(); if (!plugd_proc.pid) { execvp(plug[0], plug); ERROR(\u0026#34;Failed to start plugd: %m\\n\u0026#34;); exit(EXIT_FAILURE); } if (plugd_proc.pid \u0026lt;= 0) { ERROR(\u0026#34;Failed to start new plugd instance: %m\\n\u0026#34;); return; } uloop_process_add(\u0026amp;plugd_proc); setenv(\u0026#34;PREINIT\u0026#34;, \u0026#34;1\u0026#34;, 1); fd = creat(\u0026#34;/tmp/.preinit\u0026#34;, 0600); if (fd \u0026lt; 0) ERROR(\u0026#34;Failed to create sentinel file: %m\\n\u0026#34;); else close(fd); preinit_proc.cb = spawn_procd; preinit_proc.pid = fork(); if (!preinit_proc.pid) { execvp(init[0], init); ERROR(\u0026#34;Failed to start preinit: %m\\n\u0026#34;); exit(EXIT_FAILURE); } if (preinit_proc.pid \u0026lt;= 0) { ERROR(\u0026#34;Failed to start new preinit instance: %m\\n\u0026#34;); return; } uloop_process_add(\u0026amp;preinit_proc); DEBUG(4, \u0026#34;Launched preinit instance, pid=%d\\n\u0026#34;, (int) preinit_proc.pid); } 创建子进程执行 /sbin/procd -h /etc/hotplug-preinit.json ，主进程同时使用 uloop_process_add()把 /sbin/procd 子进程加入 uloop 进行监控，当 /sbin/procd 进程结束时回调 plugd_proc_cb 函数。 创建子进程执行 /etc/preinit 脚本，此时 PREINIT环境变量被设置为1，主进程同时使用 uloop_process_add() 把/etc/preinit 子进程加入 uloop 进行监控，当 /etc/preinit 执行结束时回调 spawn_procd函数 spawn_procd()函数繁行后继真正使用的 /sbin/procd 进程，从 /tmp/debuglevel 读出 debug 级别并设置到环境变量 DBGLVL 中，把 watchdog fd 设置到环境变量 WDTFD 中，最后调用 execvp()繁行 /sbin/procd 进程 首先看procd，因为带有参数“-h /etc/hotplug-preinit.json”，所以会执行hotplug_run函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 int main(int argc, char **argv) { int ch; char *dbglvl = getenv(\u0026#34;DBGLVL\u0026#34;); int ulog_channels = ULOG_KMSG; if (dbglvl) { debug = atoi(dbglvl); unsetenv(\u0026#34;DBGLVL\u0026#34;); } while ((ch = getopt(argc, argv, \u0026#34;d:s:h:S\u0026#34;)) != -1) { switch (ch) { case \u0026#39;h\u0026#39;: return hotplug_run(optarg); // hotplug case \u0026#39;s\u0026#39;: ubus_socket = optarg; break; case \u0026#39;d\u0026#39;: debug = atoi(optarg); break; case \u0026#39;S\u0026#39;: ulog_channels = ULOG_STDIO; break; default: return usage(argv[0]); } } ulog_open(ulog_channels, LOG_DAEMON, \u0026#34;procd\u0026#34;); ulog_threshold(LOG_DEBUG + 1); setsid(); uloop_init(); procd_signal(); procd_udebug_set_enabled(true); if (getpid() != 1) procd_connect_ubus(); else procd_state_next(); uloop_run(); uloop_done(); return 0; } hotplug实现如下，这里是建立netlink通信机制，完成用户层和内核的交互，监听内核的uevent事件。\nprocd/plug/hotplug.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 void hotplug(char *rules) { struct sockaddr_nl nls; int nlbufsize = 512 * 1024; rule_file = strdup(rules); memset(\u0026amp;nls,0,sizeof(struct sockaddr_nl)); nls.nl_family = AF_NETLINK; nls.nl_pid = getpid(); nls.nl_groups = -1; if ((hotplug_fd.fd = socket(PF_NETLINK, SOCK_DGRAM | SOCK_CLOEXEC, NETLINK_KOBJECT_UEVENT)) == -1) { ERROR(\u0026#34;Failed to open hotplug socket: %s\\n\u0026#34;, strerror(errno)); exit(1); } if (bind(hotplug_fd.fd, (void *)\u0026amp;nls, sizeof(struct sockaddr_nl))) { ERROR(\u0026#34;Failed to bind hotplug socket: %s\\n\u0026#34;, strerror(errno)); exit(1); } if (setsockopt(hotplug_fd.fd, SOL_SOCKET, SO_RCVBUFFORCE, \u0026amp;nlbufsize, sizeof(nlbufsize))) ERROR(\u0026#34;Failed to resize receive buffer: %s\\n\u0026#34;, strerror(errno)); json_script_init(\u0026amp;jctx); queue_proc.cb = queue_proc_cb; uloop_fd_add(\u0026amp;hotplug_fd, ULOOP_READ); } int hotplug_run(char *rules) { uloop_init(); hotplug(rules); uloop_run(); return 0; } 内核发出uevent事件 内核使用 uevent 事件通知用户空间， uevent 首先在内核中调用 netink_kemel_create() 函数创建一个 socket 套接字，该函数原型在 netink.h 中定义。这是一种特殊类型的 socket ，专门用于内核空间与用户空间的异步通信。kobject_uevent()产生uevent 事件 (/lib/kobject_uevent.c)，事件的部分信息通过环境变量传递，如$ACTION,$DEVPATH,$SUBSYSTEM 等，产生的 uevent 先由 netlink_broadcast_filtered()发出，最后调用uevent helper 所指定的程序来处理。在linux 中，uevent_helper 里默认指定\u0026quot;/sbin/hotplug”，但可以通过 /sys/kemel/uevent helper (kernel/ksysfs.c) /proc/kernel/uevent_elper(kernel/sysctl.c)来修改成指定的程序。在新 OpenWRT 中，并不使用 user helper 指定程序来处理 uevent(/sbin/hotplug 不存在，在以前版本中存在)，而是通过PF_NETLINK套接字来获取来自内核空间的 uevent 。 用户空间监听uevent 在 procd/plug/hotplug.c 中，创建一个 PF_NETLINK 套接字来监听内核 netlink_broadcast_fitered() 发出的 uevent 。收到uevent 之后，在根据 /etc/hotplug.json 里的描述，定位到对应的执行函数来处理.通常情况下， /etc/hotplug.json 会调用 /sbin/hotplug-call 来处理 uevent ，它根据 uevent 的 $SUBSYSTEM 变量来分别调用 /etc/hotplug.d 下不同目录中的脚本。 /etc/preinit脚本大致内容如下，先调用另外的shell脚本，获取函数定义\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 . /lib/functions.sh . /lib/functions/preinit.sh . /lib/functions/system.sh # 初始化hook链 boot_hook_init preinit_essential boot_hook_init preinit_main boot_hook_init failsafe boot_hook_init initramfs # 依次执行/lib/preinit目录中的脚本，将函数调用添加到hook链中 for pi_source_file in /lib/preinit/*; do . $pi_source_file done # 执行preinit_essential注册的hook链的所有函数 boot_run_hook preinit_essential # 执行preinit_main注册的hook链的所有函数 boot_run_hook preinit_main /etc/preinit脚本执行完成后，调用spawn_procd,spawn_procd会调用 execvp()执行 /sbin/procd进程\nprocd/initd/preinit.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 spawn_procd(struct uloop_process *proc, int ret) { char *wdt_fd = watchdog_fd(); char *argv[] = { \u0026#34;/sbin/procd\u0026#34;, NULL}; char dbg[2]; if (plugd_proc.pid \u0026gt; 0) kill(plugd_proc.pid, SIGKILL); unsetenv(\u0026#34;PREINIT\u0026#34;); unlink(\u0026#34;/tmp/.preinit\u0026#34;); check_sysupgrade(); DEBUG(2, \u0026#34;Exec to real procd now\\n\u0026#34;); if (wdt_fd) setenv(\u0026#34;WDTFD\u0026#34;, wdt_fd, 1); check_dbglvl(); if (debug \u0026gt; 0) { snprintf(dbg, 2, \u0026#34;%d\u0026#34;, debug); setenv(\u0026#34;DBGLVL\u0026#34;, dbg, 1); } execvp(argv[0], argv); } procd/procd.c中\n1 2 3 4 5 6 7 8 9 10 setsid(); uloop_init(); procd_signal(); procd_udebug_set_enabled(true); if (getpid() != 1) procd_connect_ubus(); else procd_state_next(); uloop_run(); uloop_done(); 此时getpid()等于1，所以调用procd_state_next，进入到状态机处理中。\nprocd_state不断迁移，包括STATE_EARLY，STATE_UBUS，STATE_INIT等。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 [ 3.161338@3] init: Console is alive [ 3.173921@3] init: Ping [ 3.184207@3] init: Ping [ 3.192558@1] kmodloader: loading kernel modules from /etc/modules-boot.d/* [ 3.194447@3] init: Ping [ 3.196209@1] kmodloader: done loading kernel modules from /etc/modules-boot.d/* [ 3.204716@3] init: Ping [ 3.206180@3] init: - preinit - [ 3.208671@3] init: Launched preinit instance, pid=1308 [ 3.302967@3] init: Exec to real procd now [ 3.308865@3] procd: - early - [ 3.524654@2] procd: Finished udevtrigger [ 4.024929@2] procd: Coldplug complete [ 4.028061@2] procd: - ubus - [ 4.029198@2] procd: Create service ubus [ 4.030829@2] procd: Create instance ubus::instance1 [ 4.032109@2] procd: Started instance ubus::instance1[1554] [ 4.098895@2] procd: Connected to ubus, id=459ede6c [ 4.099092@2] procd: - init - [ 4.102474@2] procd: Launched new askconsole action, pid=1555 [ 4.104142@2] procd: Launched new askfirst action, pid=1556 以STATE_INIT为例，执行procd_inittab_run(\u0026ldquo;xxx\u0026rdquo;)会调用对应handlers的callback，对应所有的init_action是在procd_inittab()中添加的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 case STATE_INIT: LOG(\u0026#34;- init -\\n\u0026#34;); procd_inittab(); procd_inittab_run(\u0026#34;respawn\u0026#34;); procd_inittab_run(\u0026#34;askconsole\u0026#34;); procd_inittab_run(\u0026#34;askfirst\u0026#34;); procd_inittab_run(\u0026#34;sysinit\u0026#34;); static struct init_handler handlers[] = { { .name = \u0026#34;sysinit\u0026#34;, .cb = runrc, }, { .name = \u0026#34;shutdown\u0026#34;, .cb = runrc, }, { .name = \u0026#34;askfirst\u0026#34;, .cb = askfirst, .multi = 1, }, { .name = \u0026#34;askconsole\u0026#34;, .cb = askconsole, .multi = 1, }, { .name = \u0026#34;respawn\u0026#34;, .cb = rcrespawn, .multi = 1, } }; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 static const char *tab = \u0026#34;/etc/inittab\u0026#34;; static char *ask = \u0026#34;/sbin/askfirst\u0026#34;; static int add_action(struct init_action *a, const char *name) { int i; for (i = 0; i \u0026lt; ARRAY_SIZE(handlers); i++) if (!strcmp(handlers[i].name, name)) { a-\u0026gt;handler = \u0026amp;handlers[i]; list_add_tail(\u0026amp;a-\u0026gt;list, \u0026amp;actions); return 0; } ERROR(\u0026#34;Unknown init handler %s\\n\u0026#34;, name); return -1; } void procd_inittab(void) { #define LINE_LEN 128 FILE *fp = fopen(tab, \u0026#34;r\u0026#34;); struct init_action *a; regex_t pat_inittab; regmatch_t matches[5]; char *line; if (!fp) { ERROR(\u0026#34;Failed to open %s: %m\\n\u0026#34;, tab); return; } regcomp(\u0026amp;pat_inittab, \u0026#34;([a-zA-Z0-9]*):([a-zA-Z0-9]*):([a-zA-Z0-9]*):(.*)\u0026#34;, REG_EXTENDED); line = malloc(LINE_LEN); a = calloc(1, sizeof(struct init_action)); while (fgets(line, LINE_LEN, fp)) { char *tags[TAG_PROCESS + 1]; char *tok; int i; int len = strlen(line); while (isspace(line[len - 1])) len--; line[len] = 0; if (*line == \u0026#39;#\u0026#39;) continue; if (regexec(\u0026amp;pat_inittab, line, 5, matches, 0)) continue; DEBUG(4, \u0026#34;Parsing inittab - %s\\n\u0026#34;, line); for (i = TAG_ID; i \u0026lt;= TAG_PROCESS; i++) { line[matches[i].rm_eo] = \u0026#39;\\0\u0026#39;; tags[i] = \u0026amp;line[matches[i + 1].rm_so]; }; tok = strtok(tags[TAG_PROCESS], \u0026#34; \u0026#34;); for (i = 0; i \u0026lt; (MAX_ARGS - 1) \u0026amp;\u0026amp; tok; i++) { a-\u0026gt;argv[i] = tok; tok = strtok(NULL, \u0026#34; \u0026#34;); } a-\u0026gt;argv[i] = NULL; a-\u0026gt;id = tags[TAG_ID]; a-\u0026gt;line = line; if (add_action(a, tags[TAG_ACTION])) continue; line = malloc(LINE_LEN); a = calloc(1, sizeof(struct init_action)); } fclose(fp); free(line); free(a); regfree(\u0026amp;pat_inittab); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 void procd_inittab_run(const char *handler) { struct init_action *a; list_for_each_entry(a, \u0026amp;actions, list) { if (!strcmp(a-\u0026gt;handler-\u0026gt;name, handler)) { if (a-\u0026gt;handler-\u0026gt;multi) { a-\u0026gt;handler-\u0026gt;cb(a); continue; } a-\u0026gt;handler-\u0026gt;cb(a); break; } } } /etc/inittab\n1 2 3 ::sysinit:/etc/init.d/rcS S boot ::shutdown:/etc/init.d/rcS K shutdown ::askconsole:/usr/libexec/login.sh 这里来看runrc的实现，代码位于inittab.c\n1 2 3 4 5 6 7 8 9 10 11 static void runrc(struct init_action *a) { if (!a-\u0026gt;argv[1] || !a-\u0026gt;argv[2]) { ERROR(\u0026#34;valid format is rcS \u0026lt;S|K\u0026gt; \u0026lt;param\u0026gt;\\n\u0026#34;); return; } /* proceed even if no init or shutdown scripts run */ if (rcS(a-\u0026gt;argv[1], a-\u0026gt;argv[2], rcdone)) rcdone(NULL); } rcS.c\n1 2 3 4 5 6 7 8 int rcS(char *pattern, char *param, void (*q_empty)(struct runqueue *)) { runqueue_init(\u0026amp;q); q.empty_cb = q_empty; q.max_running_tasks = 1; return _rc(\u0026amp;q, \u0026#34;/etc/rc.d\u0026#34;, pattern, \u0026#34;*\u0026#34;, param); } 执行/etc/rc.d目录下S开头的脚本\n","date":"2025-07-30T18:28:23+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/openwrt-procd%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90/","title":"openwrt procd启动流程分析"},{"content":"OverlayFS 简介 OverlayFS (Overlay Filesystem) 是一种联合文件系统（Union Filesystem），它允许用户将一个文件系统（通常是可写的）“覆盖”在另一个文件系统（通常是只读的）之上。对于用户来说，这两个文件系统看起来像是一个合并后的单一目录树。\nOverlayFS 在 Linux 内核 3.18 中被合并进主线，因其设计简洁、性能高效而被广泛应用于容器技术（如 Docker）和嵌入式系统（如 OpenWrt）。\n核心概念 OverlayFS 主要涉及四个目录层级：\nLower Dir (底层目录): 通常是只读的。 在 OpenWrt 中，这通常对应于压缩的只读固件部分（SquashFS）。 可以有多个 Lower 层。\nUpper Dir (上层目录): 是可写的。 所有对文件系统的修改（新建、修改、删除）都会记录在这里。 在 OpenWrt 中，这通常对应于 JFFS2 或 UBIFS 分区。\nWork Dir (工作目录): 一个对用户不可见的空目录，OverlayFS 使用它来准备文件操作（如原子性保证）。 必须与 Upper Dir 在同一个文件系统下。\nMerged Dir (合并目录): 这是用户最终看到的挂载点。 它展示了 Lower 和 Upper 合并后的视图。\n工作原理 读取 (Read): 如果文件在 Upper 层存在，直接读取 Upper 层的文件。 如果文件仅在 Lower 层存在，读取 Lower 层的文件。 如果两层都有，Upper 层的文件会“遮盖”住 Lower 层的文件。\n写入 (Write):\n修改文件: 当尝试修改一个位于 Lower 层的文件时，OverlayFS 会触发 Copy-Up 操作，将文件从 Lower 层复制到 Upper 层，然后对 Upper 层的文件进行修改。 新建文件: 直接在 Upper 层创建。 删除 (Delete): 如果删除的是 Upper 层的文件，直接删除。 如果删除的是 Lower 层的文件，OverlayFS 会在 Upper 层创建一个特殊的 Whiteout 文件（通常是字符设备 0/0），用于标记该文件已被“遮盖”（即删除），从而在 Merged 视图中不可见。\nOpenWrt 中的 OverlayFS 应用 OpenWrt 是 OverlayFS 最经典的落地场景之一。它利用 OverlayFS 完美解决了嵌入式设备存储空间有限且需要系统恢复能力的矛盾。\nOpenWrt 的文件系统架构 OpenWrt 的固件通常包含两个主要部分：\n/rom (Read-Only): 这是一个 SquashFS 文件系统，包含了系统启动所需的所有基础文件、内核模块和默认配置。 它是高度压缩的，且在运行时是只读的。这保证了系统核心文件的安全性，无论用户如何误操作，都可以恢复出厂设置。\n/overlay (Read-Write): 这是一个 JFFS2 (对于 NOR Flash) 或 UBIFS (对于 NAND Flash) 文件系统，或者是 ext4 (对于 SD 卡/硬盘)。 它用于存储用户的配置更改、安装的软件包等。\n挂载机制 当 OpenWrt 启动时，它会执行以下逻辑（简化版）：\n挂载 SquashFS 分区到 /rom。 挂载可写分区（如 JFFS2）到 /overlay。 使用 OverlayFS 将 /overlay（Upper）覆盖在 /rom（Lower）之上，并将结果挂载到根目录 /。 挂载命令示例:\n1 mount -t overlay overlay -o lowerdir=/rom,upperdir=/overlay/upper,workdir=/overlay/work / (注：OpenWrt 的实际挂载过程由 mount_root 和 preinit 脚本处理，细节可能因版本而异，早期版本使用 mini_fo，现代版本均使用 overlayfs)*\n实际操作与管理 查看挂载状态 在 OpenWrt 终端中输入 df -h 或 mount 可以看到 OverlayFS 的结构：\n1 2 3 4 5 6 root@OpenWrt:~# df -h Filesystem Size Used Available Use% Mounted on /dev/root 2.5M 2.5M 0 100% /rom tmpfs 61.8M 168.0K 61.6M 0% /tmp /dev/mtdblock3 5.0M 424.0K 4.6M 8% /overlay overlayfs:/overlay 5.0M 424.0K 4.6M 8% / 可以看到 / 的类型是 overlayfs:/overlay，它的大小等于 /overlay 分区的大小。\n恢复出厂设置 (Firstboot) 由于 OverlayFS 的特性，恢复出厂设置变得非常简单：只需要清空 /overlay 分区即可。\n当 /overlay 被清空后，Upper 层没有了任何文件，系统重启后，OverlayFS 呈现的完全是 Lower 层（即 /rom）的内容，系统就回到了初始状态。\n命令：\n1 2 firstboot -y reboot 扩容 (Extroot) OpenWrt 设备的内置 Flash 通常很小（如 16MB）。利用 OverlayFS，我们可以轻松实现扩容（Extroot）：\n插入一个 USB U盘。 将 U盘格式化为 ext4。 将 U盘挂载为 /overlay。 这样，系统的可用空间就变成了 U盘的大小，可以安装大量的软件包。 常见问题 空间不足: 如果 /overlay 满了，系统可能无法保存配置或安装软件。此时删除文件实际上是在 Upper 层操作。 文件被遮挡: 如果你在 /rom 中修改了源码重新编译固件，但刷机后发现文件没变，可能是因为 /overlay 中存在旧的修改版本遮挡了新的 /rom 文件。刷机时通常建议选择“不保留配置”来清空 /overlay。\n总结 OverlayFS 是 OpenWrt 灵活性的基石。它通过分层机制，既保证了系统底层的稳定性（只读的 /rom），又提供了用户所需的灵活性（可写的 /overlay），并且实现了极低成本的“恢复出厂设置”功能。理解 OverlayFS 对于深入玩转 OpenWrt（如定制固件、扩容、调试）至关重要。\n","date":"2025-07-29T09:52:54+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/overlayfs/","title":"OverlayFS"},{"content":"LXC (Linux 容器) 工作原理详解 LXC (Linux Containers) 是一种操作系统级别的虚拟化技术，它允许在单个 Linux 内核上运行多个隔离的 Linux 系统（容器）。与虚拟机（VM）不同，LXC 不需要模拟硬件，因此它非常轻量级且启动速度快。\nLXC 的核心是利用 Linux 内核的两个关键特性：命名空间 (Namespaces) 和 控制组 (Cgroups)。\nNamespaces：负责隔离，确保一个容器中的进程看不到或影响到另一个容器或宿主机的进程、网络、文件系统等。 Cgroups：负责资源限制和审计，确保每个容器只能使用分配给它的 CPU、内存、I/O 等资源。 本文将重点详细介绍几个关键的命名空间。\n1. PID 命名空间 (PID Namespace) PID (Process ID) 命名空间用于隔离进程 ID。\n原理 隔离进程树：每个 PID 命名空间都有一套独立的进程 ID，从 1 开始。 容器的 init 进程：在一个新的 PID 命名空间中创建的第一个进程会成为该空间的 \u0026ldquo;init\u0026rdquo; 进程，其 PID 为 1。这个进程负责管理容器内的所有其他进程（例如，处理孤儿进程）。如果这个 PID 为 1 的进程终止，内核将终止该命名空间中的所有其他进程。 内外 PID 映射：容器内的进程在容器内部有自己的 PID（例如，PID 1, 2, 3\u0026hellip;），同时在宿主机上也有一个全局唯一的 PID。这意味着从宿主机看，所有容器的进程都是普通的进程，只是被 PID 命名空间隔离开来。 示例 假设我们在宿主机上启动一个 LXC 容器，并在容器内运行 bash。\n容器内视角:\n1 2 3 4 5 6 # 在容器内执行 ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.1 0.0 2384 1596 ? Ss 10:00 0:00 /sbin/init root 15 0.0 0.0 4372 3480 pts/0 Ss 10:01 0:00 bash root 25 0.0 0.0 5924 1788 pts/0 R+ 10:02 0:00 ps aux 在这里，init 进程的 PID 是 1，bash 的 PID 是 15。\n宿主机视角:\n1 2 3 4 # 在宿主机执行 ps aux | grep bash # 输出可能像这样 root 12345 0.0 0.0 4372 3480 pts/0 Ss 10:01 0:00 bash 在宿主机上，同一个 bash 进程的 PID 可能是 12345。这种隔离使得容器内的进程管理与宿主机完全分离。\n2. 网络命名空间 (Network Namespace) 网络命名空间为每个容器提供了一个完全独立的网络协议栈。\n原理 独立网络栈：每个网络命名空间都有自己独立的网络设备（如 lo, eth0）、IP 地址、路由表、iptables 防火墙规则、端口号等。一个容器默认无法访问另一个容器或宿主机的网络。 veth 设备对：为了让容器能与外部通信，LXC 通常使用 veth (Virtual Ethernet) 设备对。veth 设备总是成对出现，像一根虚拟网线。数据从一端进入，会从另一端出来。 连接过程: 创建一对 veth 设备，例如 veth_host 和 veth_container。 将 veth_host 留在宿主机的网络命名空间中。 将 veth_container \u0026ldquo;移动\u0026rdquo; 到容器的网络命名空间中，并将其重命名为 eth0。 在宿主机上，通常会创建一个网桥（例如 lxcbr0），并将 veth_host 端连接到这个网桥上。 为容器内的 eth0 分配 IP 地址。 数据流: 容器内 eth0 发出的网络包 -\u0026gt; 通过 veth 对到达宿主机的 veth_host -\u0026gt; 进入宿主机的网桥 lxcbr0 -\u0026gt; 通过宿主机的物理网卡和路由规则与外部网络通信。 这种结构使得每个容器都像一台独立的机器连接到了一个虚拟交换机（网桥）上，实现了网络隔离和互联。\n3. 文件系统命名空间 (Mount Namespace) 文件系统（挂载）命名空间允许每个容器拥有自己独立的文件系统视图，尤其是独立的根目录 (/)。\n原理 隔离挂载点：每个挂载命名空间维护着一个独立的挂载点列表。在一个命名空间中的 mount() 和 umount() 操作不会影响到其他命名空间。 独立的根文件系统 (rootfs)：LXC 利用这个特性为每个容器创建一个独立的根文件系统。容器进程看到的文件系统层次结构与宿主机完全不同。 实现方式: 准备 rootfs：首先，需要为容器准备一个目录，其中包含一个完整的 Linux 系统所需的文件和目录（如 /bin, /etc, /lib, /usr 等）。这通常通过复制一个最小化的系统模板来完成。 pivot_root 系统调用：为了将容器的根目录切换到准备好的 rootfs，LXC 使用 pivot_root 系统调用（或者在某些情况下使用 chroot，但 pivot_root 更强大、更安全）。pivot_root 会将当前进程的根文件系统切换到一个新的挂载点，同时将旧的根文件系统挂载到新根下的一个指定目录中，之后可以将其卸载。 隔离挂载：在容器启动后，它可以在自己的文件系统命名空间内自由地挂载其他设备或文件系统（如 proc, sysfs, tmpfs），而这些挂载对宿主机是不可见的。 通过这种方式，容器内的进程被\u0026quot;囚禁\u0026quot;在其自己的文件系统视图中，无法访问或修改宿主机的文件系统（除非特别配置了绑定挂载 bind mount）。\n其他命名空间 除了以上三个，LXC 还使用了其他命名空间来实现全方位隔离：\nUTS Namespace: 隔离主机名和域名。 IPC Namespace: 隔离进程间通信资源，如 System V IPC 和 POSIX 消息队列。 User Namespace: 隔离用户和组 ID。允许容器内的 root 用户（UID 0）映射为宿主机上的一个非特权用户，极大地提升了安全性。 Cgroup Namespace: 隔离控制组视图。 总结 LXC 通过精巧地组合使用 Linux 内核的 Namespaces 和 Cgroups 特性，为用户提供了一个轻量级、高效且隔离性良好的容器环境。PID、网络和文件系统命名空间是实现这种隔离的基础，它们分别创建了独立的进程树、网络协议栈和文件系统视图，使得容器内的环境看起来就像一个独立的操作系统。\n","date":"2025-07-28T20:00:08+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/lxc%E8%AF%A6%E8%A7%A3/","title":"LXC详解"},{"content":"对称加密 加密前的原始数据，叫做 原文（ original text ），或者 明文（ plain text ）； 加密后的不规则（ scrambled ）数据，通常叫做 密文（ cipher text ）； 加密所用的密码，通常叫做 密钥（ secret key ）； 对称加密（symmetric encryption）算法最大的特点是，它只有一把密钥，加密和解密过程用的都是同一把密钥，这也符合大众对加密算法的认知，用密码对数据进行加密之后，必须用同一个密码才能将数据解密出来\nAES ，高级加密标准，新一代加密算法标准，速度快，安全级别高； DES ，数据加密标准，速度较快，适用于加密大量数据，但安全性较弱； Blowfish ，使用变长密钥，运行速度很快，非专利算法，没有使用限制； etc 非对称加密 从前有一个黑帮，老大和手下们之间的通信必须加密确保安全。于此同时，老大希望手下发给他的信息，不能被其他手下知晓。若采用对称加密算法，只能给每个手下都分配一个独立的密钥，但老大觉得太麻烦了。该怎么办呢？\n黑帮老大希望他只维护一份密钥，就能达到这样的效果，有办法做到吗？\n可以用非对称加密（asymmetric encryption）\n非对称加密，顾明思议，在加密和解密环节用的密钥是不同的。\n非对称加密算法需要两把不同的密钥，这两把密钥组成一对：\n公钥（ public key ），公钥用来对数据进行 加密 ； 私钥（ private key ），也称为 密钥（ secret key ），用来对数据进行 解密 ； 公钥和私钥总是成对出现，用公钥加密后得到的密文，必须用对应的私钥才能解密； 这套加密机制完美解决了黑帮老大的难题，他只需要生成一对密钥：公钥分发给手下们，他们先用公钥加密信息，再发老大；老大接到密文，就用自己保管的私钥来解密；手下们就算拿到别人发的密文也解不开，因为私钥只有他们老大才有。\n数学原理 公钥和私钥的加密机制看起来非常不可思议，这一切其实来一个神奇的数学原理。\n我们来做一个数字游戏，您随便写下一个整数 m （1\u0026lt;m\u0026lt;7387 ），然后计算m ^3 mod 7387 并把结果告诉我，我就知道您写下的整数 m 是什么\n1 2 3 4 5 6 7 8 9 10 11 # 520 \u0026gt;\u0026gt;\u0026gt; 520 ** 3 % 7387 3842 \u0026gt;\u0026gt;\u0026gt; 3842 ** 4811 % 7387 520 # 1314 \u0026gt;\u0026gt;\u0026gt; 1314 ** 3 % 7387 7382 \u0026gt;\u0026gt;\u0026gt; 7382 ** 4811 % 7387 1314 公钥参数 3 和 7387 ，私钥参数 4811 和 7387 又是怎么生成的呢？ 第一步，随机选择两个质数 p 和 q ： p = 83 q = 89 第二步，计算 p 和 q 的乘积 n ： n = p * q = 7387 第三步，计算 n 的欧拉函数 ，记为 phi ： φ(n) = (p-1) * (q-1) = 7216 第四步，随机选择一个整数 e ，满足1\u0026lt;e\u0026lt;φ(n)，且 e 和φ(n)互质： 选一个质数 e ，使得不能被 e 整除即可。 第五步，计算 e 对φ(n)的模反元素 d ，即找到一个数 d 使得 ed 除以φ(n)的余数为 1 ： ed ≡ 1 mod(φ ( n )) \u0026lt;=\u0026gt; ed = kφ(n) + 1 可以找到一个d :4811\n安全性分析 那么，有无可能在已知n和e的情况下，推导出d？\n1 2 3 ed≡1 (mod φ(n))。只有知道e和φ(n)，才能算出d。 φ(n)=(p-1)(q-1)。只有知道p和q，才能算出φ(n)。 n=pq。只有将n因数分解，才能算出p和q。 大整数的因数分解，是一件非常困难的事情\n目前，能够被破解的 n 最大位数是 768 位(这里提到的位是指二进制位)，因此有人开始质疑 1024 位密钥的安全性。现在推荐的密钥长度至少要 2048 位，只要长度足够，安全性完全不用担心\n应用场景 加密 公钥加密私钥解密是非对称加密算法最典型的应用场景，特别适用于密钥需要公开的场景，比如 传输层安全协议 TLS ，它为通讯双方提供可靠的加密连接\n如果没有非对称加密算法，TLS 将无法实现。因为对称加密算法要求双方使用同一密钥，加密连接建立之前，只能明文协商密钥。试想浏览器想跟服务器建立安全连接，无论是它选定密钥然后发给服务器，还是服务器选定密钥发给它，只要密钥经过明文传输，加密就失去意义。\n有了非对称加密算法，服务器可以生成一对密钥，私钥自己保管，公钥可以公开。当浏览器请求建立加密连接时，服务器可以将公钥发给浏览器，因为公钥是可以公开的。浏览器将敏感信息用公钥加密后再发给浏览器，只有掌握私钥的服务器才能解密，他人便无法知晓。\n同理，服务器想发敏感信息给客户端，必须由客户端生成的公钥加密。换句话讲，每对密钥解决一个方向的加密问题，通讯双方都需要生成自己的密钥对，负责加密对方发来的数据。\n由于非对称加密算法运算复杂，加密效率不高，通常只是用来加密少量的关键信息，比如协商密钥。回到 TLS 这个例子，其实可以借助非对称加密算法协商密钥，从而直接使用更高效的对称加密算法来加密数据：\n服务器生成公钥和私钥 对； 客户端（浏览器）连接上来后，服务器将公钥发给客户端； 客户端随机生成一个用于对称加密（ AES ）的密钥； 客户端用公钥对生成的密钥进行加密，然后后发给服务器； 服务器收到客户端用公钥加密的密钥后，用自己的私钥解密，至此密钥协商完毕； 由于私钥只有服务器才有，因此第三方无法知晓客户端选定的密钥是啥； 此后通信双方采用对称加密，以该密钥加密数据； 签名 实际上，私钥也可以用来加密数据，加密后的密文只有公钥才能解密。尽管如此，由于公钥是公开的，因此这个机制不能来加密数据，但可以对用来对数据进行签名防伪。\n数字证书(certificate) 信息摘要（ digest ），数据经过哈希算法得到的一串哈希值，代表数据的特征，也称为数据指纹； 摘要算法 ，可以把任意长度的数据，映射成一个定长的字符串（哈希值）； 由于哈希冲突的存在，两份不同的数据，有可能算出相同的摘要值； 摘要算法无法用于数据加密，通常用来校验数据完整性，即 数据防伪 ； 常见的摘要算法有：MD5 、SHA1 、SHA256 、SHA512 。 数字签名（ signature ），摘要由私钥加密后，得到的摘要密文就是数字签名； 签名，由数据发送方生成，这是一个 加密 过程（使用私钥）； 验签，由数据接收方校验，这是一个 解密 过程（使用公钥）； 数字签名只能由私钥生成，因此第三方无法伪造； 在介绍密钥协商时，我们提到服务器先将公钥发给客户端，用公钥保护对称加密密钥，确保通信内容不会被第三方获悉。但如果客户端连接的服务器是假的呢？如果用户对假网站信以为真，输入了账号密码，那么这些敏感信息都会被假网站窃取！\n上节我们也讨论了数字签名，通过它可以实现数据防伪。那么，我们是不是可以利用这项技术来甄别仿冒站点呢\n权威机构生成一对密钥，并提供站点认证审核和数字签名颁发服务； 站点管理员将站点信息，包括域名、运营单位、公钥等信息发给权威机构审核； 权威机构对提交上来的站点信息进行审核，审核通过则用私钥签名后返回给站点管理员； 客户端（浏览器）连接站点服务器，服务器将站点信息以及对应的数字签名发给客户端； 客户端用权威机构提供的公钥来校验数字签名，即可判断站点信息的真伪性； 签名验证通过，客户端从站点信息中取出公钥，与服务端协商密钥，发起加密通信； 由于签名用的私钥只有权威机构掌握，黑客无法伪造数字签名，也就无法架设仿冒站点； 权威机构必须由可信的单位运营； 你可能会觉得，黑客直接盗用站点信息和签名不就可以伪造原站点了嘛？此言差矣！因为公钥属于站点信息\n的一 部分，也会参与签名！客户端和服务端协商密钥时，会使用这个公钥加密密钥。由于黑客不掌握站点私 钥，因此 加密连接无法建立！黑客把公钥替换成自己的吧，签名就不对，肯定会被验出来！\n证书签发实验 CA权威机构 首先，权威机构需要生成一对密钥，cakey.pem 是私钥,\n1 openssl genrsa -out cakey.pem 2048 然后，生成根证书签发申请文件（ csr 文件）：\n1 openssl req -new -key cakey.pem -out ca.csr -subj \u0026#39;/C=CN/ST=Guangdong/L=Guangzhou/O=coding-fans/OU=CA/CN=ca.fasionchan.com\u0026#39; 证书申请文件包含权威机构的信息，包括机构信息(Subject )和公钥(Public Key 部分)可以用下面命令查看：\n1 openssl req -in ca.csr -text -noout 最后，自签根证书（ cer 文件 ）：\n1 openssl x509 -req -days 3650 -sha1 -extensions v3_ca -signkey cakey.pem -in ca.csr -out ca.cer 这一步生成的 cer 文件就是根证书文件，它的主要作用是承载权威机构公钥，以便预装在操作系统或者其他终端。它同样会包含权威机构的信息，公钥，以及对应的签名。\n商业站点（服务端） 首先，站点管理员生成一对密钥\n1 openssl genrsa -out sitekey.pem 2048 然后，生成证书签发申请文件（ csr 文件）：\n1 openssl req -new -key sitekey.pem -out site.csr -subj \u0026#39;/C=CN/ST=Guangdong/L=Guangzhou/O=fasionchan/OU=website/CN=fasionchan.co 证书申请文件包含站点信息和公钥，站点管理员将证书申请文件发给权威机构审核，\n权威机构对申请进行审核，审核通过则用自己的私钥对它进行签名，生成证书(cer 文件):\n1 openssl x509 -req -days 365 -sha1 -extensions v3_req -CA ca.cer -CAkey cakey.pem -CAserial ca.srl -CAcreateserial -in site.csr -out site.cer 证书中保存着包括公钥在内的站点信息，以及权威机构对这些信息的签名。管理员接到权威机构颁发的证书，就可以部署网站了\n浏览器（客户端） 客户端浏览器访问站点，服务端会将其证书发给客户端。客户端先对证书签名进行验证，步骤如下：\n重新对证书中的站点信息计算 摘要值 ； 用公钥对证书中的签名进行解密，得到证书的原始摘要值； 公钥通常由根证书提供，根证书通常预装在系统里； 对比两个摘要值看是否一致； 调用 openssl 工具，一行命令即可完成签名验证\n1 openssl verify -CAfile ca.cer site.cer 总结 数字证书是支撑互联网身份认证的重要技术手段，可以简单理解成经过 CA 权威结构签名认证过的站点信息。由于经过 CA 签名，第三方无法通过伪造手段冒充身份。\n证书由站点信息和 CA 签名组成，站点信息包含站点公钥，公钥用于协商对称加密密钥； 证书由 CA 权威机构审核签发，签名用的是 CA 的私钥； CA 公钥通常以根证书形式预装在系统内，客户端通过它来验证证书签名； 有了数字签名，黑客无法对证书进行篡改，也无法伪造证书，因此无法部署仿冒站点； 若只窃取原站点证书，不做篡改，客户端使用真实站点的公钥，而黑客无法掌握站点私钥，因此加密连接无法建立； 如果篡改原站点证书，换上自己的公钥，但因为没有 CA 私钥无法生成合法签名，也会被识别出来； 转载自数字证书身份认证原理与签发步骤详解 | 小菜学网络\n","date":"2025-07-28T16:36:08+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/%E8%AF%81%E4%B9%A6%E8%AF%A6%E8%A7%A3/","title":"证书详解"},{"content":"RESTful API 一、RESTful API概述 1.1 定义 REST（Representational State Transfer）即表现层状态转移，是一种针对网络应用的设计风格，主要用于设计分布式超媒体系统。RESTful API 则是遵循 REST 架构原则的应用程序接口，允许客户端和服务器通过 HTTP 协议进行交互。它采用资源定位的思维模式，将所有的操作都视为对资源的操作，以使系统更加简洁、易于理解和扩展。\n1.2 核心概念 资源（Resource）：RESTful API 中的每一个对象、实体或数据都被抽象为一个资源。例如，用户、文章等都可以作为资源。每个资源都通过一个唯一的 URI（统一资源标识符）标识。比如，/users/123 表示 id 为 123 的用户资源，/posts/456 表示 id 为 456 的文章资源。 URI（统一资源标识符）：用于标识资源的地址，通常使用 URL（统一资源定位符）作为 URI。 HTTP 动作（HTTP Methods）：依赖于 HTTP 协议的常见方法来对资源进行操作，每个 HTTP 方法对应不同的操作： GET：获取服务器上的资源。 POST：在服务器上创建新的资源。 PUT：更新服务器上的资源。 DELETE：删除服务器上的资源。 无状态（Statelessness）：每个请求都应该是独立的，服务器不会在请求之间保存客户端的状态。每次请求都必须包含理解请求所必需的信息。 表现层状态转移（Representational State Transfer）：资源的表现形式可以是 JSON、XML、HTML 等格式，通常 RESTful API 使用 JSON 作为数据交换格式，因为它轻量且易于解析。客户端通过接收资源的表现形式（如 JSON、XML）来感知资源的变化，从而实现状态的“转移”。 二、RESTful API的特点和优势 2.1 特点 资源导向：所有内容都被抽象为资源（如 User、Order、Article 等），每个资源都有一个唯一的标识符（URI）。例如，/users 表示用户资源，/users/1 表示 ID 为 1 的用户。 使用标准协议：基于 HTTP 协议，直接使用其方法（GET、POST 等）来操作资源。 无状态通信：每次请求都包含所有上下文，不依赖服务器保存状态。这使得服务器可以更加容易地进行扩展和负载均衡，因为每个请求都是独立的，不需要考虑之前的请求状态。 统一接口：接口风格统一、易于理解和使用。通过标准的 HTTP 方法（GET、POST、PUT、DELETE 等）和资源标识符（URI）访问资源，简化了系统的整体架构，提升了互操作性。 可缓存：客户端可根据响应头对资源进行缓存，提高性能。利用 HTTP 协议的缓存机制，允许中间件或客户端缓存响应结果，减少不必要的网络请求，从而提升响应速度和减轻服务器负担。 分层架构：客户端无需知道请求最终由谁处理（例如中间层、负载均衡等）。允许通过中间层（如代理服务器、网关）来处理请求，每层只需与相邻层通信，增强了系统的安全性、可扩展性和灵活性。 按需代码（可选）：客户端可以从服务器下载代码或脚本，以扩展其功能，增加了系统的灵活性和可扩展性。 2.2 优势 简洁易懂：使用 HTTP 协议的标准方法和 URI，可以让 API 的设计和使用变得简单。通过 URL 和 HTTP 动词的组合，可以明确地表示对特定资源的操作意图。 灵活性：资源可以有不同的表示形式（JSON、XML 等），同时 HTTP 方法明确区分不同的操作。客户端可以根据自身需求选择合适的数据格式。 扩展性强：通过一致的接口设计，可以很容易地扩展和维护 API。随着应用程序的发展，可以轻松地添加新的资源和操作，而不会影响现有的 API 结构。 无状态性：简化了服务器端的设计，增强了系统的可扩展性。服务器不需要保存客户端的状态信息，使得服务器可以更容易地进行扩展和负载均衡。 跨平台：基于 HTTP 协议，可以被任何支持 HTTP 的客户端调用，适用于各种应用场景，特别是需要跨平台和跨语言交互的系统。 三、RESTful API的设计原则 3.1 基于资源 将网络上的每个实体或概念视为唯一资源是一个关键原则。通过 URL 来表示这些资源，使得资源的定位更加清晰和直观。例如，一个博客文章可以被表示为 /articles/123，其中 “articles” 表示文章资源的集合，“123” 是具体某一篇文章的唯一标识符。这种方式使得开发者和用户都能够轻松地理解和访问特定的资源。以电商平台为例，商品可以表示为 /products，每个具体的商品可以通过 /products/{productId} 来访问，其中 {productId} 是商品的唯一标识。\n3.2 统一接口 资源标识（Resource Identification）：每个资源都应有唯一的 URL。例如，用户资源可以通过 /users/{id} 进行标识，其中 {id} 是用户的具体标识。 资源操作（Resource Manipulation Through Representations）：通过表示（representation）来操作资源，而不是直接操作资源本身。使用标准的 HTTP 方法（GET、POST、PUT、DELETE 等）来操作资源。 自描述消息（Self - descriptive Messages）：响应消息应包含足够的信息以便客户端无需额外文档即可理解。每个请求和响应都包含足够的信息，使得客户端能够理解如何处理它们。 无状态（Stateless）：服务器不保存客户端的上下文信息，每次请求都是独立的。每个请求都必须包含足够的信息，使服务器能够理解和处理该请求，而不依赖于之前的请求。 3.3 使用标准的 HTTP 方法 主要使用 HTTP 方法来定义对资源的操作，常见的 HTTP 方法及其作用如下：\nHTTP 方法 操作 幂等性 安全性 示例 GET 获取资源 ✅ ✅ GET /users 查看所有用户信息；GET /users/id 查看该 id 的用户信息 POST 创建资源 ❌ ❌ POST /users 创建用户，可在 DATA 处带需要的参数 PUT 更新或替换资源 ✅ ❌ PUT /users/id?name='张三'\u0026amp;age=20 修改该 id 的用户信息（name 和 age） PATCH 部分更新资源 ❌ ❌ 对资源进行部分属性的更新 DELETE 删除资源 ✅ ❌ DELETE /users/id 删除该 id 的用户信息 HEAD 获取资源的元数据 ✅ ✅ OPTIONS 获取信息，关于资源的哪些属性是客户端可以改变的 ✅ ✅ 3.4 无状态通信 每个请求必须包含服务器处理该请求所需的所有信息，服务器不依赖之前的请求上下文。这使得服务器可以更加容易地进行扩展和负载均衡，因为每个请求都是独立的，不需要考虑之前的请求状态。例如，当客户端发送多个请求时，服务器不需要记住之前的请求内容，只需要根据当前请求的信息进行处理。\n3.5 返回适当的状态码 API 应返回适当的 HTTP 状态码，准确反映请求结果。常用的状态码如下：\n状态码 含义 说明 200 OK 服务器成功返回用户请求的数据，该操作是幂等的（Idempotent），通用成功。 201 Created 资源已创建，通常用于 POST 请求。 204 No Content 请求成功，但无返回内容，通常用于 DELETE 请求。 400 Bad Request 请求参数有误，服务器无法处理。 401 Unauthorized 认证失败，客户端需要提供身份验证。 403 Forbidden 没有权限访问资源，服务器理解请求，但拒绝执行，通常由于权限问题。 404 Not Found 请求的资源不存在。 500 Internal Server Error 服务器内部错误。 3.6 过滤信息 如果记录数量很多，服务器不可能都将它们返回给用户。API 应该提供参数，过滤返回结果。常见的参数如下：\n?limit=10：指定返回记录的数量。 ?offset=10：指定返回记录的开始位置。 ?page=2\u0026amp;per_page=100：指定第几页，以及每页的记录数。 ?sortby=name\u0026amp;order=asc：指定返回结果按照哪个属性排序，以及排序顺序。 ?animal_type_id=1：指定筛选条件。 3.7 支持 HATEOAS（超媒体作为应用程序状态引擎） HATEOAS 要求客户端能够通过服务器返回的超链接（URL）导航到相关资源。简而言之，HATEOAS 要求 API 的响应不仅包含资源数据，还应该包含与资源相关的操作链接，帮助客户端更好地理解如何进行下一步操作。例如，获取用户信息时，除了返回用户的详细数据外，API 还可以提供相关操作的链接：\n1 2 3 4 5 6 7 8 9 { \u0026#34;user_id\u0026#34;: 123, \u0026#34;name\u0026#34;: \u0026#34;John Doe\u0026#34;, \u0026#34;links\u0026#34;: { \u0026#34;self\u0026#34;: \u0026#34;/users/123\u0026#34;, \u0026#34;update\u0026#34;: \u0026#34;/users/123/update\u0026#34;, \u0026#34;delete\u0026#34;: \u0026#34;/users/123/delete\u0026#34; } } 3.8 数据格式 返回数据格式通常使用 JSON 或 XML，其中 JSON 因其轻量级和易读性，已成为 RESTful API 事实上的数据交换格式。统一返回 JSON 格式，包含数据、状态码和错误信息，例如：\n1 2 3 4 5 { \u0026#34;status\u0026#34;: 200, \u0026#34;data\u0026#34;: { \u0026#34;id\u0026#34;: 123, \u0026#34;name\u0026#34;: \u0026#34;Alice\u0026#34; }, \u0026#34;error\u0026#34;: null } 3.9 版本控制 当 API 发生变化时，可以通过版本号来管理不同版本的 API，以保持向后兼容性。常见的版本控制策略有：\nURL 路径版本：如 /v1/resource，优点是简单、显式、易缓存；缺点是不够优雅、URL 膨胀。 请求头版本：如 X - API - Version: 1，优点是 URL 干净、松耦合；缺点是难调试、可能被代理移除。 内容协商版本：如 Accept: application/vnd.example.v1+json，优点是 RESTful、标准 HTTP 头；缺点是复杂、客户端支持不一。 查询参数版本：如 /resource?version=1，优点是简单、显式；缺点是不是 RESTful、URL 污染。 四、RESTful API的设计示例 以一个简单的博客平台为例，设计其 RESTful API：\n4.1 资源列表 用户（/users） 文章（/articles） 评论（/comments） 4.2 操作设计 操作 HTTP 方法 URL 说明 获取所有用户 GET /users 返回所有用户的列表 获取特定用户 GET /users/{id} 返回指定 ID 用户的详细信息 创建用户 POST /users 根据请求体中的数据创建新用户 更新用户信息 PUT /users/{id} 更新指定 ID 用户的信息 删除用户 DELETE /users/{id} 删除指定 ID 的用户 获取所有文章 GET /articles 返回所有文章的列表 获取特定文章 GET /articles/{id} 返回指定 ID 文章的详细信息 创建文章 POST /articles 根据请求体中的数据创建新文章 更新文章信息 PUT /articles/{id} 更新指定 ID 文章的信息 删除文章 DELETE /articles/{id} 删除指定 ID 的文章 获取特定文章的评论 GET /articles/{id}/comments 返回指定 ID 文章的所有评论 创建评论 POST /articles/{id}/comments 在指定 ID 文章下创建新评论 删除评论 DELETE /comments/{id} 删除指定 ID 的评论 五、RESTful API的实现 5.1 服务端实现（以 Node.js 为例） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 const express = require(\u0026#39;express\u0026#39;); const app = express(); app.use(express.json()); // 模拟用户数据 const users = [ { id: 1, name: \u0026#39;John Doe\u0026#39;, email: \u0026#39;john@example.com\u0026#39; }, { id: 2, name: \u0026#39;Jane Smith\u0026#39;, email: \u0026#39;jane@example.com\u0026#39; } ]; // 获取所有用户 app.get(\u0026#39;/api/v1/users\u0026#39;, (req, res) =\u0026gt; { res.status(200).json({ status: 200, data: users }); }); // 创建新用户 app.post(\u0026#39;/api/v1/users\u0026#39;, (req, res) =\u0026gt; { const newUser = req.body; users.push(newUser); res.status(201).json({ status: 201, data: newUser }); }); // 获取特定用户 app.get(\u0026#39;/api/v1/users/:id\u0026#39;, (req, res) =\u0026gt; { const userId = parseInt(req.params.id); const user = users.find(u =\u0026gt; u.id === userId); if (user) { res.status(200).json({ status: 200, data: user }); } else { res.status(404).json({ status: 404, error: \u0026#39;User not found\u0026#39; }); } }); // 更新用户信息 app.put(\u0026#39;/api/v1/users/:id\u0026#39;, (req, res) =\u0026gt; { const userId = parseInt(req.params.id); const updatedUser = req.body; const index = users.findIndex(u =\u0026gt; u.id === userId); if (index!== -1) { users[index] = updatedUser; res.status(200).json({ status: 200, data: updatedUser }); } else { res.status(404).json({ status: 404, error: \u0026#39;User not found\u0026#39; }); } }); // 删除用户 app.delete(\u0026#39;/api/v1/users/:id\u0026#39;, (req, res) =\u0026gt; { const userId = parseInt(req.params.id); const index = users.findIndex(u =\u0026gt; u.id === userId); if (index!== -1) { users.splice(index, 1); res.status(204).send(); } else { res.status(404).json({ status: 404, error: \u0026#39;User not found\u0026#39; }); } }); const port = process.env.PORT || 3000; app.listen(port, () =\u0026gt; { console.log(`Server is running on port ${port}`); }); 5.2 客户端调用（以 JavaScript Fetch 为例） 1 2 3 4 5 6 7 8 9 10 11 12 // 获取用户数据 fetch(\u0026#39;https://api.example.com/users/123\u0026#39;) .then(response =\u0026gt; response.json()) .then(data =\u0026gt; console.log(data)) .catch(error =\u0026gt; console.error(\u0026#39;Error:\u0026#39;, error)); // 提交新文章 fetch(\u0026#39;https://api.example.com/articles\u0026#39;, { method: \u0026#39;POST\u0026#39;, headers: { \u0026#39;Content - Type\u0026#39;: \u0026#39;application/json\u0026#39; }, body: JSON.stringify({ title: \u0026#39;Hello REST\u0026#39;, content: \u0026#39;...\u0026#39; }) }); 六、RESTful API的应用场景 6.1 Web 服务 提供 Web 服务，如社交媒体、电商网站等。前端（如 JavaScript、Angular、React 等）可以通过 RESTful API 与后端服务器进行通信，获取和更新数据。例如，一个电商网站的前端可以使用 RESTful API 从服务器获取商品列表、用户信息等，并将用户的订单信息发送到服务器进行处理。\n6.2 移动应用 移动应用通过 RESTful API 与服务器交互，获取和更新数据，实现用户登录、数据同步等功能。Android 和 iOS 应用可以使用 RESTful API 与服务器交互，提供丰富的用户体验。\n6.3 物联网（IoT） 设备通过 RESTful API 与服务器通信，实现数据采集和控制。物联网设备可以通过 RESTful API 将采集到的数据发送到服务器，同时接收服务器的控制指令。\n6.4 微服务架构 微服务之间通过 RESTful API 进行通信和协作。每个微服务都可以暴露自己的 RESTful API，其他微服务可以通过调用这些 API 来获取所需的数据或执行特定的操作。例如，一个电商系统可能由用户服务、商品服务、订单服务等多个微服务组成，这些微服务之间可以通过 RESTful API 进行数据交互和业务协作。\n6.5 企业级应用集成 企业内部的不同系统之间可以使用 RESTful API 进行集成。例如，企业的客户关系管理系统（CRM）和企业资源规划系统（ERP）可以通过 RESTful API 进行数据交换，实现信息共享和业务流程的协同。\n七、RESTful API与传统 API的对比 比较项 RESTful API 传统 API 风格 接口风格 资源导向，结构清晰 动作导向，接口混乱 动作表示 使用 HTTP 方法表示动作 接口路径中包含动词（如 /getUser） 可读性 高，可直观理解操作含义 低，需要阅读文档才能理解 维护性 易于扩展和维护 扩展性差，接口膨胀 数据传输格式 通常使用 JSON 或 XML，有明确标准 可能使用多种格式，无明确标准 状态与缓存 强调状态无关性，可利用 HTTP 缓存机制 可能依赖服务器端状态，缓存策略不一致 安全性和认证 支持各种安全性措施，如 HTTPS、认证、授权等 可能缺乏统一的安全标准 接口一致性 统一接口，易于使用 接口设计松散，不一致 资源关联性 在响应中提供相关资源的链接，具有自描述性 通常不提供自描述性 综上所述，RESTful API 以其简洁、灵活、可扩展等优点，成为现代 Web 开发中主流的 API 设计风格之一，广泛应用于各种网络应用场景中。在设计和开发 RESTful API 时，遵循其设计原则和最佳实践，能够构建出高效、易用、可维护的 API 系统。\n","date":"2025-06-26T15:22:59+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/restful-api/","title":"RESTful API"},{"content":"创建public仓库用来存放照片 创建token token将来PicGo操作你的github仓库来上传图片时要用到，在 GitHub 账户下 Setting - Developer setting - Personal access tokens(classic) 下创建一个不过期(no expiration)的 Token，权限需要开启 repo.这个我们在用Github action 来部署博客仓库时已经创建了，用那个就好.token 在创建时只显示一次，要保存好哦！\n配置PicGo github 搜索PicGo 然后安装 图床具体参数配置 仓库名 分支名 对应于之前你创建的GitHub仓库\nToken就是前面创建的Token,被PicGo用来上传照片到长仓库\n路径可以自定义\n自定义域名格式:https://cdn.jsdelivr.net/gh/用户名/仓库名@分支名\nTypora Typora 可搭配PicGo使用\n若PicGo显示unable to verify the first certificate at TLS,无法上传，则可能是你的网络加速工具造成的某些网络加速工具可能会修改网络流量，可能与 SSL证书验证机制发生冲突。这可能导致 SSL 证书验证失败，因为服务器的证书无法正常验证，从而出现类似 \u0026ldquo;unable to verify the first certificate\u0026rdquo; 的错误。例如我之前用Watt Toolkit就出现了：\n如果Typora显示failed to fetch ；检查PicGo server 设置的监听地址是否一致（点击Typora图片设置中的验证图片上传）\njsDelivr jsDelivr是一个免费、开源的加速CDN公共服务,托管了许多大大小小的项目,可加速访问托管的项目目录或图片资源。 他支持提供npm、Github、WordPress上资源cdn服务。\nCDN (全称 Content Delivery Network)，即内容分发网络。\nCDN构建在现有网络基础之上的智能虚拟网络，依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等功能模块，使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。\nCDN 的关键技术主要有内容存储和分发技术，简单来讲，CDN就是根据用户位置分配最近的资源，于是，用户在上网的时候不用直接访问源站，而是访问离他“最近的”一个 CDN 节点(也叫做“边缘节点”、edge node)，其实就是缓存了源站内容的代理服务器\n","date":"2025-06-12T19:33:46+08:00","permalink":"https://charles-7777.github.io/hugo-stack/p/github--picgo-%E6%90%AD%E5%BB%BA%E5%9B%BE%E5%BA%8A/","title":"Github + PicGo 搭建图床"},{"content":" 创建仓库 首先在github创建两个仓库，一个用于存储hugo new site创建的workspace，这个设置为private私密；另一个仓库用来存储hugo -D生成的网页文件 ，设置为公开:\n本地获取ssh密钥 终端输入命令：\n1 2 git config --global user.email \u0026#34;you@example.com\u0026#34; #you@example.com替换为你的邮箱 git config --global user.name \u0026#34;Your Name\u0026#34; #Your Name替换为你的名字并回车 生成ssh key,在git bash中输入以下命令:\nssh-keygen -t rsa -C \u0026quot;your_email@example.com\u0026quot; 生成的密钥将存储在C:\\uers\\username\\.ssh\\路径下 打开公钥文件 id_rsa.pub， 复制所有内容，在GitHub上打开Setting -\u0026gt; SSH and GPG keys -\u0026gt; add SSH key，将复制的内容粘贴在里边，保存。\n若配置完后，还是显示无法连接到github,可能是你的Windows电脑的username 是中文导致的bug 或者尝试在.ssh 下创建一个config 文件\n1 2 3 4 5 6 Host github.com HostName ssh.github.com # **这是最重要的部分** User git Port 443 PreferredAuthentications publickey IdentityFile ~/.ssh/id_rsa 创建github token 在 GitHub 账户下 Setting - Developer setting - Personal access tokens(classic) 下创建一个不过期(no expiration)的 Token，权限需要开启 repo 与 workflow。\n（注意：token只会显示一次，请及时保存） 私密源仓库设置token 在博客源仓库的 Settings-\u0026gt;Secrets-\u0026gt;Actions 中添加 PERSONAL_TOKEN 环境变量为刚才的 Token,\n这样 GitHub Action 就可以获取到Token 了。 本地首次创建博客 1 2 3 hugo new site hugo-stack-blog-dev git init git submodule add https://github.com/CaiJimmy/hugo-theme-stack/ themes/hugo-theme-stack git submodule主要是将自己的改动，与引用的stack主题仓库分开。hugo-theme-stack 下的目录结构基本与站点源目录结构一致 hugo 生成网站时优先寻找站点源目录下的，找不到，才会去stack主题对应目录下寻找\n接下来将 exampleSite样例数据中的 Content 和 hugo.yaml 复制到主文件夹中，并删掉hugo.toml\n可以hugo server -D看一下初始网站长啥样\n创建一篇新文章(在主目录下)\n1 hugo new post/blog1/index.zh-cn.md 初始化博客源仓库，提交到github\n1 2 3 4 5 git add . git commit -m \u0026#34;first commit\u0026#34; git branch -M main git remote add origin git@github.com:charles-7777/hugo-stack-blog-dev.git git push -u origin main 创建workflows发布文件 在本地博客主目录下创建 .github/workflows目录，然后创建xxxx.yaml文件。我的 GitHub Action 配置为，自动发布示例配置如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 name: deploy # 代码提交到main分支时触发github action on: push: branches: - main jobs: deploy: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v2 with: submodules: recursive fetch-depth: 0 - name: Setup Hugo uses: peaceiris/actions-hugo@v3 with: hugo-version: \u0026#34;0.147.7\u0026#34; extended: true - name: Build Web run: hugo -D - name: Deploy Web uses: peaceiris/actions-gh-pages@v4 with: PERSONAL_TOKEN: ${{ secrets.TOKEN }} EXTERNAL_REPOSITORY: charles-7777/hugo-stack PUBLISH_BRANCH: main PUBLISH_DIR: ./public commit_message: auto deploy 提交github action的改动后，每次push hugo-stack-blog-dev ,就会把基于这个厂库 hugo -D 生成的文件 自动push 到仓库 hugo-stack\nGitHub Pages 前往hugo-stack 仓库的settings--\u0026gt;Pages去添加deploy GitHub Pages 在别的电脑拉取源仓库修改 1 2 3 git clone git@github.com:charles-7777/hugo-stack-blog-dev.git git submodule init git submodule update 参考链接\nhttps://letere-gzj.github.io/hugo-stack/tags/hugo/\n参考博主letere-gzj的视频 markdown中的图片也可以不用本地的图片，可以使用网络url，可以自己创建一个图床，方便管理。 github图床\n","date":"2025-06-09T00:00:00Z","image":"https://cdn.jsdelivr.net/gh/charles-7777/ImageBed@main/blog/hugo.png","permalink":"https://charles-7777.github.io/hugo-stack/p/hugo-stack-blog-%E6%90%AD%E5%BB%BA%E8%AE%B0%E5%BD%95/","title":"hugo stack blog 搭建记录"}]